{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Ansible Collection For Arista Validated Designs - arista.avd # Table of Contents: Ansible Collection For Arista Validated Designs - arista.avd Roles Overview Custom Plugins Installation Requirements Installation from ansible-galaxy Example Playbooks License Roles Overview # This repository provides roles for Ansible\u2019s collection arista.avd with the following content: arista.avd.eos_l3ls_evpn - Opinionated Data model for deployment of L3 Leaf and Spine Fabric with VXLAN data-plane with an EVPN Control plane. arista.avd.eos_cli_config_gen - Generate Arista EOS cli syntax and device documentation. arista.avd.eos_config_deploy_cvp - deploys intended configuration via CloudVision. arista.avd.eos_config_deploy_eapi - deploys intended configuration via eAPI. arista.avd.cvp_configlet_upload - Uploads configlets from a local folder to CloudVision Server. Custom Plugins # This repository provides custom plugins for Ansible\u2019s collection arista.avd : Arista AVD Plugins Installation # Requirements # Arista EOS: EOS 4.21.8M or later Roles validated with eAPI transport -> ansible_connection: httpapi Python: Python 3.6.8 or later Supported Ansible Versions: ansible 2.9.2 or later Additional Python Libraries required: Jinja2 2.10.3 netaddr 0.7.19 requests 2.22.0 treelib 1.5.5 pytest 5.3.4 pytest-html 2.0.1 Ansible + Additional Python Libraries Installation: pip3 install -r requirements.txt requirements.txt content: ansible==2.9.2 Jinja2==2.10.3 netaddr==0.7.19 requests==2.22.0 treelib==1.5.5 pytest==5.3.4 pytest-html==2.0.1 Ansible Configuration INI file: enable jinja2 extensions: loop controls and do Jinja2 Extensions Documentation By default, Ansible will issue a warning when a duplicate dict key is encountered in YAML. We recommend to change to error instead and stop playbook execution when a duplicate key is detected. jinja2_extensions = jinja2.ext.loopcontrols,jinja2.ext.do duplicate_dict_key = error Installation from ansible-galaxy # Ansible galaxy hosts all stable version of this collection. Installation from ansible-galaxy is the most convenient approach for consuming arista.avd content ansible-galaxy collection install arista.avd Example Playbooks # An example playbook to deploy VXLAN/EVPN Fabric via CloudVision: - hosts: DC1_FABRIC tasks: - name: generate intended variables import_role: name: arista.avd.eos_l3ls_evpn - name: generate device intended config and documentation import_role: name: arista.avd.eos_cli_config_gen - name: deploy configuration via CVP import_role: name: arista.avd.eos_config_deploy_cvp An example playbook to deploy VXLAN/EVPN Fabric via eAPI: - hosts: DC1_FABRIC tasks: - name: generate intended variables import_role: name: arista.avd.eos_l3ls_evpn - name: generate device intended config and documentation import_role: name: arista.avd.eos_cli_config_gen - name: deploy configuration to device import_role: name: arista.avd.eos_config_deploy_eapi Full examples with variables and outputs, are located here: Arista NetDevOps Examples License # Project is published under Apache 2.0 License","title":"Ansible Collection For Arista Validated Designs - arista.avd"},{"location":"#ansible-collection-for-arista-validated-designs-aristaavd","text":"Table of Contents: Ansible Collection For Arista Validated Designs - arista.avd Roles Overview Custom Plugins Installation Requirements Installation from ansible-galaxy Example Playbooks License","title":"Ansible Collection For Arista Validated Designs - arista.avd"},{"location":"#roles-overview","text":"This repository provides roles for Ansible\u2019s collection arista.avd with the following content: arista.avd.eos_l3ls_evpn - Opinionated Data model for deployment of L3 Leaf and Spine Fabric with VXLAN data-plane with an EVPN Control plane. arista.avd.eos_cli_config_gen - Generate Arista EOS cli syntax and device documentation. arista.avd.eos_config_deploy_cvp - deploys intended configuration via CloudVision. arista.avd.eos_config_deploy_eapi - deploys intended configuration via eAPI. arista.avd.cvp_configlet_upload - Uploads configlets from a local folder to CloudVision Server.","title":"Roles Overview"},{"location":"#custom-plugins","text":"This repository provides custom plugins for Ansible\u2019s collection arista.avd : Arista AVD Plugins","title":"Custom Plugins"},{"location":"#installation","text":"","title":"Installation"},{"location":"#requirements","text":"Arista EOS: EOS 4.21.8M or later Roles validated with eAPI transport -> ansible_connection: httpapi Python: Python 3.6.8 or later Supported Ansible Versions: ansible 2.9.2 or later Additional Python Libraries required: Jinja2 2.10.3 netaddr 0.7.19 requests 2.22.0 treelib 1.5.5 pytest 5.3.4 pytest-html 2.0.1 Ansible + Additional Python Libraries Installation: pip3 install -r requirements.txt requirements.txt content: ansible==2.9.2 Jinja2==2.10.3 netaddr==0.7.19 requests==2.22.0 treelib==1.5.5 pytest==5.3.4 pytest-html==2.0.1 Ansible Configuration INI file: enable jinja2 extensions: loop controls and do Jinja2 Extensions Documentation By default, Ansible will issue a warning when a duplicate dict key is encountered in YAML. We recommend to change to error instead and stop playbook execution when a duplicate key is detected. jinja2_extensions = jinja2.ext.loopcontrols,jinja2.ext.do duplicate_dict_key = error","title":"Requirements"},{"location":"#installation-from-ansible-galaxy","text":"Ansible galaxy hosts all stable version of this collection. Installation from ansible-galaxy is the most convenient approach for consuming arista.avd content ansible-galaxy collection install arista.avd","title":"Installation from ansible-galaxy"},{"location":"#example-playbooks","text":"An example playbook to deploy VXLAN/EVPN Fabric via CloudVision: - hosts: DC1_FABRIC tasks: - name: generate intended variables import_role: name: arista.avd.eos_l3ls_evpn - name: generate device intended config and documentation import_role: name: arista.avd.eos_cli_config_gen - name: deploy configuration via CVP import_role: name: arista.avd.eos_config_deploy_cvp An example playbook to deploy VXLAN/EVPN Fabric via eAPI: - hosts: DC1_FABRIC tasks: - name: generate intended variables import_role: name: arista.avd.eos_l3ls_evpn - name: generate device intended config and documentation import_role: name: arista.avd.eos_cli_config_gen - name: deploy configuration to device import_role: name: arista.avd.eos_config_deploy_eapi Full examples with variables and outputs, are located here: Arista NetDevOps Examples","title":"Example Playbooks"},{"location":"#license","text":"Project is published under Apache 2.0 License","title":"License"},{"location":"docs/contributing/","text":"Contribute to Arista ansible-avd collection # Contribute to Arista ansible-avd collection Reporting Bugs Feature Requests Using the issue tracker Branches Pull requests Please take a moment to review this document in order to make the contribution process easy and effective for everyone involved. Following these guidelines helps to communicate that you respect the time of the developers managing and developing this open source project. In return, they should reciprocate that respect in addressing your issue or assessing patches and features. Reporting Bugs # First, ensure that you\u2019ve installed the latest stable version of ansible-avd . If you\u2019re running an older version, it\u2019s possible that the bug has already been fixed. Next, check the GitHub issues list to see if the bug you\u2019ve found has already been reported. If you think you may be experiencing a reported issue that hasn\u2019t already been resolved, please click \u201cadd a reaction\u201d in the top right corner of the issue and add a thumbs up (+1). You might also want to add a comment describing how it\u2019s affecting your installation. This will allow us to prioritize bugs based on how many users are affected. If you haven\u2019t found an existing issue that describes your suspected bug, Do not file an issue until you have received confirmation that it is in fact a bug. Invalid issues are very distracting and slow the pace at which ansible-avd is developed. When submitting an issue, please be as descriptive as possible. Be sure to include: The environment in which ansible-avd is running The exact steps that can be taken to reproduce the issue (if applicable) Any error messages generated Screenshots (if applicable) Please avoid prepending any sort of tag (e.g. \u201c[Bug]\u201d) to the issue title. The issue will be reviewed by a moderator after submission and the appropriate labels will be applied for categorization. Keep in mind that we prioritize bugs based on their severity and how much work is required to resolve them. It may take some time for someone to address your issue. Feature Requests # First, check the GitHub issues list to see if the feature you\u2019re requesting is already listed. (Be sure to search closed issues as well, since some feature requests have been rejected.) If the feature you\u2019d like to see has already been requested and is open, click \u201cadd a reaction\u201d in the top right corner of the issue and add a thumbs up (+1). This ensures that the issue has a better chance of receiving attention. Also feel free to add a comment with any additional justification for the feature. (However, note that comments with no substance other than a \u201c+1\u201d will be deleted. Please use GitHub\u2019s reactions feature to indicate your support.) Before filing a new feature request, consider raising your idea on the mailing list first. Feedback you receive there will help validate and shape the proposed feature before filing a formal issue. Good feature requests are very narrowly defined. Be sure to thoroughly describe the functionality and data model(s) being proposed. The more effort you put into writing a feature request, the better its chance is of being implemented. Overly broad feature requests will be closed. When submitting a feature request on GitHub, be sure to include the following: A detailed description of the proposed functionality A use case for the feature; who would use it and what value it would add to ansible-avd A rough description of changes necessary Any third-party libraries or other resources which would be involved Please avoid prepending any sort of tag (e.g. \u201c[Feature]\u201d) to the issue title. The issue will be reviewed by a moderator after submission and the appropriate labels will be applied for categorization. Using the issue tracker # The issue tracker is the preferred channel for bug reports , features requests and submitting pull requests , but please respect the following restrictions: Please do not use the issue tracker for personal support requests. Please do not derail or troll issues. Keep the discussion on topic and respect the opinions of others. Branches # Current development branch: releases/v1.0.x Stable branch: master Branch namespace for issues: issues/<IssueID>-<issue-name-shorten> Branch namespace for Feature: features/<IssueID>-<issue-name-shorten> Branch namespace for release & development: releases/<release_id> Pull requests # Be sure to open an issue before starting work on a pull request, and discuss your idea with the ansible-avd maintainers before beginning work. This will help prevent wasting time on something that might we might not be able to implement. When suggesting a new feature, also make sure it won\u2019t conflict with any work that\u2019s already in progress. Any pull request which does not relate to an accepted issue will be closed. All major new functionality must include relevant tests where applicable. When submitting a pull request, please be sure to work off of the releases/grant-v1.x branch, rather than master . The releases/grant-v1.x branch is used for ongoing development, while master is used for tagging new stable releases. All code submissions should meet the following criteria (CI will enforce these checks): YAML syntax is valid Python syntax is valid All tests pass when run with make sanity PEP 8 compliance is enforced, with the exception that lines may be greater than 80 characters in length Adhering to the following this process is the best way to get your work merged: Fork the repo, clone your fork, and configure the remotes: # Clone your fork of the repo into the current directory git clone https://github.com/<your-username>/ansible-avd # Navigate to the newly cloned directory cd ansible-avd # Assign the original repo to a remote called \"upstream\" git remote add upstream https://github.com/aristanetworks/ansible-avd.git If you cloned a while ago, get the latest changes from upstream: git checkout <dev-branch> git pull upstream <dev-branch> Create a new topic branch (off the main project development branch) to contain your feature, change, or fix: git checkout -b <topic-branch-name> Commit your changes in logical chunks. Please adhere to these git commit message guidelines or your code is unlikely be merged into the main project. Use Git\u2019s interactive rebase feature to tidy up your commits before making them public. Locally merge (or rebase) the upstream development branch into your topic branch: git pull [ --rebase ] upstream <dev-branch> Push your topic branch up to your fork: git push origin <topic-branch-name> Open a Pull Request with a clear title and description.","title":"Contribution Guide"},{"location":"docs/contributing/#contribute-to-arista-ansible-avd-collection","text":"Contribute to Arista ansible-avd collection Reporting Bugs Feature Requests Using the issue tracker Branches Pull requests Please take a moment to review this document in order to make the contribution process easy and effective for everyone involved. Following these guidelines helps to communicate that you respect the time of the developers managing and developing this open source project. In return, they should reciprocate that respect in addressing your issue or assessing patches and features.","title":"Contribute to Arista ansible-avd collection"},{"location":"docs/contributing/#reporting-bugs","text":"First, ensure that you\u2019ve installed the latest stable version of ansible-avd . If you\u2019re running an older version, it\u2019s possible that the bug has already been fixed. Next, check the GitHub issues list to see if the bug you\u2019ve found has already been reported. If you think you may be experiencing a reported issue that hasn\u2019t already been resolved, please click \u201cadd a reaction\u201d in the top right corner of the issue and add a thumbs up (+1). You might also want to add a comment describing how it\u2019s affecting your installation. This will allow us to prioritize bugs based on how many users are affected. If you haven\u2019t found an existing issue that describes your suspected bug, Do not file an issue until you have received confirmation that it is in fact a bug. Invalid issues are very distracting and slow the pace at which ansible-avd is developed. When submitting an issue, please be as descriptive as possible. Be sure to include: The environment in which ansible-avd is running The exact steps that can be taken to reproduce the issue (if applicable) Any error messages generated Screenshots (if applicable) Please avoid prepending any sort of tag (e.g. \u201c[Bug]\u201d) to the issue title. The issue will be reviewed by a moderator after submission and the appropriate labels will be applied for categorization. Keep in mind that we prioritize bugs based on their severity and how much work is required to resolve them. It may take some time for someone to address your issue.","title":"Reporting Bugs"},{"location":"docs/contributing/#feature-requests","text":"First, check the GitHub issues list to see if the feature you\u2019re requesting is already listed. (Be sure to search closed issues as well, since some feature requests have been rejected.) If the feature you\u2019d like to see has already been requested and is open, click \u201cadd a reaction\u201d in the top right corner of the issue and add a thumbs up (+1). This ensures that the issue has a better chance of receiving attention. Also feel free to add a comment with any additional justification for the feature. (However, note that comments with no substance other than a \u201c+1\u201d will be deleted. Please use GitHub\u2019s reactions feature to indicate your support.) Before filing a new feature request, consider raising your idea on the mailing list first. Feedback you receive there will help validate and shape the proposed feature before filing a formal issue. Good feature requests are very narrowly defined. Be sure to thoroughly describe the functionality and data model(s) being proposed. The more effort you put into writing a feature request, the better its chance is of being implemented. Overly broad feature requests will be closed. When submitting a feature request on GitHub, be sure to include the following: A detailed description of the proposed functionality A use case for the feature; who would use it and what value it would add to ansible-avd A rough description of changes necessary Any third-party libraries or other resources which would be involved Please avoid prepending any sort of tag (e.g. \u201c[Feature]\u201d) to the issue title. The issue will be reviewed by a moderator after submission and the appropriate labels will be applied for categorization.","title":"Feature Requests"},{"location":"docs/contributing/#using-the-issue-tracker","text":"The issue tracker is the preferred channel for bug reports , features requests and submitting pull requests , but please respect the following restrictions: Please do not use the issue tracker for personal support requests. Please do not derail or troll issues. Keep the discussion on topic and respect the opinions of others.","title":"Using the issue tracker"},{"location":"docs/contributing/#branches","text":"Current development branch: releases/v1.0.x Stable branch: master Branch namespace for issues: issues/<IssueID>-<issue-name-shorten> Branch namespace for Feature: features/<IssueID>-<issue-name-shorten> Branch namespace for release & development: releases/<release_id>","title":"Branches"},{"location":"docs/contributing/#pull-requests","text":"Be sure to open an issue before starting work on a pull request, and discuss your idea with the ansible-avd maintainers before beginning work. This will help prevent wasting time on something that might we might not be able to implement. When suggesting a new feature, also make sure it won\u2019t conflict with any work that\u2019s already in progress. Any pull request which does not relate to an accepted issue will be closed. All major new functionality must include relevant tests where applicable. When submitting a pull request, please be sure to work off of the releases/grant-v1.x branch, rather than master . The releases/grant-v1.x branch is used for ongoing development, while master is used for tagging new stable releases. All code submissions should meet the following criteria (CI will enforce these checks): YAML syntax is valid Python syntax is valid All tests pass when run with make sanity PEP 8 compliance is enforced, with the exception that lines may be greater than 80 characters in length Adhering to the following this process is the best way to get your work merged: Fork the repo, clone your fork, and configure the remotes: # Clone your fork of the repo into the current directory git clone https://github.com/<your-username>/ansible-avd # Navigate to the newly cloned directory cd ansible-avd # Assign the original repo to a remote called \"upstream\" git remote add upstream https://github.com/aristanetworks/ansible-avd.git If you cloned a while ago, get the latest changes from upstream: git checkout <dev-branch> git pull upstream <dev-branch> Create a new topic branch (off the main project development branch) to contain your feature, change, or fix: git checkout -b <topic-branch-name> Commit your changes in logical chunks. Please adhere to these git commit message guidelines or your code is unlikely be merged into the main project. Use Git\u2019s interactive rebase feature to tidy up your commits before making them public. Locally merge (or rebase) the upstream development branch into your topic branch: git pull [ --rebase ] upstream <dev-branch> Push your topic branch up to your fork: git push origin <topic-branch-name> Open a Pull Request with a clear title and description.","title":"Pull requests"},{"location":"docs/getting-started/","text":"Getting Started # An example playbook to deploy VXLAN/EVPN Fabric via CloudVision: - hosts: DC1_FABRIC tasks: - name: generate intended variables import_role: name: arista.avd.eos_l3ls_evpn - name: generate device intended config and documentation import_role: name: arista.avd.eos_cli_config_gen - name: deploy configuration via CVP import_role: name: arista.avd.eos_config_deploy_cvp An example playbook to deploy VXLAN/EVPN Fabric via eAPI: - hosts: DC1_FABRIC tasks: - name: generate intended variables import_role: name: arista.avd.eos_l3ls_evpn - name: generate device intended config and documentation import_role: name: arista.avd.eos_cli_config_gen - name: deploy configuration to device import_role: name: arista.avd.eos_config_deploy_eapi","title":"Getting Started"},{"location":"docs/getting-started/#getting-started","text":"An example playbook to deploy VXLAN/EVPN Fabric via CloudVision: - hosts: DC1_FABRIC tasks: - name: generate intended variables import_role: name: arista.avd.eos_l3ls_evpn - name: generate device intended config and documentation import_role: name: arista.avd.eos_cli_config_gen - name: deploy configuration via CVP import_role: name: arista.avd.eos_config_deploy_cvp An example playbook to deploy VXLAN/EVPN Fabric via eAPI: - hosts: DC1_FABRIC tasks: - name: generate intended variables import_role: name: arista.avd.eos_l3ls_evpn - name: generate device intended config and documentation import_role: name: arista.avd.eos_cli_config_gen - name: deploy configuration to device import_role: name: arista.avd.eos_config_deploy_eapi","title":"Getting Started"},{"location":"docs/installation/development/","text":"Development Process # Development Process Overview Getting started Script Step by step installation process One liner installation Build local environment Docker Container for Ansible Testing and Development Development containers Container commands Python Virtual Environment Install Python3 Virtual Environment Development & test tools Pre-commit hook Installation Run pre-commit manually Configure git hook Overview # Two methods can be used get Ansible up and running quickly with all the requirements to leverage ansible-avd. A Python Virtual Environment or Docker container. The best way to use the development files, is to copy them to the root directory where you have your repositories cloned. For example, see the file/folder structure below. \u251c\u2500\u2500 git_projects \u2502 \u251c\u2500\u2500 ansible-avd \u2502 \u251c\u2500\u2500 ansible-cvp \u2502 \u251c\u2500\u2500 ansible-avd-cloudvision-demo \u2502 \u251c\u2500\u2500 <your-own-test-folder> \u2502 \u251c\u2500\u2500 Makefile ... Getting started Script # Step by step installation process # mkdir git_projects cd git_projects git clone https://github.com/aristanetworks/ansible-avd.git git clone https://github.com/aristanetworks/ansible-cvp.git git clone https://github.com/arista-netdevops-community/ansible-avd-cloudvision-demo.git cp ansible-avd/development/Makefile ./ make run One liner installation # One liner script to setup a development environment. it does following actions: Create local folder for development Instantiate a local git repository (no remote) Clone AVD and CVP collections Deploy Makefile $ sh -c \" $( curl -fsSL https://raw.githubusercontent.com/aristanetworks/ansible-avd/devel/development/install.sh ) \" Build local environment # Docker Container for Ansible Testing and Development # The docker container approach for development can be used to ensure that everybody is using the same development environment while still being flexible enough to use the repo you are making changes in. You can inspect the Dockerfile to see what packages have been installed. The container will mount the current working directory, so you can work with your local files. The ansible version is passed in with the docker build command using ANSIBLE variable. If the ANSIBLE variable is not used the Dockerfile will by default set the ansible version to 2.9.2 Before you can use a container, you must install Docker CE and docker-compose on your workstation. Development containers # Ansible shell : provide a built-in container with all AVD and CVP requirements already installed. MKDOCS for documentation update: Run MKDOCS in a container and expose port 8000 to test and validate markdown rendering for AVD site. Container commands # In this folder you have a Makefile providing a list of commands to start a development environment: run : Start a shell within a container and local folder mounted in /projects dev-start : Start a stack of containers based on docker-compose: 1 container for ansible playbooks and 1 container for mkdocs dev-stop : Stop compose stack and remove containers. dev-run : Connect to ansible container to run your test playbooks. dev-reload : Run stop and start. If you want to test a specific ansible version, you can refer to this dedicated page to start your own docker image. You can also use following make command: make ANSIBLE_VERSION=2.9.3 run Since docker image is now automatically published on docker-hub , a dedicated repository is available on Arista Netdevops Community . Python Virtual Environment # Install Python3 Virtual Environment # # install virtualenv via pip3 $ sudo pip3 install virtualenv ... # Configure Python virtual environment $ virtualenv -p python3 .venv $ source .venv/bin/activate # Install Python requirements $ pip install -r requirements.txt Development & test tools # Pre-commit hook # pre-commit can run standard hooks on every commit to automatically point out issues in code such as missing semicolons, trailing whitespace, and debug statements. By pointing these issues out before code review, this allows a code reviewer to focus on the architecture of a change while not wasting time with trivial style nitpicks. Repository implements following hooks: trailing-whitespace : Fix trailing whitespace. if found, commit is stopped and you must run commit process again. end-of-file-fixer : Like trailing-whitespace , this hook fix wrong end of file and stop your commit. check-yaml : Check all YAML files ares valid check-added-large-files : Check if there is no large file included in repository check-merge-conflict : Validate there is no MERGE syntax related to a invalid merge process. pylint : Run python linting with settings defined in pylintrc yamllint : Validate all YAML files using configuration from yamllintrc ansible-lint : Validate yaml files are valid against ansible rules. Installation # pre-commit is part of developement requirememnts . To install, run pip command : $ pip install -r requirements-dev.txt ... Run pre-commit manually # To run pre-commit manually before your commit, use this command: pre-commit run [ WARNING ] Unstaged files detected. [ INFO ] Stashing unstaged files to /Users/xxx/.cache/pre-commit/patch1590742434. Trim Trailing Whitespace............................. ( no files to check ) Skipped Fix End of Files..................................... ( no files to check ) Skipped Check Yaml........................................... ( no files to check ) Skipped Check for added large files.......................... ( no files to check ) Skipped Check for merge conflicts............................ ( no files to check ) Skipped Check for Linting error on Python files.............. ( no files to check ) Skipped Check for Linting error on YAML files................ ( no files to check ) Skipped Check for ansible-lint errors............................................Passed [ INFO ] Restored changes from /Users/xxx/.cache/pre-commit/patch1590742434. Command will automatically detect changed files using git status and run tests according their type. Configure git hook # To automatically run tests when running a commit, configure your repository whit command: $ pre-commit install pre-commit installed at .git/hooks/pre-commit To remove installation, use uninstall option.","title":"Configure development environment"},{"location":"docs/installation/development/#development-process","text":"Development Process Overview Getting started Script Step by step installation process One liner installation Build local environment Docker Container for Ansible Testing and Development Development containers Container commands Python Virtual Environment Install Python3 Virtual Environment Development & test tools Pre-commit hook Installation Run pre-commit manually Configure git hook","title":"Development Process"},{"location":"docs/installation/development/#overview","text":"Two methods can be used get Ansible up and running quickly with all the requirements to leverage ansible-avd. A Python Virtual Environment or Docker container. The best way to use the development files, is to copy them to the root directory where you have your repositories cloned. For example, see the file/folder structure below. \u251c\u2500\u2500 git_projects \u2502 \u251c\u2500\u2500 ansible-avd \u2502 \u251c\u2500\u2500 ansible-cvp \u2502 \u251c\u2500\u2500 ansible-avd-cloudvision-demo \u2502 \u251c\u2500\u2500 <your-own-test-folder> \u2502 \u251c\u2500\u2500 Makefile ...","title":"Overview"},{"location":"docs/installation/development/#getting-started-script","text":"","title":"Getting started Script"},{"location":"docs/installation/development/#step-by-step-installation-process","text":"mkdir git_projects cd git_projects git clone https://github.com/aristanetworks/ansible-avd.git git clone https://github.com/aristanetworks/ansible-cvp.git git clone https://github.com/arista-netdevops-community/ansible-avd-cloudvision-demo.git cp ansible-avd/development/Makefile ./ make run","title":"Step by step installation process"},{"location":"docs/installation/development/#one-liner-installation","text":"One liner script to setup a development environment. it does following actions: Create local folder for development Instantiate a local git repository (no remote) Clone AVD and CVP collections Deploy Makefile $ sh -c \" $( curl -fsSL https://raw.githubusercontent.com/aristanetworks/ansible-avd/devel/development/install.sh ) \"","title":"One liner installation"},{"location":"docs/installation/development/#build-local-environment","text":"","title":"Build local environment"},{"location":"docs/installation/development/#docker-container-for-ansible-testing-and-development","text":"The docker container approach for development can be used to ensure that everybody is using the same development environment while still being flexible enough to use the repo you are making changes in. You can inspect the Dockerfile to see what packages have been installed. The container will mount the current working directory, so you can work with your local files. The ansible version is passed in with the docker build command using ANSIBLE variable. If the ANSIBLE variable is not used the Dockerfile will by default set the ansible version to 2.9.2 Before you can use a container, you must install Docker CE and docker-compose on your workstation.","title":"Docker Container for Ansible Testing and Development"},{"location":"docs/installation/development/#development-containers","text":"Ansible shell : provide a built-in container with all AVD and CVP requirements already installed. MKDOCS for documentation update: Run MKDOCS in a container and expose port 8000 to test and validate markdown rendering for AVD site.","title":"Development containers"},{"location":"docs/installation/development/#container-commands","text":"In this folder you have a Makefile providing a list of commands to start a development environment: run : Start a shell within a container and local folder mounted in /projects dev-start : Start a stack of containers based on docker-compose: 1 container for ansible playbooks and 1 container for mkdocs dev-stop : Stop compose stack and remove containers. dev-run : Connect to ansible container to run your test playbooks. dev-reload : Run stop and start. If you want to test a specific ansible version, you can refer to this dedicated page to start your own docker image. You can also use following make command: make ANSIBLE_VERSION=2.9.3 run Since docker image is now automatically published on docker-hub , a dedicated repository is available on Arista Netdevops Community .","title":"Container commands"},{"location":"docs/installation/development/#python-virtual-environment","text":"","title":"Python Virtual Environment"},{"location":"docs/installation/development/#install-python3-virtual-environment","text":"# install virtualenv via pip3 $ sudo pip3 install virtualenv ... # Configure Python virtual environment $ virtualenv -p python3 .venv $ source .venv/bin/activate # Install Python requirements $ pip install -r requirements.txt","title":"Install Python3 Virtual Environment"},{"location":"docs/installation/development/#development-test-tools","text":"","title":"Development &amp; test tools"},{"location":"docs/installation/development/#pre-commit-hook","text":"pre-commit can run standard hooks on every commit to automatically point out issues in code such as missing semicolons, trailing whitespace, and debug statements. By pointing these issues out before code review, this allows a code reviewer to focus on the architecture of a change while not wasting time with trivial style nitpicks. Repository implements following hooks: trailing-whitespace : Fix trailing whitespace. if found, commit is stopped and you must run commit process again. end-of-file-fixer : Like trailing-whitespace , this hook fix wrong end of file and stop your commit. check-yaml : Check all YAML files ares valid check-added-large-files : Check if there is no large file included in repository check-merge-conflict : Validate there is no MERGE syntax related to a invalid merge process. pylint : Run python linting with settings defined in pylintrc yamllint : Validate all YAML files using configuration from yamllintrc ansible-lint : Validate yaml files are valid against ansible rules.","title":"Pre-commit hook"},{"location":"docs/installation/development/#installation","text":"pre-commit is part of developement requirememnts . To install, run pip command : $ pip install -r requirements-dev.txt ...","title":"Installation"},{"location":"docs/installation/development/#run-pre-commit-manually","text":"To run pre-commit manually before your commit, use this command: pre-commit run [ WARNING ] Unstaged files detected. [ INFO ] Stashing unstaged files to /Users/xxx/.cache/pre-commit/patch1590742434. Trim Trailing Whitespace............................. ( no files to check ) Skipped Fix End of Files..................................... ( no files to check ) Skipped Check Yaml........................................... ( no files to check ) Skipped Check for added large files.......................... ( no files to check ) Skipped Check for merge conflicts............................ ( no files to check ) Skipped Check for Linting error on Python files.............. ( no files to check ) Skipped Check for Linting error on YAML files................ ( no files to check ) Skipped Check for ansible-lint errors............................................Passed [ INFO ] Restored changes from /Users/xxx/.cache/pre-commit/patch1590742434. Command will automatically detect changed files using git status and run tests according their type.","title":"Run pre-commit manually"},{"location":"docs/installation/development/#configure-git-hook","text":"To automatically run tests when running a commit, configure your repository whit command: $ pre-commit install pre-commit installed at .git/hooks/pre-commit To remove installation, use uninstall option.","title":"Configure git hook"},{"location":"docs/installation/requirements/","text":"Requirements # Arista EOS: EOS 4.21.8M or later Roles validated with eAPI transport -> ansible_connection: httpapi Python: Python 3.6.8 or later Supported Ansible Versions: ansible 2.9.2 or later Additional Python Libraries required: Jinja2 2.10.3 netaddr 0.7.19 requests 2.22.0 treelib 1.5.5 pytest 5.3.4 pytest-html 2.0.1 Ansible + Additional Python Libraries Installation: pip3 install -r development/requirements.txt requirements.txt content: ansible==2.9.2 Jinja2==2.10.3 netaddr==0.7.19 requests==2.22.0 treelib==1.5.5 pytest==5.3.4 pytest-html==2.0.1","title":"Requirements"},{"location":"docs/installation/requirements/#requirements","text":"Arista EOS: EOS 4.21.8M or later Roles validated with eAPI transport -> ansible_connection: httpapi Python: Python 3.6.8 or later Supported Ansible Versions: ansible 2.9.2 or later Additional Python Libraries required: Jinja2 2.10.3 netaddr 0.7.19 requests 2.22.0 treelib 1.5.5 pytest 5.3.4 pytest-html 2.0.1 Ansible + Additional Python Libraries Installation: pip3 install -r development/requirements.txt requirements.txt content: ansible==2.9.2 Jinja2==2.10.3 netaddr==0.7.19 requests==2.22.0 treelib==1.5.5 pytest==5.3.4 pytest-html==2.0.1","title":"Requirements"},{"location":"docs/installation/setup-galaxy/","text":"Collection installation via ansible-galaxy # Install from Ansible Galaxy # arista.avd collection is available on Ansible Galaxy server and can be automatically installed on your system. Latest version # $ ansible-galaxy collection install arista.avd Install specific version # $ ansible-galaxy collection install arista.avd: == 1 .0.2 Install in specific directory # If you want to install collection in a specific directory part of your project, you can call ansible-galaxy and update your ansible.cfg # Install collection under ${PWD/collections/} $ ansible-galaxy collection install arista.avd -p collections/ # Update ansible.cfg file $ vim ansible.cfg collections_paths = ${ PWD } /collections:~/.ansible/collections:/usr/share/ansible/collections","title":"Ansible-galaxy installation"},{"location":"docs/installation/setup-galaxy/#collection-installation-via-ansible-galaxy","text":"","title":"Collection installation via ansible-galaxy"},{"location":"docs/installation/setup-galaxy/#install-from-ansible-galaxy","text":"arista.avd collection is available on Ansible Galaxy server and can be automatically installed on your system.","title":"Install from Ansible Galaxy"},{"location":"docs/installation/setup-galaxy/#latest-version","text":"$ ansible-galaxy collection install arista.avd","title":"Latest version"},{"location":"docs/installation/setup-galaxy/#install-specific-version","text":"$ ansible-galaxy collection install arista.avd: == 1 .0.2","title":"Install specific version"},{"location":"docs/installation/setup-galaxy/#install-in-specific-directory","text":"If you want to install collection in a specific directory part of your project, you can call ansible-galaxy and update your ansible.cfg # Install collection under ${PWD/collections/} $ ansible-galaxy collection install arista.avd -p collections/ # Update ansible.cfg file $ vim ansible.cfg collections_paths = ${ PWD } /collections:~/.ansible/collections:/usr/share/ansible/collections","title":"Install in specific directory"},{"location":"docs/installation/setup-git/","text":"Installation using GIT # Build & install collection from git # In this approach, an ansible collection package is built from current git version and installed locally. Clone repository # $ git clone https://github.com/aristanetworks/ansible-avd.git $ cd ansible-avd Build and install collection # $ ansible-galaxy collection build --force ansible_collections/arista/avd $ ansible-galaxy collection install arista-avd-<VERSION>.tar.gz Use Git as source of collection # In this setup, git repository will be used by ansible as collection. It is useful when working on feature development as we can change git branch and test code lively. Clone repository # # Clone repository $ git clone https://github.com/aristanetworks/ansible-avd.git # Move to git folder cd ansible-avd Install python virtual-environment # # Install virtualenv if not part of your system $ python -m pip3 install virtualenv Create virtual environment # # Create a virtual env named .venv $ virtualenv --no-site-packages -p $( which python3 ) .venv # Activate virtualenv $ source .venv/bin/activate Install collection requirements # # Install repsoitory requirements $ pip install -r development/requirements.txt Update your ansible.cfg # In your project, update your ansible.cfg file to point collection_paths to your local version of ansible-avd # Get your current location $ pwd /path/to/ansible/avd/collection_repository # Update your ansible.cfg $ vim ansible.cfg collections_paths = /path/to/ansible/avd/collection_repository","title":"Git installation"},{"location":"docs/installation/setup-git/#installation-using-git","text":"","title":"Installation using GIT"},{"location":"docs/installation/setup-git/#build-install-collection-from-git","text":"In this approach, an ansible collection package is built from current git version and installed locally.","title":"Build &amp; install collection from git"},{"location":"docs/installation/setup-git/#clone-repository","text":"$ git clone https://github.com/aristanetworks/ansible-avd.git $ cd ansible-avd","title":"Clone repository"},{"location":"docs/installation/setup-git/#build-and-install-collection","text":"$ ansible-galaxy collection build --force ansible_collections/arista/avd $ ansible-galaxy collection install arista-avd-<VERSION>.tar.gz","title":"Build and install collection"},{"location":"docs/installation/setup-git/#use-git-as-source-of-collection","text":"In this setup, git repository will be used by ansible as collection. It is useful when working on feature development as we can change git branch and test code lively.","title":"Use Git as source of collection"},{"location":"docs/installation/setup-git/#clone-repository_1","text":"# Clone repository $ git clone https://github.com/aristanetworks/ansible-avd.git # Move to git folder cd ansible-avd","title":"Clone repository"},{"location":"docs/installation/setup-git/#install-python-virtual-environment","text":"# Install virtualenv if not part of your system $ python -m pip3 install virtualenv","title":"Install python virtual-environment"},{"location":"docs/installation/setup-git/#create-virtual-environment","text":"# Create a virtual env named .venv $ virtualenv --no-site-packages -p $( which python3 ) .venv # Activate virtualenv $ source .venv/bin/activate","title":"Create virtual environment"},{"location":"docs/installation/setup-git/#install-collection-requirements","text":"# Install repsoitory requirements $ pip install -r development/requirements.txt","title":"Install collection requirements"},{"location":"docs/installation/setup-git/#update-your-ansiblecfg","text":"In your project, update your ansible.cfg file to point collection_paths to your local version of ansible-avd # Get your current location $ pwd /path/to/ansible/avd/collection_repository # Update your ansible.cfg $ vim ansible.cfg collections_paths = /path/to/ansible/avd/collection_repository","title":"Update your ansible.cfg"},{"location":"docs/modules/","text":"Modules documentation #","title":"Modules documentation"},{"location":"docs/modules/#modules-documentation","text":"","title":"Modules documentation"},{"location":"docs/modules/configlet_build_config.rst/","text":"configlet_build_config # Build arista.cvp.configlet configuration. Module added in version 2.9 Synopsis # Build configuration to publish configlets on Cloudvision. Module-specific Options # The following options may be specified for this module: parameter type required default choices comments configlet_dir str yes Directory where configlets are located. configlet_extension str no conf File extensio to look for. configlet_prefix str yes Prefix to append on configlet. destination str no File where to save information. Examples: # # tasks file for cvp_configlet_upload - name: generate intented variables tags: [build, provision] configlet_build_config: configlet_dir: ' {{ configlet_dir }} ' configlet_prefix: ' {{ configlets_prefix }} ' configlet_extension: ' {{ configlet_extension }} ' Author # EMEA AS Team (@aristanetworks) Status # This module is flagged as preview which means that it is not guaranteed to have a backwards compatible interface.","title":"Module Configlet Build configuration"},{"location":"docs/modules/configlet_build_config.rst/#configlet_build_config","text":"Build arista.cvp.configlet configuration. Module added in version 2.9","title":"configlet_build_config"},{"location":"docs/modules/configlet_build_config.rst/#synopsis","text":"Build configuration to publish configlets on Cloudvision.","title":"Synopsis"},{"location":"docs/modules/configlet_build_config.rst/#module-specific-options","text":"The following options may be specified for this module: parameter type required default choices comments configlet_dir str yes Directory where configlets are located. configlet_extension str no conf File extensio to look for. configlet_prefix str yes Prefix to append on configlet. destination str no File where to save information.","title":"Module-specific Options"},{"location":"docs/modules/configlet_build_config.rst/#examples","text":"# tasks file for cvp_configlet_upload - name: generate intented variables tags: [build, provision] configlet_build_config: configlet_dir: ' {{ configlet_dir }} ' configlet_prefix: ' {{ configlets_prefix }} ' configlet_extension: ' {{ configlet_extension }} '","title":"Examples:"},{"location":"docs/modules/configlet_build_config.rst/#author","text":"EMEA AS Team (@aristanetworks)","title":"Author"},{"location":"docs/modules/configlet_build_config.rst/#status","text":"This module is flagged as preview which means that it is not guaranteed to have a backwards compatible interface.","title":"Status"},{"location":"docs/modules/index.rst/","text":"Arista Cloudvision Ansible Modules # Collection Overview \\ < ../README.md\\> DHCP Configuration \\ < ../ansible\\_collections/arista/cvp/roles/dhcp\\_configuration/README.md\\> Module arista.cvp.configlet\\_build\\_config \\ Module arista.cvp.inventory\\_to\\_container \\","title":"Arista Cloudvision Ansible Modules"},{"location":"docs/modules/index.rst/#arista-cloudvision-ansible-modules","text":"Collection Overview \\ < ../README.md\\> DHCP Configuration \\ < ../ansible\\_collections/arista/cvp/roles/dhcp\\_configuration/README.md\\> Module arista.cvp.configlet\\_build\\_config \\ Module arista.cvp.inventory\\_to\\_container \\","title":"Arista Cloudvision Ansible Modules"},{"location":"docs/modules/inventory_to_container.rst/","text":"inventory_to_container # Transform information from inventory to arista.cvp collection Module added in version 2.9 Synopsis # Transform information from ansible inventory to be able to provision CloudVision Platform using arista.cvp collection and its specific data structure. Module-specific Options # The following options may be specified for this module: parameter type required default choices comments configlet_dir str no Directory where intended configurations are located. configlet_prefix str no Prefix to put on configlet. container_root str yes Ansible group name to consider to be Root of our topology. destination str no Optional path to save variable. device_filter list no ['all'] Filter to apply intended mode on a set of configlet. If not used, then module only uses ADD mode. device_filter list devices that can be modified or deleted based on configlets entries. inventory str yes YAML inventory file Examples: # - name: generate intented variables inventory_to_container: inventory: 'inventory.yml' container_root: 'DC1_FABRIC' configlet_dir: 'intended_configs' configlet_prefix: 'AVD' device_filter: ['DC1-LE'] # destination: 'generated_vars/ {{ inventory_hostname }} .yml' register: CVP_VARS - name: 'Collecting facts from CVP {{ inventory_hostname }} .' arista.cvp.cv_facts: register: CVP_FACTS - name: 'Create configlets on CVP {{ inventory_hostname }} .' arista.cvp.cv_configlet: cvp_facts: \" {{ CVP_FACTS.ansible_facts }} \" configlets: \" {{ CVP_VARS.CVP_CONFIGLETS }} \" configlet_filter: [\"AVD\"] - name: \"Building Container topology on {{ inventory_hostname }} \" arista.cvp.cv_container: topology: ' {{ CVP_VARS.CVP_TOPOLOGY }} ' cvp_facts: ' {{ CVP_FACTS.ansible_facts }} ' save_topology: true Author # Ansible Arista Team (@aristanetworks) Status # This module is flagged as preview which means that it is not guaranteed to have a backwards compatible interface.","title":"Module Inventory to containers"},{"location":"docs/modules/inventory_to_container.rst/#inventory_to_container","text":"Transform information from inventory to arista.cvp collection Module added in version 2.9","title":"inventory_to_container"},{"location":"docs/modules/inventory_to_container.rst/#synopsis","text":"Transform information from ansible inventory to be able to provision CloudVision Platform using arista.cvp collection and its specific data structure.","title":"Synopsis"},{"location":"docs/modules/inventory_to_container.rst/#module-specific-options","text":"The following options may be specified for this module: parameter type required default choices comments configlet_dir str no Directory where intended configurations are located. configlet_prefix str no Prefix to put on configlet. container_root str yes Ansible group name to consider to be Root of our topology. destination str no Optional path to save variable. device_filter list no ['all'] Filter to apply intended mode on a set of configlet. If not used, then module only uses ADD mode. device_filter list devices that can be modified or deleted based on configlets entries. inventory str yes YAML inventory file","title":"Module-specific Options"},{"location":"docs/modules/inventory_to_container.rst/#examples","text":"- name: generate intented variables inventory_to_container: inventory: 'inventory.yml' container_root: 'DC1_FABRIC' configlet_dir: 'intended_configs' configlet_prefix: 'AVD' device_filter: ['DC1-LE'] # destination: 'generated_vars/ {{ inventory_hostname }} .yml' register: CVP_VARS - name: 'Collecting facts from CVP {{ inventory_hostname }} .' arista.cvp.cv_facts: register: CVP_FACTS - name: 'Create configlets on CVP {{ inventory_hostname }} .' arista.cvp.cv_configlet: cvp_facts: \" {{ CVP_FACTS.ansible_facts }} \" configlets: \" {{ CVP_VARS.CVP_CONFIGLETS }} \" configlet_filter: [\"AVD\"] - name: \"Building Container topology on {{ inventory_hostname }} \" arista.cvp.cv_container: topology: ' {{ CVP_VARS.CVP_TOPOLOGY }} ' cvp_facts: ' {{ CVP_FACTS.ansible_facts }} ' save_topology: true","title":"Examples:"},{"location":"docs/modules/inventory_to_container.rst/#author","text":"Ansible Arista Team (@aristanetworks)","title":"Author"},{"location":"docs/modules/inventory_to_container.rst/#status","text":"This module is flagged as preview which means that it is not guaranteed to have a backwards compatible interface.","title":"Status"},{"location":"molecule/","text":"AVD Unit test # This section provides a list of AVD scenario executed during Continuous Integration to validate AVD integration. AVD Unit test Ansible molecule Scenario Create Molecule scenario Create molecule structure Configure Molecule Ansible playbook for molecule Create playbook Converge playbook Destroy playbook Verify playbook Inventory creation Manual execution Continuous Integration Ansible molecule # Molecule provides support for testing with multiple instances, operating systems and distributions, virtualization providers, test frameworks and testing scenarios. Molecule encourages an approach that results in consistently developed roles that are well-written, easily understood and maintained. Scenario # Current molecule implementation provides following scenario: AVD-L3LS-EBGP AVD-L3LS-EBGP-JSON AVD-L3LS-ISIS EOS-CLI-CONFIG-GEN Create Molecule scenario # Create molecule structure # First create new molecule scenario: $ molecule init scenario test --> Initializing new scenario test... Initialized scenario in ./molecule/test successfully. Configure Molecule # Once, default structure is created by molecule itself, you can customize your molecule settings to define: Inventory Scenario execution Provisioner content Verifier content First, let\u2019s define docker as molecule driver: # vim molecule.yml dependency : name : galaxy driver : name : docker Define inventory for provisioner. This section will run a playbook to build AVD configurations # vim molecule.yml provisioner : name : ansible env : # Path to access to collection. Usually root of the repository ANSIBLE_COLLECTIONS_PATHS : '../../../../../' # Replicate specific ansible.cfg settings config_options : defaults : jinja2_extensions : 'jinja2.ext.loopcontrols,jinja2.ext.do,jinja2.ext.i18n' gathering : explicit command_warnings : False # Define where inventory file is defined inventory : links : hosts : 'inventory/hosts' group_vars : 'inventory/group_vars/' host_vars : 'inventory/host_vars/' ansible_args : - --inventory=inventory/hosts Then we should define a platform to run molecule testing. In AVD context, this platform should be a device part of testing inventory platforms: - name: DC1-LEAF1A # Docker image to run for that host image: avdteam/base:3.6 pre_build_image: true managed: false # Inventory group for this specific host. groups: - DC1_LEAF1 - DC1_LEAFS - DC1_FABRIC - AVD_LAB Then, configure sequence to run during molecule execution: scenario : test_sequence : - destroy - create - converge - idempotence In this configuration, molecule will run playbooks in that specific order: destroy: destroy.yml playbook create: create.yml playbook converge: converge.yml playbook idempotency: converge.yml playbook with no change expected. Molecule provides more sequences as explained in documentation Ansible playbook for molecule # Create playbook # This playbook is a helper to prepare converge and test sequences. In AVD context, we leverage this playbook to build output directories: --- - name : Configure local folders hosts : all gather_facts : false connection : local tasks : - name : create local output folders delegate_to : 127.0.0.1 import_role : name : arista.avd.build_output_folders run_once : true Converge playbook # This playbook builds AVD content: --- - name : Converge hosts : all gather_facts : false connection : local tasks : - name : generate intented variables delegate_to : 127.0.0.1 import_role : name : arista.avd.eos_l3ls_evpn - name : generate device intended config and documention delegate_to : 127.0.0.1 import_role : name : arista.avd.eos_cli_config_gen This playbook will be run twice: first as converge sequence and second as idempotency Destroy playbook # Because we want to save content to CI, this sequence should not be added to the end of the scenario but only at the begining to cleanup pre-execution. --- - name : Remove output folders hosts : all gather_facts : false connection : local tasks : - name : delete local folders delegate_to : 127.0.0.1 run_once : true file : path : \"{{root_dir}}/{{ item }}\" state : absent with_items : - documentation - intended - config_backup Verify playbook # Not leverage in current implementation. Inventory creation # Inventory has no difference with AVD documentation provides: inventory/hosts has list of devices using YAML structure. inventory/group_vars has list of all AVD variables inventory/host_vars/all.yml configure a specific variable to save all AVD output outside of inventory fo CI purpose # inventory/host_vars/all.yml --- root_dir : '{{playbook_dir}}' Manual execution # To manually run molecule testing, follow commands: # Install development requirements $ pip install -r development/requirements-dev.txt # Move to AVD collection $ ansible-avd/ansible_collections/arista/avd # Run molecule for a given test $ molecule test -s <scenario-name> # Run molecule for all test $ molecule test --all Continuous Integration # These scenario are all included in github actions and executed on push and pull_request when a file under roles and/or molecule is updated. name : Ansible Molecule on : push : pull_request : paths : - 'ansible_collections/arista/avd/roles/**' - 'ansible_collections/arista/avd/molecules/**' - 'requirements.txt' jobs : molecule : runs-on : ubuntu-latest env : PY_COLORS : 1 # allows molecule colors to be passed to GitHub Actions ANSIBLE_FORCE_COLOR : 1 # allows ansible colors to be passed to GitHub Actions strategy : fail-fast : true matrix : avd_scenario : - 'avd-l3ls-ebgp' - 'avd-l3ls-ebgp-json' - 'avd-l3ls-isis' - 'eos-cli-config-gen' steps : - uses : actions/checkout@v1 - name : Set up Python 3 uses : actions/setup-python@v1 with : python-version : '3.x' - name : Install dependencies run : | python -m pip install --upgrade pip pip install -r development/requirements.txt pip install -r development/requirements-dev.txt - name : Execute molecule run : | cd ansible_collections/arista/avd molecule test --scenario-name ${{ matrix.avd_scenario }} - uses : actions/upload-artifact@v1 with : name : molecule-results-${{ matrix.avd_scenario }} path : ansible_collections/arista/avd/molecule/${{ matrix.avd_scenario }}","title":"AVD Unit test"},{"location":"molecule/#avd-unit-test","text":"This section provides a list of AVD scenario executed during Continuous Integration to validate AVD integration. AVD Unit test Ansible molecule Scenario Create Molecule scenario Create molecule structure Configure Molecule Ansible playbook for molecule Create playbook Converge playbook Destroy playbook Verify playbook Inventory creation Manual execution Continuous Integration","title":"AVD Unit test"},{"location":"molecule/#ansible-molecule","text":"Molecule provides support for testing with multiple instances, operating systems and distributions, virtualization providers, test frameworks and testing scenarios. Molecule encourages an approach that results in consistently developed roles that are well-written, easily understood and maintained.","title":"Ansible molecule"},{"location":"molecule/#scenario","text":"Current molecule implementation provides following scenario: AVD-L3LS-EBGP AVD-L3LS-EBGP-JSON AVD-L3LS-ISIS EOS-CLI-CONFIG-GEN","title":"Scenario"},{"location":"molecule/#create-molecule-scenario","text":"","title":"Create Molecule scenario"},{"location":"molecule/#create-molecule-structure","text":"First create new molecule scenario: $ molecule init scenario test --> Initializing new scenario test... Initialized scenario in ./molecule/test successfully.","title":"Create molecule structure"},{"location":"molecule/#configure-molecule","text":"Once, default structure is created by molecule itself, you can customize your molecule settings to define: Inventory Scenario execution Provisioner content Verifier content First, let\u2019s define docker as molecule driver: # vim molecule.yml dependency : name : galaxy driver : name : docker Define inventory for provisioner. This section will run a playbook to build AVD configurations # vim molecule.yml provisioner : name : ansible env : # Path to access to collection. Usually root of the repository ANSIBLE_COLLECTIONS_PATHS : '../../../../../' # Replicate specific ansible.cfg settings config_options : defaults : jinja2_extensions : 'jinja2.ext.loopcontrols,jinja2.ext.do,jinja2.ext.i18n' gathering : explicit command_warnings : False # Define where inventory file is defined inventory : links : hosts : 'inventory/hosts' group_vars : 'inventory/group_vars/' host_vars : 'inventory/host_vars/' ansible_args : - --inventory=inventory/hosts Then we should define a platform to run molecule testing. In AVD context, this platform should be a device part of testing inventory platforms: - name: DC1-LEAF1A # Docker image to run for that host image: avdteam/base:3.6 pre_build_image: true managed: false # Inventory group for this specific host. groups: - DC1_LEAF1 - DC1_LEAFS - DC1_FABRIC - AVD_LAB Then, configure sequence to run during molecule execution: scenario : test_sequence : - destroy - create - converge - idempotence In this configuration, molecule will run playbooks in that specific order: destroy: destroy.yml playbook create: create.yml playbook converge: converge.yml playbook idempotency: converge.yml playbook with no change expected. Molecule provides more sequences as explained in documentation","title":"Configure Molecule"},{"location":"molecule/#ansible-playbook-for-molecule","text":"","title":"Ansible playbook for molecule"},{"location":"molecule/#create-playbook","text":"This playbook is a helper to prepare converge and test sequences. In AVD context, we leverage this playbook to build output directories: --- - name : Configure local folders hosts : all gather_facts : false connection : local tasks : - name : create local output folders delegate_to : 127.0.0.1 import_role : name : arista.avd.build_output_folders run_once : true","title":"Create playbook"},{"location":"molecule/#converge-playbook","text":"This playbook builds AVD content: --- - name : Converge hosts : all gather_facts : false connection : local tasks : - name : generate intented variables delegate_to : 127.0.0.1 import_role : name : arista.avd.eos_l3ls_evpn - name : generate device intended config and documention delegate_to : 127.0.0.1 import_role : name : arista.avd.eos_cli_config_gen This playbook will be run twice: first as converge sequence and second as idempotency","title":"Converge playbook"},{"location":"molecule/#destroy-playbook","text":"Because we want to save content to CI, this sequence should not be added to the end of the scenario but only at the begining to cleanup pre-execution. --- - name : Remove output folders hosts : all gather_facts : false connection : local tasks : - name : delete local folders delegate_to : 127.0.0.1 run_once : true file : path : \"{{root_dir}}/{{ item }}\" state : absent with_items : - documentation - intended - config_backup","title":"Destroy playbook"},{"location":"molecule/#verify-playbook","text":"Not leverage in current implementation.","title":"Verify playbook"},{"location":"molecule/#inventory-creation","text":"Inventory has no difference with AVD documentation provides: inventory/hosts has list of devices using YAML structure. inventory/group_vars has list of all AVD variables inventory/host_vars/all.yml configure a specific variable to save all AVD output outside of inventory fo CI purpose # inventory/host_vars/all.yml --- root_dir : '{{playbook_dir}}'","title":"Inventory creation"},{"location":"molecule/#manual-execution","text":"To manually run molecule testing, follow commands: # Install development requirements $ pip install -r development/requirements-dev.txt # Move to AVD collection $ ansible-avd/ansible_collections/arista/avd # Run molecule for a given test $ molecule test -s <scenario-name> # Run molecule for all test $ molecule test --all","title":"Manual execution"},{"location":"molecule/#continuous-integration","text":"These scenario are all included in github actions and executed on push and pull_request when a file under roles and/or molecule is updated. name : Ansible Molecule on : push : pull_request : paths : - 'ansible_collections/arista/avd/roles/**' - 'ansible_collections/arista/avd/molecules/**' - 'requirements.txt' jobs : molecule : runs-on : ubuntu-latest env : PY_COLORS : 1 # allows molecule colors to be passed to GitHub Actions ANSIBLE_FORCE_COLOR : 1 # allows ansible colors to be passed to GitHub Actions strategy : fail-fast : true matrix : avd_scenario : - 'avd-l3ls-ebgp' - 'avd-l3ls-ebgp-json' - 'avd-l3ls-isis' - 'eos-cli-config-gen' steps : - uses : actions/checkout@v1 - name : Set up Python 3 uses : actions/setup-python@v1 with : python-version : '3.x' - name : Install dependencies run : | python -m pip install --upgrade pip pip install -r development/requirements.txt pip install -r development/requirements-dev.txt - name : Execute molecule run : | cd ansible_collections/arista/avd molecule test --scenario-name ${{ matrix.avd_scenario }} - uses : actions/upload-artifact@v1 with : name : molecule-results-${{ matrix.avd_scenario }} path : ansible_collections/arista/avd/molecule/${{ matrix.avd_scenario }}","title":"Continuous Integration"},{"location":"plugins/","text":"Arista AVD Plugins # Table of Contents: Arista AVD Plugins Plugin Filters list_compress filter natural_sort filter Plugin Filters # Arista AVD provides built-in filters to help extend jinja2 templates list_compress filter # The list_compress filter provides the capabilities to compress a list of integers and return as a string for example: - [ 1 , 2 , 3 , 4 , 5 ] -> \"1-5\" - [ 1 , 2 , 3 , 7 , 8 ] -> \"1-3,7-8\" To use this filter: {{ list_to_compress | arista .avd.list_compress }} natural_sort filter # The natural_sort filter provides the capabilities to sort a list or a dictionary of integers and/or strings that contain alphanumeric characters naturally. When leveraged on a dictionary, only the key value will be returned. To use this filter: {% for item in dictionary_to_natural_sort | arista .avd.natural_sort %} {{ natural_sorted_item }} {% endfor %} Modules # Inventory to CloudVision Containers # The inventory_to_container module provides following capabilities: - Transform inventory groups into CloudVision containers topology. - Create list of configlets definition. It saves everything in a YAML file using destination keyword. It is a module to build structure of data to configure on a CloudVision server. Output is ready to be passed to arista.cvp to configure CloudVision . Example: To use this module: tasks : - name : generate intented variables tags : [ always ] inventory_to_container : inventory : '{{ inventory_file }}' container_root : '{{ container_root }}' configlet_dir : 'intended/configs' configlet_prefix : '{{ configlets_prefix }}' destination : '{{playbook_dir}}/intended/structured_configs/{{inventory_hostname}}.yml' Inventory example applied to this example: all : children : # DC1_Fabric - EVPN Fabric running in home lab DC1 : children : DC1_FABRIC : children : DC1_SPINES : hosts : DC1-SPINE1 : DC1-SPINE2 : DC1_L3LEAFS : children : DC1_LEAF1 : hosts : DC1-LEAF1A : DC1-LEAF1B : DC1_LEAF2 : hosts : DC1-LEAF2A : DC1-LEAF2B : Generated output ready to be used by arista.cvp collection: --- CVP_DEVICES : DC1-SPINE1 : name : DC1-SPINE1 parentContainerName : DC1_SPINES configlets : - DC1-AVD_DC1-SPINE1 imageBundle : [] CVP_CONTAINERS : DC1_LEAF1 : parent_container : DC1_L3LEAFS DC1_FABRIC : parent_container : Tenant DC1_L3LEAFS : parent_container : DC1_FABRIC DC1_LEAF2 : parent_container : DC1_L3LEAFS DC1_SPINES : parent_container : DC1_FABRIC","title":"Arista AVD Plugins"},{"location":"plugins/#arista-avd-plugins","text":"Table of Contents: Arista AVD Plugins Plugin Filters list_compress filter natural_sort filter","title":"Arista AVD Plugins"},{"location":"plugins/#plugin-filters","text":"Arista AVD provides built-in filters to help extend jinja2 templates","title":"Plugin Filters"},{"location":"plugins/#list_compress-filter","text":"The list_compress filter provides the capabilities to compress a list of integers and return as a string for example: - [ 1 , 2 , 3 , 4 , 5 ] -> \"1-5\" - [ 1 , 2 , 3 , 7 , 8 ] -> \"1-3,7-8\" To use this filter: {{ list_to_compress | arista .avd.list_compress }}","title":"list_compress filter"},{"location":"plugins/#natural_sort-filter","text":"The natural_sort filter provides the capabilities to sort a list or a dictionary of integers and/or strings that contain alphanumeric characters naturally. When leveraged on a dictionary, only the key value will be returned. To use this filter: {% for item in dictionary_to_natural_sort | arista .avd.natural_sort %} {{ natural_sorted_item }} {% endfor %}","title":"natural_sort filter"},{"location":"plugins/#modules","text":"","title":"Modules"},{"location":"plugins/#inventory-to-cloudvision-containers","text":"The inventory_to_container module provides following capabilities: - Transform inventory groups into CloudVision containers topology. - Create list of configlets definition. It saves everything in a YAML file using destination keyword. It is a module to build structure of data to configure on a CloudVision server. Output is ready to be passed to arista.cvp to configure CloudVision . Example: To use this module: tasks : - name : generate intented variables tags : [ always ] inventory_to_container : inventory : '{{ inventory_file }}' container_root : '{{ container_root }}' configlet_dir : 'intended/configs' configlet_prefix : '{{ configlets_prefix }}' destination : '{{playbook_dir}}/intended/structured_configs/{{inventory_hostname}}.yml' Inventory example applied to this example: all : children : # DC1_Fabric - EVPN Fabric running in home lab DC1 : children : DC1_FABRIC : children : DC1_SPINES : hosts : DC1-SPINE1 : DC1-SPINE2 : DC1_L3LEAFS : children : DC1_LEAF1 : hosts : DC1-LEAF1A : DC1-LEAF1B : DC1_LEAF2 : hosts : DC1-LEAF2A : DC1-LEAF2B : Generated output ready to be used by arista.cvp collection: --- CVP_DEVICES : DC1-SPINE1 : name : DC1-SPINE1 parentContainerName : DC1_SPINES configlets : - DC1-AVD_DC1-SPINE1 imageBundle : [] CVP_CONTAINERS : DC1_LEAF1 : parent_container : DC1_L3LEAFS DC1_FABRIC : parent_container : Tenant DC1_L3LEAFS : parent_container : DC1_FABRIC DC1_LEAF2 : parent_container : DC1_L3LEAFS DC1_SPINES : parent_container : DC1_FABRIC","title":"Inventory to CloudVision Containers"},{"location":"roles/build_output_folders/","text":"Build Output Folders # Role to cleanup and create local folder structure to save roles\u2019 outputs Requirements # None Role Variables # Role support following variables: # Root directory where to build output structure root_dir : '{{playbook_dir}}' # Main output directory output_dir_name : 'intended' # Output for structured YAML files: structured_dir_name : 'structured_configs' # EOS Configuration Directory name eos_config_dir_name : 'configs' # Main documentation folder documentation_dir_name : 'documentation' # Fabric Documentation fabric_dir_name : 'DC1_FABRIC' # Device documentation devices_dir_name : 'devices' Role will create following structure: intended \u251c\u2500\u2500 configs \u2514\u2500\u2500 structured_configs | documentation \u251c\u2500\u2500 DC1_FABRIC \u2514\u2500\u2500 devices If folders already exists, role will delete them and recreate structure. Dependencies # None Example Playbook # Below is an example to use in your playbook to build output folders using default values. - name : Build Switch configuration hosts : DC1_FABRIC connection : local gather_facts : no tasks : - name : 'Reset local folders for output' tags : [ build ] import_role : name : arista.avd.build_output_folders License # Project is published under Apache 2.0 License","title":"build_output_folders"},{"location":"roles/build_output_folders/#build-output-folders","text":"Role to cleanup and create local folder structure to save roles\u2019 outputs","title":"Build Output Folders"},{"location":"roles/build_output_folders/#requirements","text":"None","title":"Requirements"},{"location":"roles/build_output_folders/#role-variables","text":"Role support following variables: # Root directory where to build output structure root_dir : '{{playbook_dir}}' # Main output directory output_dir_name : 'intended' # Output for structured YAML files: structured_dir_name : 'structured_configs' # EOS Configuration Directory name eos_config_dir_name : 'configs' # Main documentation folder documentation_dir_name : 'documentation' # Fabric Documentation fabric_dir_name : 'DC1_FABRIC' # Device documentation devices_dir_name : 'devices' Role will create following structure: intended \u251c\u2500\u2500 configs \u2514\u2500\u2500 structured_configs | documentation \u251c\u2500\u2500 DC1_FABRIC \u2514\u2500\u2500 devices If folders already exists, role will delete them and recreate structure.","title":"Role Variables"},{"location":"roles/build_output_folders/#dependencies","text":"None","title":"Dependencies"},{"location":"roles/build_output_folders/#example-playbook","text":"Below is an example to use in your playbook to build output folders using default values. - name : Build Switch configuration hosts : DC1_FABRIC connection : local gather_facts : no tasks : - name : 'Reset local folders for output' tags : [ build ] import_role : name : arista.avd.build_output_folders","title":"Example Playbook"},{"location":"roles/build_output_folders/#license","text":"Project is published under Apache 2.0 License","title":"License"},{"location":"roles/cvp_configlet_upload/","text":"Ansible Role: cvp_configlet_upload # Table of Contents: Ansible Role: cvp_configlet_upload Overview Role requirements Role Inputs and Outputs Requirements License Overview # cvp_configlet_upload , is a role that deploys configlets stored in a local folder to Cloudvision server. Role requirements # This role requires to install arista.cvp collection to support CloudVision interactions. $ ansible-galaxy collection install arista.cvp Role Inputs and Outputs # Read content of {{configlet_directory}} and create cv_configlet input structure. Collect Cloudvision facts. Create or update configlets on Cloudvision server with content from {{configlet_directory}} Inputs: Inventory configuration: An entry must be part of the inventory to describe CloudVision server. arista.cvp modules use httpapi approach. Example below provides framework to use in your inventory. all : children : cloudvision : hosts : cv_server01 : ansible_httpapi_host : 10.83.28.164 ansible_host : 10.83.28.164 ansible_user : ansible ansible_password : ansible ansible_connection : httpapi ansible_httpapi_use_ssl : True ansible_httpapi_validate_certs : False ansible_network_os : eos ansible_httpapi_port : 443 # Configuration to get Virtual Env information ansible_python_interpreter : $(which python3) Module variables: configlet_directory : Folder where local configlets are stored. Default: configlets . file_extension : File extension to look for configlet in their local folder. Default: conf . configlets_cvp_prefix : Prefix to use for configlet on CV side. Default: none . Example : tasks : - name : upload cvp configlets import_role : name : arista.avd.cvp_configlet_upload vars : configlet_directory : 'configlets/' file_extension : 'txt' configlets_cvp_prefix : 'DC1-AVD' This module also supports tags to run a subset of ansible tasks: build : Generate cv_configlet input structure. provision : Run build tags + configure Cloudvision with information generated in previous tasks $ ansible-playbook playbook.to.deploy.with.cvp.yml --tags \"provision\" Outputs: None. Tasks: Read content of {{configlet_directory}} and create cv_configlet input structure. Collect Cloudvision facts. Create or update configlets on Cloudvision server with content from {{configlet_directory}} Requirements # Requirements are located here: avd-requirements License # Project is published under Apache 2.0 License","title":"cvp_configlet_upload"},{"location":"roles/cvp_configlet_upload/#ansible-role-cvp_configlet_upload","text":"Table of Contents: Ansible Role: cvp_configlet_upload Overview Role requirements Role Inputs and Outputs Requirements License","title":"Ansible Role: cvp_configlet_upload"},{"location":"roles/cvp_configlet_upload/#overview","text":"cvp_configlet_upload , is a role that deploys configlets stored in a local folder to Cloudvision server.","title":"Overview"},{"location":"roles/cvp_configlet_upload/#role-requirements","text":"This role requires to install arista.cvp collection to support CloudVision interactions. $ ansible-galaxy collection install arista.cvp","title":"Role requirements"},{"location":"roles/cvp_configlet_upload/#role-inputs-and-outputs","text":"Read content of {{configlet_directory}} and create cv_configlet input structure. Collect Cloudvision facts. Create or update configlets on Cloudvision server with content from {{configlet_directory}} Inputs: Inventory configuration: An entry must be part of the inventory to describe CloudVision server. arista.cvp modules use httpapi approach. Example below provides framework to use in your inventory. all : children : cloudvision : hosts : cv_server01 : ansible_httpapi_host : 10.83.28.164 ansible_host : 10.83.28.164 ansible_user : ansible ansible_password : ansible ansible_connection : httpapi ansible_httpapi_use_ssl : True ansible_httpapi_validate_certs : False ansible_network_os : eos ansible_httpapi_port : 443 # Configuration to get Virtual Env information ansible_python_interpreter : $(which python3) Module variables: configlet_directory : Folder where local configlets are stored. Default: configlets . file_extension : File extension to look for configlet in their local folder. Default: conf . configlets_cvp_prefix : Prefix to use for configlet on CV side. Default: none . Example : tasks : - name : upload cvp configlets import_role : name : arista.avd.cvp_configlet_upload vars : configlet_directory : 'configlets/' file_extension : 'txt' configlets_cvp_prefix : 'DC1-AVD' This module also supports tags to run a subset of ansible tasks: build : Generate cv_configlet input structure. provision : Run build tags + configure Cloudvision with information generated in previous tasks $ ansible-playbook playbook.to.deploy.with.cvp.yml --tags \"provision\" Outputs: None. Tasks: Read content of {{configlet_directory}} and create cv_configlet input structure. Collect Cloudvision facts. Create or update configlets on Cloudvision server with content from {{configlet_directory}}","title":"Role Inputs and Outputs"},{"location":"roles/cvp_configlet_upload/#requirements","text":"Requirements are located here: avd-requirements","title":"Requirements"},{"location":"roles/cvp_configlet_upload/#license","text":"Project is published under Apache 2.0 License","title":"License"},{"location":"roles/eos_cli_config_gen/","text":"Ansible Role: eos_cli_config_gen # Table of Contents: Ansible Role: eos_cli_config_gen Overview Role Inputs and Outputs Requirements Input Variables Terminal Settings Aliases Hardware Counters Daemon TerminAttr IP DHCP Relay Internal VLAN Allocation Policy IP IGMP Snooping Event Monitor Event Handler Load Interval Queue Monitor Length Service Routing Protocols Model Logging LLDP Domain Lookup Name Servers DNS Domain NTP Servers Router L2 VPN Sflow Redundancy SNMP Settings Spanning Tree Platform Tacacs+ Servers AAA Server Groups AAA Authentication AAA Authorization AAA Accounting Local Users Clock Timezone VLANs VRF Instances Bfd Multihop Interval Port-Channel Interfaces Ethernet Interfaces Loopback Interfaces Management Interfaces VLAN Interfaces VxLAN Interface Hardware TCAM Profiles MAC Address-table Router Virtual MAC Address Virtual Source NAT IPv6 Extended Access-Lists IPv6 Standard Access-Lists IP Extended Access-Lists IP Standard Access-Lists Static Routes IPv6 Static Routes IP Routing Prefix Lists IPv6 Prefix Lists IPv6 Routing MLAG Configuration Community Lists Route Maps Peer Filters Router BGP Configuration Routing - Multicast Router OSPF Configuration Routing PIM Sparse Mode Router ISIS Configuration Queue Monitor Streaming IP TACACS+ Source Interfaces VM Tracer Sessions Banners HTTP Management API Management Console Management Security Management SSH License Overview # eos_cli_config_gen , is a role that generates eos cli syntax and device documentation. The eos_cli_config_gen role: Designed to generate the intended configuration offline, without relying on switch current state information. Facilitates the evaluation of the configuration prior to deployment with tools like Batfish Role Inputs and Outputs # Figure 1 below provides a visualization of the roles inputs, and outputs and tasks in order executed by the role. Inputs: Structured EOS configuration file in yaml format. Outputs: EOS configuration in CLI format. Device Documentation in Markdown format. Tasks: Include device structured configuration that was previously generated. Generate EOS configuration in CLI format. Generate Device Documentation in Markdown format. Requirements # Requirements are located here: avd-requirements Input Variables # The input variables are documented inline within yaml formated output with: \u201c< >\u201d Variables are organized in order of how they appear in the CLI syntax. Available features and variables may vary by platforms, refer to documentation on arista.com for specifics. All values are optional. Terminal Settings # terminal : length : < 0-32767 > width : < 0-32767 > Aliases # aliases : | < list of alias commands in EOS CLI syntax > Hardware Counters # hardware_counters : features : - <feature_1> : < direction | in | out > - <feature_1> : < direction | in | out > Daemon TerminAttr # daemon_terminattr : ingestgrpcurl : ips : - < IPv4_address > - < IPv4_address > - < IPv4_address > port : < port_id > ingestauth_key : < ingest_key > ingestvrf : < vrf_name > smashexcludes : \"< list as string >\" ingestexclude : \"< list as string >\" IP DHCP Relay # ip_dhcp_relay : information_option : < true | false > Internal VLAN Allocation Policy # vlan_internal_allocation_policy : allocation : < ascending | descending > range : beginning : < vlan_id > ending : < vlan_id > IP IGMP Snooping # ip_igmp_snooping : vlans : < vlan_id > : enabled : < true | false > Event Monitor # event_monitor : enabled : < true | false > Event Handler # ### Event Handler ### event_handlers : evpn-blacklist-recovery : action_type : < Type of action. [bash, increment, log]> action : < Command to execute > delay : < Event-handler delay in seconds > trigger : < Configure event trigger condition. Only supports on-logging > regex : < Regular expression to use for searching log messages. Required for on-logging trigger > asynchronous : < Set the action to be non-blocking. if unset, default is False > Load Interval # load_interval : default : < seconds > Queue Monitor Length # queue_monitor_length : log : < seconds > notifying : < true | false > Service Routing Protocols Model # service_routing_protocols_model : < multi-agent | ribd > LLDP # lldp : timer : < transmission_time > holdtime : < hold_time_period > management_address : < all | ethernetN | loopbackN | managementN | port-channelN | vlanN > vrf : < vrf_name > run : < true | false > Logging # logging : console : < severity_level > monitor : < severity_level > buffered : size : < messages_nb (minimum of 10) > level : < severity_level > trap : < severity_level > source_interface : < source_interface_name > vrfs : < vrf_name > : source_interface : < source_interface_name > hosts : - < syslog_server_1> - < syslog_server_2> Domain Lookup # ip_domain_lookup : source_interfaces : < source_interface_1 > : vrf : < vrf_name > Name Servers # name_server : source : vrf : < vrf_name > nodes : - < name_server_1 > - < name_server_2 > DNS Domain # dns_domain : < domain_name > NTP Servers # ntp_server : local_interface : vrf : < vrf_name > interface : < source_interface > nodes : - < ntp_server_1 > - < ntp_server_2 > Router L2 VPN # router_l2_vpn : nd_rs_flooding_disabled : < true | false > virtual_router_nd_ra_flooding_disabled : < true | false > arp_selective_install : < true | false > arp_proxy : prefix_list : < prefix_list_name > Sflow # sflow : sample : < sample_rate > dangerous : < true | false > vrfs : <vrf_name_1> : destinations : < sflow_destination_ip_1> : < sflow_destination_ip_2> : port : < port_number > source_interface : < source_interface > <vrf_name_2> : destinations : < sflow_destination_ip_1> : source_interface : < source_interface > destinations : < sflow_destination_ip_1 > : < sflow_destination_ip_2 > : source_interface : < source_interface > run : < true | false > Redundancy # Redundancy : protocol : < redundancy_protocol > SNMP Settings # snmp_server : contact : < contact_name > location : < location > local_interfaces : - name : < interface_name_1 > vrf : < vrf_name > - name : < interface_name_2 > views : - name : < view_name > MIB_family_name : < MIB_family_name > included : < true | false > - name : < view_name > MIB_family_name : < MIB_family_name > included : < true | false > groups : - name : < group_name > version : < v1 | v2c | v3 > authentication : < auth | noauth | priv > read : < read_view > write : < write_view > notify : < notify_view > - name : < group_name > version : < v1 | v2c | v3 > authentication : < auth | noauth | priv > read : < read_view > users : - name : < username > group : < group_name > version : < v1 | v2c | v3 > auth : < hash_algorithm > auth_passphrase : < encrypted_auth_passphrase > priv : < encryption_algorithm > priv_passphrase : < encrypted_priv_passphrase > - name : < username > group : < group_name > version : < v1 | v2c | v3 > hosts : - host : < host IP address or name > vrf : < vrf_name > users : - username : < username > authentication_level : < auth | noauth | priv > version : < 1 | 2c | 3 > - host : < host IP address or name > vrf : < vrf_name > users : - username : < username > authentication_level : < auth | noauth | priv > version : < 1 | 2c | 3 > traps : enable : < true | false > vrfs : - name : < vrf_name > enable : < true | false > - name : < vrf_name > enable : < true | false > Spanning Tree # spanning_tree : edge_port : bpduguard_default : < true | false > mode : < spanning_tree_mode > priority : < priority_level > no_spanning_tree_vlan : < vlan_id >, < vlan_id >-< vlan_id > Platform # platform : trident : forwarding_table_partition : < partition > Tacacs+ Servers # tacacs_servers : hosts : - host : < host1_ip_address > vrf : < vrf_name > key : < encypted_key > - host : < host2_ip_address > key : < encypted_key > AAA Server Groups # aaa_server_groups : - name : < server_group_name > type : < tacacs+ | radius | ldap > servers : - server : < server1_ip_address > vrf : < vrf_name > - server : < server1_ip_address > vrf : < vrf_name > - name : < server_group_name > type : < tacacs+ | radius | ladp > servers : - server : < host1_ip_address > AAA Authentication # aaa_authentication : login : default : < group | local | none > serial_console : < group | local | none > AAA Authorization # aaa_authorization : exec_default : < group | local | none > config_commands : < true | false > AAA Accounting # aaa_accounting : exec : default : type : < none | start-stop | stop-only > group : < group_name > commands : commands_default : - commands : < all | 0-15 > type : < none | start-stop | stop-only > group : < group_name > logging : < true | false > - commands : < all | 0-15 > type : < none | start-stop | stop-only > logging : < true | false > Local Users # local_users : < user_1 > : privilege : < 1-15 > role : < role > sha512_password : \"< sha_512_password >\" < user_2 > : privilege : < 1-15 > role : < role > sha512_password : \"< sha_512_password >\" Clock Timezone # clock : timezone : < timezone > VLANs # vlans : < vlan_id > : name : < vlan_name > state : < active | suspend > trunk_groups : - < trunk_group_name_1 > - < trunk_group_name_2 > < vlan_id > : name : < vlan_name > VRF Instances # vrfs : < vrf_name > : description : < description> ip_routing : < true | false > ipv6_routing : < true | false > < vrf_name > : description : < description> ip_routing : < true | false > ipv6_routing : < true | false > Bfd Multihop Interval # bfd_multihop : interval : < rate in milliseconds > min_rx : < rate in milliseconds > multiplier : < 3-50 > Port-Channel Interfaces # port_channel_interfaces : < Port-Channel_interface_1 > : description : < description > shutdown : < true | false > vlans : \"< list of vlans as string >\" mode : < access | dot1q-tunnel | trunk > mlag : < mlag_id > trunk_groups : - < trunk_group_name_1 > - < trunk_group_name_2 > qos : trust : < cos | dscp > < Port-Channel_interface_2 > : description : < description > vlans : \"< list of vlans as string >\" mode : < access | dot1q-tunnel | trunk > spanning_tree_bpdufilter : < true | false > spanning_tree_bpduguard : < true | false > spanning_tree_portfast : < portfast_mode > vmtracer : < true | false > < Port-Channel_interface_3 > : description : < description > mtu : < mtu > type : < switched | routed > ip_address : < IP_address/mask > ipv6_enable : < true | false > ipv6_address : < IPv6_address/mask > ipv6_address_link_local : < link_local_IPv6_address/mask > ipv6_nd_ra_disabled : < true | false > ipv6_nd_managed_config_flag : < true | false > ipv6_nd_prefixes : < IPv6_address_1/Mask > : valid_lifetime : < infinite or lifetime in seconds > preferred_lifetime : < infinite or lifetime in seconds > no_autoconfig_flag : < true | false > < IPv6_address_2/Mask > : access_group_in : < access_list_name > access_group_out : < access_list_name > ipv6_access_group_in : < ipv6_access_list_name > ipv6_access_group_out : < ipv6_access_list_name > pim : ipv4 : sparse_mode : < true | false > Ethernet Interfaces # # Routed Interfaces ethernet_interfaces : <Ethernet_interface_1 > : description : < description > shutdown : < true | false > speed : < interface_speed > mtu : < mtu > type : < routed | switched > vrf : < vrf_name > ip_address : < IPv4_address/Mask > ipv6_enable : < true | false > ipv6_address : < IPv6_address/Mask > ipv6_address_link_local : < link_local_IPv6_address/Mask > ipv6_nd_ra_disabled : < true | false > ipv6_nd_managed_config_flag : < true | false > ipv6_nd_prefixes : < IPv6_address_1/Mask > : valid_lifetime : < infinite or lifetime in seconds > preferred_lifetime : < infinite or lifetime in seconds > no_autoconfig_flag : < true | false > < IPv6_address_2/Mask > : access_group_in : < access_list_name > access_group_out : < access_list_name > ipv6_access_group_in : < ipv6_access_list_name > ipv6_access_group_out : < ipv6_access_list_name > ospf_network_point_to_point : < true | false > ospf_area : < ospf_area > pim : ipv4 : sparse_mode : < true | false > isis_enable : < ISIS Instance > isis_passive : < boolean > isis_metric : < integer > isis_network_point_to_point : < boolean > # Switched Interfaces <Ethernet_interface_2 > : description : < description > shutdown : < true | false > speed : < interface_speed > mtu : < mtu > vlans : \"< list of vlans as string >\" native_vlan : <native vlan number> mode : < access | dot1q-tunnel | trunk > flowcontrol : received : < received | send | on > channel_group : id : < Port-Channel_id > mode : < on | active | passive > qos : trust : < cos | dscp > spanning_tree_bpdufilter : < true | false > spanning_tree_bpduguard : < true | false > spanning_tree_portfast : < portfast_mode > vmtracer : < true | false > Loopback Interfaces # loopback_interfaces : < Loopback_interface_1 > : description : < description > shutdown : < true | false > vrf : < vrf_name > ip_address : < IPv4_address/Mask > ipv6_enable : < true | false > ipv6_address : < IPv6_address/Mask > ospf_area : < ospf_area > < Loopback_interface_2 > : description : < description > ip_address : < IPv4_address/Mask > isis_enable : < ISIS Instance > isis_passive : < boolean > isis_metric : < integer > isis_network_point_to_point : < boolean > Management Interfaces # management_interfaces : < Management_interface_1 > : description : < description > vrf : < vrf_name > ip_address : < IPv4_address/Mask > ipv6_enable : < true | false > ipv6_address : < IPv6_address/Mask > gateway : <IPv4 address of gateway> ipv6_gateway : <IPv6 address of gateway> VLAN Interfaces # vlan_interfaces : < Vlan_id_1 > : description : < description > shutdown : < true | false > vrf : < vrf_name > ip_address : < IPv4_address/Mask > ip_address_secondary : < IPv4_address/Mask > ip_router_virtual_address : < IPv4_address > ip_router_virtual_address_secondary : < IPv4_address > ip_address_virtual : < IPv4_address/Mask > mtu : < mtu > ip_helpers : < ip_helper_address_1 > : source_interface : < source_interface_name > vrf : < vrf_name > < ip_helper_address_2 > : source_interface : < source_interface_name > ipv6_enable : < true | false > ipv6_address : < IPv6_address/Mask > ipv6_address_link_local : < link_local_IPv6_address/Mask > ipv6_nd_ra_disabled : < true | false > ipv6_nd_managed_config_flag : < true | false > ipv6_nd_prefixes : < IPv6_address_1/Mask > : valid_lifetime : < infinite or lifetime in seconds > preferred_lifetime : < infinite or lifetime in seconds > no_autoconfig_flag : < true | false > < IPv6_address_2/Mask > : access_group_in : < access_list_name > access_group_out : < access_list_name > ipv6_access_group_in : < ipv6_access_list_name > ipv6_access_group_out : < ipv6_access_list_name > multicast : ipv4 : source_route_export : enabled : < true | false > administrative_distance : < 1-255 > ospf_network_point_to_point : < true | false > ospf_area : < ospf_area > pim : ipv4 : sparse_mode : < true | false > local_interface : < local_interface_name > ipv6_virtual_router_address : < IPv6_address > isis_enable : < ISIS Instance > isis_passive : < boolean > isis_metric : < integer > isis_network_point_to_point : < boolean > mtu : < mtu > vrrp : virtual_router : < virtual_router_id > priority : < instance_priority > advertisement_interval : < advertisement_interval> preempt_delay_minimum : < minimum_preemption_delay > ipv4 : < virtual_ip_address > ipv6 : < virtual_ip_address > < Vlan_id_2 > : description : < description > ip_address : < IPv4_address/Mask > VxLAN Interface # vxlan_tunnel_interface : Vxlan1 : description : < description > source_interface : < source_interface_name > virtual_router : encapsulation_mac_address : < mlag-system-id | ethernet_address (H.H.H) > vxlan_udp_port : < udp_port > vxlan_vni_mappings : vlans : < vlan_id_1 > : vni : < vni_id_1 > < vlan_id_2 > : vni : < vni_id_2 > vrfs : < vrf_name > : vni : < vni_id_3 > < vrf_name > : vni : < vni_id_4 > Hardware TCAM Profiles # tcam_profile : - < tcam_profile > MAC Address-table # mac_address_table : aging_time : < aging_time_in_seconds > Router Virtual MAC Address # ip_virtual_router_mac_address : < mac_address (hh:hh:hh:hh:hh:hh) > Virtual Source NAT # virtual_source_nat_vrfs : < vrf_name_1 > : ip_address : < IPv4_address > < vrf_name_2 > : ip_address : < IPv4_address > IPv6 Extended Access-Lists # ipv6_access_lists : < ipv6_access_list_name_1 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\" < sequence_id_2 > : action : \"< action as string >\" < ipv6_access_list_name_2 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\" IPv6 Standard Access-Lists # ipv6_standard_access_lists : < ipv6_access_list_name_1 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\" < sequence_id_2 > : action : \"< action as string >\" < ipv6_access_list_name_2 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\" IP Extended Access-Lists # access_lists : < access_list_name_1 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\" < sequence_id_2 > : action : \"< action as string >\" < access_list_name_2 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\" IP Standard Access-Lists # standard_access_lists : < access_list_name_1 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\" < sequence_id_2 > : action : \"< action as string >\" < access_list_name_2 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\" Static Routes # static_routes : - vrf : < vrf_name, if vrf_name = default the route will be placed in the GRT > destination_address_prefix : < IPv4_network/Mask > gateway : < IPv4_address > distance : < 1-255 > tag : < 0-4294967295 > name : < description > - destination_address_prefix : < IPv4_network/Mask > gateway : < IPv4_address > IPv6 Static Routes # ipv6_static_routes : - vrf : < vrf_name, if vrf_name = default the route will be placed in the GRT > destination_address_prefix : < IPv6_network/Mask > gateway : < IPv6_address > distance : < 1-255 > tag : < 0-4294967295 > name : < description > - destination_address_prefix : < IPv6_network/Mask > gateway : < IPv6_address > IP Routing # ip_routing : < true | false > Prefix Lists # prefix_lists : < prefix_list_name_1 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\" < sequence_id_2 > : action : \"< action as string >\" < prefix_list_name_2 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\" IPv6 Prefix Lists # ipv6_prefix_lists : < ipv6_prefix_list_name_1 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\" < sequence_id_2 > : action : \"< action as string >\" < ipv6_prefix_list_name_2 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\" IPv6 Routing # ipv6_unicast_routing : < true | false > MLAG Configuration # mlag_configuration : domain_id : < domain_id_name > local_interface : < interface_name > peer_address : < IPv4_address > peer_address_heartbeat : peer_ip : < IPv4_address > vrf : < vrf_name > dual_primary_detection_delay : < seconds > peer_link : < Port-Channel_id > reload_delay_mlag : < seconds > reload_delay_non_mlag : < seconds > Community Lists # community_lists : < community_list_name_1 > : action : \"< action as string >\" < community_list_name_2 > : action : \"< action as string >\" Route Maps # route_maps : < route_map_name_1 > : sequence_numbers : < sequence_id_1 > : type : < permit | deny > description : < description > match : - \"< match rule 1 as string >\" - \"< match rule 2 as string >\" set : - \"< set as string >\" < sequence_id_2 > : type : < permit | deny > match : - \"< match as string >\" < route_map_name_2 > : sequence_numbers : < sequence_id_1 > : type : < permit | deny > description : < description > set : - \"< set rule 1 as string >\" - \"< set rule 2 as string >\" Peer Filters # peer_filters : < peer_filter_name_1 : sequence_numbers : < sequence_id_1 > : match : \"< match as string >\" < sequence_id_2 > : match : \"< match as string >\" < peer_filter_name_2 : sequence_numbers : < sequence_id_1 > : match : \"< match as string >\" Router BGP Configuration # router_bgp : as : < bgp_as > router_id : < IPv4_address > bgp_defaults : - \"< bgp command as string >\" - \"< bgp command as string >\" peer_groups : < peer_group_name_1> : type : < ipv4 | evpn > description : \"< description as string >\" shutdown : < true | false > peer_filter : < peer_filter > next_hop_unchanged : < true | false > update_source : < interface > bfd : < true | false > ebgp_multihop : < integer > next_hop_self : < true | false > password : \"< encrypted_password >\" send_community : < true | false > maximum_routes : < integer > weight : < weight_value > timers : < keepalive_hold_timer_values > < peer_group_name_2 > : type : < ipv4 | evpn > bgp_listen_range_prefix : < IP prefix range > peer_filter : < peer_filter > password : \"< encrypted_password >\" maximum_routes : < integer > neighbors : < IPv4_address_1 > : peer_group : < peer_group_name > remote_as : < bgp_as > description : \"< description as string >\" shutdown : < true | false > update_source : < interface > weight : < weight_value > timers : < keepalive_hold_timer_values > < IPv4_address_2 > : remote_as : < bgp_as > next_hop_self : < true | false > password : \"< encrypted_password >\" < IPv6_address_1 > : remote_as : < bgp_as > redistribute_routes : < route_type > : route_map : < route_map_name > < route_type > : route_map : < route_map_name > vlan_aware_bundles : < vlan_aware_bundle_name_1 > : rd : \"< route distinguisher >\" route_targets : both : - \"< route_target >\" import : - \"< route_target >\" - \"< route_target >\" export : - \"< route_target >\" - \"< route_target >\" redistribute_routes : - < learned > vlan : < vlan_range > < vlan_aware_bundle_name_2 > : rd : \"< route distinguisher >\" route_targets : both : - \"< route_target >\" import : - \"< route_target >\" - \"< route_target >\" export : - \"< route_target >\" - \"< route_target >\" redistribute_routes : - < connected > - < learned > vlan : < vlan_range > vlans : < vlan_id_1> : rd : \"< route distinguisher >\" route_targets : both : - \"< route_target >\" redistribute_routes : - < connected > - < learned > <vlan_id_2 > : rd : \"< route distinguisher >\" route_targets : import : - \"< route_target >\" - \"< route_target >\" export : - \"< route_target >\" - \"< route_target >\" redistribute_routes : - < connected > - < learned > address_family_evpn : peer_groups : < peer_group_name > : activate : < true | false > address_family_ipv4 : networks : < prefix_ipv4 > : route_map : < route_map_name > peer_groups : < peer_group_name > : route_map_in : < route_map_name > route_map_out : < route_map_name > activate : < true | false > < peer_group_name > : activate : < true | false > neighbors : < neighbor_ip_address> : activate : < true | false > prefix_list_in : < prefix_list_name > prefix_list_out : < prefix_list_name > < neighbor_ip_address> : activate : < true | false > default_originate : always : < true | false > route_map : < route_map_name > address_family_ipv4_multicast : peer_groups : < peer_group_name > : activate : < true | false > < peer_group_name > : activate : < true | false > neighbors : < neighbor_ip_address> : redistribute_routes : < route_type > : address_family_ipv6 : peer_groups : < peer_group_name > : activate : < true | false > route_map_in : < route_map_name > route_map_out : < route_map_name > < peer_group_name > : activate : true neighbors : < neighbor_ip_address> : route_map_in : < route_map_name > route_map_out : < route_map_name > activate : < true | false > redistribute_routes : < route_type > : route_map : < route_map_name > < route_type > : route_map : < route_map_name > vrfs : < vrf_name_1 > : rd : \"< route distinguisher >\" route_targets : import : < address_family > : - \"< route_target >\" - \"< route_target >\" < address_family > : - \"< route_target >\" - \"< route_target >\" export : < address_family > : - \"< route_target >\" - \"< route_target >\" neighbors : < neighbor_ip_address > : remote_as : < asn > < neighbor_ip_address > : remote_as : < asn > redistribute_routes : < route_type > : route_map : < route_map_name > < route_type > : route_map : < route_map_name > < vrf_name_2 > : rd : \"<route distinguisher >\" route_targets : import : < address_family > : - \"< route_target >\" - \"< route_target >\" < address_family > : - \"< route_target >\" - \"< route_target >\" export : < address_family > : - \"< route_target >\" - \"< route_target >\" redistribute_routes : < route_type > : route_map : < route_map_name > < route_type > : route_map : < route_map_name > Routing - Multicast # router_multicast : ipv4 : routing : < true | false > Router OSPF Configuration # router_ospf : process_ids : < process_id > : passive_interface_default : < true | false > router_id : < IPv4_address > no_passive_interfaces : - < interface_1 > - < interface_2 > max_lsa : < integer > default_information_originate : always : true redistribute : static : route_map : < route_map_name > connected : route_map : < route_map_name > Routing PIM Sparse Mode # router_pim_sparse_mode : ipv4 : rp_addresses : < rp_address_1 > : groups : < group_prefix_1/mask > : < group_prefix_2/mask > : < rp_address_2 > : anycast_rps : < anycast_rp_address_1 > : other_anycast_rp_addresses : < ip_address_other_anycast_rp_1 > : register_count : < register_count_nb > Router ISIS Configuration # router_isis : instance : <ISIS Instance Name> net : < CLNS Address to run ISIS | format 49.0001.0001.0000.0001.00 > router_id : < IPv4_address > no_passive_interfaces : < List no-passive-interface > is_type : < level-1 | level-1-2 | level-2 > address_family : < List of Address Families > isis_af_defaults : - maximum-paths < Integer 1-64 > Queue Monitor Streaming # queue_monitor_streaming : enable : < true | false > IP TACACS+ Source Interfaces # ip_tacacs_source_interfaces : - name : <interface_name_1 > vrf : < vrf_name_1 > - name : <interface_name_2 > VM Tracer Sessions # vmtracer_sessions : < vmtracer_session_name_1 > : url : < url > username : < username > password : < encrypted_password > autovlan_disable : < true | false > source_interface : < interface_name > < vmtracer_session_name_2 > : url : < url > username : < username > password : < encrypted_password > Banners # banners : login : | < text ending with EOF > motd : | < text ending with EOF > HTTP Management API # management_api_http : enable_http : < true | false > enable_https : < true | false > enable_vrfs : < vrf_name_1 > : access_group : < Standard IPv4 ACL name > ipv6_access_group : < Standard IPv6 ACL name > < vrf_name_2 > : Management Console # management_console : idle_timeout : < 0-86400 in minutes > Management Security # management_security : password : encryption_key_common : < true | false > Management SSH # management_ssh : access_groups : - name : < standard_acl_name_1 > : - name : < standard_acl_name_2 > : vrf : < vrf name > ipv6_access_groups : - name : < standard_acl_name_1 > : - name : < standard_acl_name_2 > : vrf : < vrf name > idle_timeout : < 0-86400 in minutes > enable : < true | false > vrfs : < vrf_name_1 > : enable : < true | false > < vrf_name_2 > : enable : < true | false > License # Project is published under Apache 2.0 License","title":"eos_cli_config_gen"},{"location":"roles/eos_cli_config_gen/#ansible-role-eos_cli_config_gen","text":"Table of Contents: Ansible Role: eos_cli_config_gen Overview Role Inputs and Outputs Requirements Input Variables Terminal Settings Aliases Hardware Counters Daemon TerminAttr IP DHCP Relay Internal VLAN Allocation Policy IP IGMP Snooping Event Monitor Event Handler Load Interval Queue Monitor Length Service Routing Protocols Model Logging LLDP Domain Lookup Name Servers DNS Domain NTP Servers Router L2 VPN Sflow Redundancy SNMP Settings Spanning Tree Platform Tacacs+ Servers AAA Server Groups AAA Authentication AAA Authorization AAA Accounting Local Users Clock Timezone VLANs VRF Instances Bfd Multihop Interval Port-Channel Interfaces Ethernet Interfaces Loopback Interfaces Management Interfaces VLAN Interfaces VxLAN Interface Hardware TCAM Profiles MAC Address-table Router Virtual MAC Address Virtual Source NAT IPv6 Extended Access-Lists IPv6 Standard Access-Lists IP Extended Access-Lists IP Standard Access-Lists Static Routes IPv6 Static Routes IP Routing Prefix Lists IPv6 Prefix Lists IPv6 Routing MLAG Configuration Community Lists Route Maps Peer Filters Router BGP Configuration Routing - Multicast Router OSPF Configuration Routing PIM Sparse Mode Router ISIS Configuration Queue Monitor Streaming IP TACACS+ Source Interfaces VM Tracer Sessions Banners HTTP Management API Management Console Management Security Management SSH License","title":"Ansible Role: eos_cli_config_gen"},{"location":"roles/eos_cli_config_gen/#overview","text":"eos_cli_config_gen , is a role that generates eos cli syntax and device documentation. The eos_cli_config_gen role: Designed to generate the intended configuration offline, without relying on switch current state information. Facilitates the evaluation of the configuration prior to deployment with tools like Batfish","title":"Overview"},{"location":"roles/eos_cli_config_gen/#role-inputs-and-outputs","text":"Figure 1 below provides a visualization of the roles inputs, and outputs and tasks in order executed by the role. Inputs: Structured EOS configuration file in yaml format. Outputs: EOS configuration in CLI format. Device Documentation in Markdown format. Tasks: Include device structured configuration that was previously generated. Generate EOS configuration in CLI format. Generate Device Documentation in Markdown format.","title":"Role Inputs and Outputs"},{"location":"roles/eos_cli_config_gen/#requirements","text":"Requirements are located here: avd-requirements","title":"Requirements"},{"location":"roles/eos_cli_config_gen/#input-variables","text":"The input variables are documented inline within yaml formated output with: \u201c< >\u201d Variables are organized in order of how they appear in the CLI syntax. Available features and variables may vary by platforms, refer to documentation on arista.com for specifics. All values are optional.","title":"Input Variables"},{"location":"roles/eos_cli_config_gen/#terminal-settings","text":"terminal : length : < 0-32767 > width : < 0-32767 >","title":"Terminal Settings"},{"location":"roles/eos_cli_config_gen/#aliases","text":"aliases : | < list of alias commands in EOS CLI syntax >","title":"Aliases"},{"location":"roles/eos_cli_config_gen/#hardware-counters","text":"hardware_counters : features : - <feature_1> : < direction | in | out > - <feature_1> : < direction | in | out >","title":"Hardware Counters"},{"location":"roles/eos_cli_config_gen/#daemon-terminattr","text":"daemon_terminattr : ingestgrpcurl : ips : - < IPv4_address > - < IPv4_address > - < IPv4_address > port : < port_id > ingestauth_key : < ingest_key > ingestvrf : < vrf_name > smashexcludes : \"< list as string >\" ingestexclude : \"< list as string >\"","title":"Daemon TerminAttr"},{"location":"roles/eos_cli_config_gen/#ip-dhcp-relay","text":"ip_dhcp_relay : information_option : < true | false >","title":"IP DHCP Relay"},{"location":"roles/eos_cli_config_gen/#internal-vlan-allocation-policy","text":"vlan_internal_allocation_policy : allocation : < ascending | descending > range : beginning : < vlan_id > ending : < vlan_id >","title":"Internal VLAN Allocation Policy"},{"location":"roles/eos_cli_config_gen/#ip-igmp-snooping","text":"ip_igmp_snooping : vlans : < vlan_id > : enabled : < true | false >","title":"IP IGMP Snooping"},{"location":"roles/eos_cli_config_gen/#event-monitor","text":"event_monitor : enabled : < true | false >","title":"Event Monitor"},{"location":"roles/eos_cli_config_gen/#event-handler","text":"### Event Handler ### event_handlers : evpn-blacklist-recovery : action_type : < Type of action. [bash, increment, log]> action : < Command to execute > delay : < Event-handler delay in seconds > trigger : < Configure event trigger condition. Only supports on-logging > regex : < Regular expression to use for searching log messages. Required for on-logging trigger > asynchronous : < Set the action to be non-blocking. if unset, default is False >","title":"Event Handler"},{"location":"roles/eos_cli_config_gen/#load-interval","text":"load_interval : default : < seconds >","title":"Load Interval"},{"location":"roles/eos_cli_config_gen/#queue-monitor-length","text":"queue_monitor_length : log : < seconds > notifying : < true | false >","title":"Queue Monitor Length"},{"location":"roles/eos_cli_config_gen/#service-routing-protocols-model","text":"service_routing_protocols_model : < multi-agent | ribd >","title":"Service Routing Protocols Model"},{"location":"roles/eos_cli_config_gen/#lldp","text":"lldp : timer : < transmission_time > holdtime : < hold_time_period > management_address : < all | ethernetN | loopbackN | managementN | port-channelN | vlanN > vrf : < vrf_name > run : < true | false >","title":"LLDP"},{"location":"roles/eos_cli_config_gen/#logging","text":"logging : console : < severity_level > monitor : < severity_level > buffered : size : < messages_nb (minimum of 10) > level : < severity_level > trap : < severity_level > source_interface : < source_interface_name > vrfs : < vrf_name > : source_interface : < source_interface_name > hosts : - < syslog_server_1> - < syslog_server_2>","title":"Logging"},{"location":"roles/eos_cli_config_gen/#domain-lookup","text":"ip_domain_lookup : source_interfaces : < source_interface_1 > : vrf : < vrf_name >","title":"Domain Lookup"},{"location":"roles/eos_cli_config_gen/#name-servers","text":"name_server : source : vrf : < vrf_name > nodes : - < name_server_1 > - < name_server_2 >","title":"Name Servers"},{"location":"roles/eos_cli_config_gen/#dns-domain","text":"dns_domain : < domain_name >","title":"DNS Domain"},{"location":"roles/eos_cli_config_gen/#ntp-servers","text":"ntp_server : local_interface : vrf : < vrf_name > interface : < source_interface > nodes : - < ntp_server_1 > - < ntp_server_2 >","title":"NTP Servers"},{"location":"roles/eos_cli_config_gen/#router-l2-vpn","text":"router_l2_vpn : nd_rs_flooding_disabled : < true | false > virtual_router_nd_ra_flooding_disabled : < true | false > arp_selective_install : < true | false > arp_proxy : prefix_list : < prefix_list_name >","title":"Router L2 VPN"},{"location":"roles/eos_cli_config_gen/#sflow","text":"sflow : sample : < sample_rate > dangerous : < true | false > vrfs : <vrf_name_1> : destinations : < sflow_destination_ip_1> : < sflow_destination_ip_2> : port : < port_number > source_interface : < source_interface > <vrf_name_2> : destinations : < sflow_destination_ip_1> : source_interface : < source_interface > destinations : < sflow_destination_ip_1 > : < sflow_destination_ip_2 > : source_interface : < source_interface > run : < true | false >","title":"Sflow"},{"location":"roles/eos_cli_config_gen/#redundancy","text":"Redundancy : protocol : < redundancy_protocol >","title":"Redundancy"},{"location":"roles/eos_cli_config_gen/#snmp-settings","text":"snmp_server : contact : < contact_name > location : < location > local_interfaces : - name : < interface_name_1 > vrf : < vrf_name > - name : < interface_name_2 > views : - name : < view_name > MIB_family_name : < MIB_family_name > included : < true | false > - name : < view_name > MIB_family_name : < MIB_family_name > included : < true | false > groups : - name : < group_name > version : < v1 | v2c | v3 > authentication : < auth | noauth | priv > read : < read_view > write : < write_view > notify : < notify_view > - name : < group_name > version : < v1 | v2c | v3 > authentication : < auth | noauth | priv > read : < read_view > users : - name : < username > group : < group_name > version : < v1 | v2c | v3 > auth : < hash_algorithm > auth_passphrase : < encrypted_auth_passphrase > priv : < encryption_algorithm > priv_passphrase : < encrypted_priv_passphrase > - name : < username > group : < group_name > version : < v1 | v2c | v3 > hosts : - host : < host IP address or name > vrf : < vrf_name > users : - username : < username > authentication_level : < auth | noauth | priv > version : < 1 | 2c | 3 > - host : < host IP address or name > vrf : < vrf_name > users : - username : < username > authentication_level : < auth | noauth | priv > version : < 1 | 2c | 3 > traps : enable : < true | false > vrfs : - name : < vrf_name > enable : < true | false > - name : < vrf_name > enable : < true | false >","title":"SNMP Settings"},{"location":"roles/eos_cli_config_gen/#spanning-tree","text":"spanning_tree : edge_port : bpduguard_default : < true | false > mode : < spanning_tree_mode > priority : < priority_level > no_spanning_tree_vlan : < vlan_id >, < vlan_id >-< vlan_id >","title":"Spanning Tree"},{"location":"roles/eos_cli_config_gen/#platform","text":"platform : trident : forwarding_table_partition : < partition >","title":"Platform"},{"location":"roles/eos_cli_config_gen/#tacacs-servers","text":"tacacs_servers : hosts : - host : < host1_ip_address > vrf : < vrf_name > key : < encypted_key > - host : < host2_ip_address > key : < encypted_key >","title":"Tacacs+ Servers"},{"location":"roles/eos_cli_config_gen/#aaa-server-groups","text":"aaa_server_groups : - name : < server_group_name > type : < tacacs+ | radius | ldap > servers : - server : < server1_ip_address > vrf : < vrf_name > - server : < server1_ip_address > vrf : < vrf_name > - name : < server_group_name > type : < tacacs+ | radius | ladp > servers : - server : < host1_ip_address >","title":"AAA Server Groups"},{"location":"roles/eos_cli_config_gen/#aaa-authentication","text":"aaa_authentication : login : default : < group | local | none > serial_console : < group | local | none >","title":"AAA Authentication"},{"location":"roles/eos_cli_config_gen/#aaa-authorization","text":"aaa_authorization : exec_default : < group | local | none > config_commands : < true | false >","title":"AAA Authorization"},{"location":"roles/eos_cli_config_gen/#aaa-accounting","text":"aaa_accounting : exec : default : type : < none | start-stop | stop-only > group : < group_name > commands : commands_default : - commands : < all | 0-15 > type : < none | start-stop | stop-only > group : < group_name > logging : < true | false > - commands : < all | 0-15 > type : < none | start-stop | stop-only > logging : < true | false >","title":"AAA Accounting"},{"location":"roles/eos_cli_config_gen/#local-users","text":"local_users : < user_1 > : privilege : < 1-15 > role : < role > sha512_password : \"< sha_512_password >\" < user_2 > : privilege : < 1-15 > role : < role > sha512_password : \"< sha_512_password >\"","title":"Local Users"},{"location":"roles/eos_cli_config_gen/#clock-timezone","text":"clock : timezone : < timezone >","title":"Clock Timezone"},{"location":"roles/eos_cli_config_gen/#vlans","text":"vlans : < vlan_id > : name : < vlan_name > state : < active | suspend > trunk_groups : - < trunk_group_name_1 > - < trunk_group_name_2 > < vlan_id > : name : < vlan_name >","title":"VLANs"},{"location":"roles/eos_cli_config_gen/#vrf-instances","text":"vrfs : < vrf_name > : description : < description> ip_routing : < true | false > ipv6_routing : < true | false > < vrf_name > : description : < description> ip_routing : < true | false > ipv6_routing : < true | false >","title":"VRF Instances"},{"location":"roles/eos_cli_config_gen/#bfd-multihop-interval","text":"bfd_multihop : interval : < rate in milliseconds > min_rx : < rate in milliseconds > multiplier : < 3-50 >","title":"Bfd Multihop Interval"},{"location":"roles/eos_cli_config_gen/#port-channel-interfaces","text":"port_channel_interfaces : < Port-Channel_interface_1 > : description : < description > shutdown : < true | false > vlans : \"< list of vlans as string >\" mode : < access | dot1q-tunnel | trunk > mlag : < mlag_id > trunk_groups : - < trunk_group_name_1 > - < trunk_group_name_2 > qos : trust : < cos | dscp > < Port-Channel_interface_2 > : description : < description > vlans : \"< list of vlans as string >\" mode : < access | dot1q-tunnel | trunk > spanning_tree_bpdufilter : < true | false > spanning_tree_bpduguard : < true | false > spanning_tree_portfast : < portfast_mode > vmtracer : < true | false > < Port-Channel_interface_3 > : description : < description > mtu : < mtu > type : < switched | routed > ip_address : < IP_address/mask > ipv6_enable : < true | false > ipv6_address : < IPv6_address/mask > ipv6_address_link_local : < link_local_IPv6_address/mask > ipv6_nd_ra_disabled : < true | false > ipv6_nd_managed_config_flag : < true | false > ipv6_nd_prefixes : < IPv6_address_1/Mask > : valid_lifetime : < infinite or lifetime in seconds > preferred_lifetime : < infinite or lifetime in seconds > no_autoconfig_flag : < true | false > < IPv6_address_2/Mask > : access_group_in : < access_list_name > access_group_out : < access_list_name > ipv6_access_group_in : < ipv6_access_list_name > ipv6_access_group_out : < ipv6_access_list_name > pim : ipv4 : sparse_mode : < true | false >","title":"Port-Channel Interfaces"},{"location":"roles/eos_cli_config_gen/#ethernet-interfaces","text":"# Routed Interfaces ethernet_interfaces : <Ethernet_interface_1 > : description : < description > shutdown : < true | false > speed : < interface_speed > mtu : < mtu > type : < routed | switched > vrf : < vrf_name > ip_address : < IPv4_address/Mask > ipv6_enable : < true | false > ipv6_address : < IPv6_address/Mask > ipv6_address_link_local : < link_local_IPv6_address/Mask > ipv6_nd_ra_disabled : < true | false > ipv6_nd_managed_config_flag : < true | false > ipv6_nd_prefixes : < IPv6_address_1/Mask > : valid_lifetime : < infinite or lifetime in seconds > preferred_lifetime : < infinite or lifetime in seconds > no_autoconfig_flag : < true | false > < IPv6_address_2/Mask > : access_group_in : < access_list_name > access_group_out : < access_list_name > ipv6_access_group_in : < ipv6_access_list_name > ipv6_access_group_out : < ipv6_access_list_name > ospf_network_point_to_point : < true | false > ospf_area : < ospf_area > pim : ipv4 : sparse_mode : < true | false > isis_enable : < ISIS Instance > isis_passive : < boolean > isis_metric : < integer > isis_network_point_to_point : < boolean > # Switched Interfaces <Ethernet_interface_2 > : description : < description > shutdown : < true | false > speed : < interface_speed > mtu : < mtu > vlans : \"< list of vlans as string >\" native_vlan : <native vlan number> mode : < access | dot1q-tunnel | trunk > flowcontrol : received : < received | send | on > channel_group : id : < Port-Channel_id > mode : < on | active | passive > qos : trust : < cos | dscp > spanning_tree_bpdufilter : < true | false > spanning_tree_bpduguard : < true | false > spanning_tree_portfast : < portfast_mode > vmtracer : < true | false >","title":"Ethernet Interfaces"},{"location":"roles/eos_cli_config_gen/#loopback-interfaces","text":"loopback_interfaces : < Loopback_interface_1 > : description : < description > shutdown : < true | false > vrf : < vrf_name > ip_address : < IPv4_address/Mask > ipv6_enable : < true | false > ipv6_address : < IPv6_address/Mask > ospf_area : < ospf_area > < Loopback_interface_2 > : description : < description > ip_address : < IPv4_address/Mask > isis_enable : < ISIS Instance > isis_passive : < boolean > isis_metric : < integer > isis_network_point_to_point : < boolean >","title":"Loopback Interfaces"},{"location":"roles/eos_cli_config_gen/#management-interfaces","text":"management_interfaces : < Management_interface_1 > : description : < description > vrf : < vrf_name > ip_address : < IPv4_address/Mask > ipv6_enable : < true | false > ipv6_address : < IPv6_address/Mask > gateway : <IPv4 address of gateway> ipv6_gateway : <IPv6 address of gateway>","title":"Management Interfaces"},{"location":"roles/eos_cli_config_gen/#vlan-interfaces","text":"vlan_interfaces : < Vlan_id_1 > : description : < description > shutdown : < true | false > vrf : < vrf_name > ip_address : < IPv4_address/Mask > ip_address_secondary : < IPv4_address/Mask > ip_router_virtual_address : < IPv4_address > ip_router_virtual_address_secondary : < IPv4_address > ip_address_virtual : < IPv4_address/Mask > mtu : < mtu > ip_helpers : < ip_helper_address_1 > : source_interface : < source_interface_name > vrf : < vrf_name > < ip_helper_address_2 > : source_interface : < source_interface_name > ipv6_enable : < true | false > ipv6_address : < IPv6_address/Mask > ipv6_address_link_local : < link_local_IPv6_address/Mask > ipv6_nd_ra_disabled : < true | false > ipv6_nd_managed_config_flag : < true | false > ipv6_nd_prefixes : < IPv6_address_1/Mask > : valid_lifetime : < infinite or lifetime in seconds > preferred_lifetime : < infinite or lifetime in seconds > no_autoconfig_flag : < true | false > < IPv6_address_2/Mask > : access_group_in : < access_list_name > access_group_out : < access_list_name > ipv6_access_group_in : < ipv6_access_list_name > ipv6_access_group_out : < ipv6_access_list_name > multicast : ipv4 : source_route_export : enabled : < true | false > administrative_distance : < 1-255 > ospf_network_point_to_point : < true | false > ospf_area : < ospf_area > pim : ipv4 : sparse_mode : < true | false > local_interface : < local_interface_name > ipv6_virtual_router_address : < IPv6_address > isis_enable : < ISIS Instance > isis_passive : < boolean > isis_metric : < integer > isis_network_point_to_point : < boolean > mtu : < mtu > vrrp : virtual_router : < virtual_router_id > priority : < instance_priority > advertisement_interval : < advertisement_interval> preempt_delay_minimum : < minimum_preemption_delay > ipv4 : < virtual_ip_address > ipv6 : < virtual_ip_address > < Vlan_id_2 > : description : < description > ip_address : < IPv4_address/Mask >","title":"VLAN Interfaces"},{"location":"roles/eos_cli_config_gen/#vxlan-interface","text":"vxlan_tunnel_interface : Vxlan1 : description : < description > source_interface : < source_interface_name > virtual_router : encapsulation_mac_address : < mlag-system-id | ethernet_address (H.H.H) > vxlan_udp_port : < udp_port > vxlan_vni_mappings : vlans : < vlan_id_1 > : vni : < vni_id_1 > < vlan_id_2 > : vni : < vni_id_2 > vrfs : < vrf_name > : vni : < vni_id_3 > < vrf_name > : vni : < vni_id_4 >","title":"VxLAN Interface"},{"location":"roles/eos_cli_config_gen/#hardware-tcam-profiles","text":"tcam_profile : - < tcam_profile >","title":"Hardware TCAM Profiles"},{"location":"roles/eos_cli_config_gen/#mac-address-table","text":"mac_address_table : aging_time : < aging_time_in_seconds >","title":"MAC Address-table"},{"location":"roles/eos_cli_config_gen/#router-virtual-mac-address","text":"ip_virtual_router_mac_address : < mac_address (hh:hh:hh:hh:hh:hh) >","title":"Router Virtual MAC Address"},{"location":"roles/eos_cli_config_gen/#virtual-source-nat","text":"virtual_source_nat_vrfs : < vrf_name_1 > : ip_address : < IPv4_address > < vrf_name_2 > : ip_address : < IPv4_address >","title":"Virtual Source NAT"},{"location":"roles/eos_cli_config_gen/#ipv6-extended-access-lists","text":"ipv6_access_lists : < ipv6_access_list_name_1 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\" < sequence_id_2 > : action : \"< action as string >\" < ipv6_access_list_name_2 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\"","title":"IPv6 Extended Access-Lists"},{"location":"roles/eos_cli_config_gen/#ipv6-standard-access-lists","text":"ipv6_standard_access_lists : < ipv6_access_list_name_1 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\" < sequence_id_2 > : action : \"< action as string >\" < ipv6_access_list_name_2 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\"","title":"IPv6 Standard Access-Lists"},{"location":"roles/eos_cli_config_gen/#ip-extended-access-lists","text":"access_lists : < access_list_name_1 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\" < sequence_id_2 > : action : \"< action as string >\" < access_list_name_2 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\"","title":"IP Extended Access-Lists"},{"location":"roles/eos_cli_config_gen/#ip-standard-access-lists","text":"standard_access_lists : < access_list_name_1 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\" < sequence_id_2 > : action : \"< action as string >\" < access_list_name_2 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\"","title":"IP Standard Access-Lists"},{"location":"roles/eos_cli_config_gen/#static-routes","text":"static_routes : - vrf : < vrf_name, if vrf_name = default the route will be placed in the GRT > destination_address_prefix : < IPv4_network/Mask > gateway : < IPv4_address > distance : < 1-255 > tag : < 0-4294967295 > name : < description > - destination_address_prefix : < IPv4_network/Mask > gateway : < IPv4_address >","title":"Static Routes"},{"location":"roles/eos_cli_config_gen/#ipv6-static-routes","text":"ipv6_static_routes : - vrf : < vrf_name, if vrf_name = default the route will be placed in the GRT > destination_address_prefix : < IPv6_network/Mask > gateway : < IPv6_address > distance : < 1-255 > tag : < 0-4294967295 > name : < description > - destination_address_prefix : < IPv6_network/Mask > gateway : < IPv6_address >","title":"IPv6 Static Routes"},{"location":"roles/eos_cli_config_gen/#ip-routing","text":"ip_routing : < true | false >","title":"IP Routing"},{"location":"roles/eos_cli_config_gen/#prefix-lists","text":"prefix_lists : < prefix_list_name_1 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\" < sequence_id_2 > : action : \"< action as string >\" < prefix_list_name_2 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\"","title":"Prefix Lists"},{"location":"roles/eos_cli_config_gen/#ipv6-prefix-lists","text":"ipv6_prefix_lists : < ipv6_prefix_list_name_1 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\" < sequence_id_2 > : action : \"< action as string >\" < ipv6_prefix_list_name_2 > : sequence_numbers : < sequence_id_1 > : action : \"< action as string >\"","title":"IPv6 Prefix Lists"},{"location":"roles/eos_cli_config_gen/#ipv6-routing","text":"ipv6_unicast_routing : < true | false >","title":"IPv6 Routing"},{"location":"roles/eos_cli_config_gen/#mlag-configuration","text":"mlag_configuration : domain_id : < domain_id_name > local_interface : < interface_name > peer_address : < IPv4_address > peer_address_heartbeat : peer_ip : < IPv4_address > vrf : < vrf_name > dual_primary_detection_delay : < seconds > peer_link : < Port-Channel_id > reload_delay_mlag : < seconds > reload_delay_non_mlag : < seconds >","title":"MLAG Configuration"},{"location":"roles/eos_cli_config_gen/#community-lists","text":"community_lists : < community_list_name_1 > : action : \"< action as string >\" < community_list_name_2 > : action : \"< action as string >\"","title":"Community Lists"},{"location":"roles/eos_cli_config_gen/#route-maps","text":"route_maps : < route_map_name_1 > : sequence_numbers : < sequence_id_1 > : type : < permit | deny > description : < description > match : - \"< match rule 1 as string >\" - \"< match rule 2 as string >\" set : - \"< set as string >\" < sequence_id_2 > : type : < permit | deny > match : - \"< match as string >\" < route_map_name_2 > : sequence_numbers : < sequence_id_1 > : type : < permit | deny > description : < description > set : - \"< set rule 1 as string >\" - \"< set rule 2 as string >\"","title":"Route Maps"},{"location":"roles/eos_cli_config_gen/#peer-filters","text":"peer_filters : < peer_filter_name_1 : sequence_numbers : < sequence_id_1 > : match : \"< match as string >\" < sequence_id_2 > : match : \"< match as string >\" < peer_filter_name_2 : sequence_numbers : < sequence_id_1 > : match : \"< match as string >\"","title":"Peer Filters"},{"location":"roles/eos_cli_config_gen/#router-bgp-configuration","text":"router_bgp : as : < bgp_as > router_id : < IPv4_address > bgp_defaults : - \"< bgp command as string >\" - \"< bgp command as string >\" peer_groups : < peer_group_name_1> : type : < ipv4 | evpn > description : \"< description as string >\" shutdown : < true | false > peer_filter : < peer_filter > next_hop_unchanged : < true | false > update_source : < interface > bfd : < true | false > ebgp_multihop : < integer > next_hop_self : < true | false > password : \"< encrypted_password >\" send_community : < true | false > maximum_routes : < integer > weight : < weight_value > timers : < keepalive_hold_timer_values > < peer_group_name_2 > : type : < ipv4 | evpn > bgp_listen_range_prefix : < IP prefix range > peer_filter : < peer_filter > password : \"< encrypted_password >\" maximum_routes : < integer > neighbors : < IPv4_address_1 > : peer_group : < peer_group_name > remote_as : < bgp_as > description : \"< description as string >\" shutdown : < true | false > update_source : < interface > weight : < weight_value > timers : < keepalive_hold_timer_values > < IPv4_address_2 > : remote_as : < bgp_as > next_hop_self : < true | false > password : \"< encrypted_password >\" < IPv6_address_1 > : remote_as : < bgp_as > redistribute_routes : < route_type > : route_map : < route_map_name > < route_type > : route_map : < route_map_name > vlan_aware_bundles : < vlan_aware_bundle_name_1 > : rd : \"< route distinguisher >\" route_targets : both : - \"< route_target >\" import : - \"< route_target >\" - \"< route_target >\" export : - \"< route_target >\" - \"< route_target >\" redistribute_routes : - < learned > vlan : < vlan_range > < vlan_aware_bundle_name_2 > : rd : \"< route distinguisher >\" route_targets : both : - \"< route_target >\" import : - \"< route_target >\" - \"< route_target >\" export : - \"< route_target >\" - \"< route_target >\" redistribute_routes : - < connected > - < learned > vlan : < vlan_range > vlans : < vlan_id_1> : rd : \"< route distinguisher >\" route_targets : both : - \"< route_target >\" redistribute_routes : - < connected > - < learned > <vlan_id_2 > : rd : \"< route distinguisher >\" route_targets : import : - \"< route_target >\" - \"< route_target >\" export : - \"< route_target >\" - \"< route_target >\" redistribute_routes : - < connected > - < learned > address_family_evpn : peer_groups : < peer_group_name > : activate : < true | false > address_family_ipv4 : networks : < prefix_ipv4 > : route_map : < route_map_name > peer_groups : < peer_group_name > : route_map_in : < route_map_name > route_map_out : < route_map_name > activate : < true | false > < peer_group_name > : activate : < true | false > neighbors : < neighbor_ip_address> : activate : < true | false > prefix_list_in : < prefix_list_name > prefix_list_out : < prefix_list_name > < neighbor_ip_address> : activate : < true | false > default_originate : always : < true | false > route_map : < route_map_name > address_family_ipv4_multicast : peer_groups : < peer_group_name > : activate : < true | false > < peer_group_name > : activate : < true | false > neighbors : < neighbor_ip_address> : redistribute_routes : < route_type > : address_family_ipv6 : peer_groups : < peer_group_name > : activate : < true | false > route_map_in : < route_map_name > route_map_out : < route_map_name > < peer_group_name > : activate : true neighbors : < neighbor_ip_address> : route_map_in : < route_map_name > route_map_out : < route_map_name > activate : < true | false > redistribute_routes : < route_type > : route_map : < route_map_name > < route_type > : route_map : < route_map_name > vrfs : < vrf_name_1 > : rd : \"< route distinguisher >\" route_targets : import : < address_family > : - \"< route_target >\" - \"< route_target >\" < address_family > : - \"< route_target >\" - \"< route_target >\" export : < address_family > : - \"< route_target >\" - \"< route_target >\" neighbors : < neighbor_ip_address > : remote_as : < asn > < neighbor_ip_address > : remote_as : < asn > redistribute_routes : < route_type > : route_map : < route_map_name > < route_type > : route_map : < route_map_name > < vrf_name_2 > : rd : \"<route distinguisher >\" route_targets : import : < address_family > : - \"< route_target >\" - \"< route_target >\" < address_family > : - \"< route_target >\" - \"< route_target >\" export : < address_family > : - \"< route_target >\" - \"< route_target >\" redistribute_routes : < route_type > : route_map : < route_map_name > < route_type > : route_map : < route_map_name >","title":"Router BGP Configuration"},{"location":"roles/eos_cli_config_gen/#routing-multicast","text":"router_multicast : ipv4 : routing : < true | false >","title":"Routing - Multicast"},{"location":"roles/eos_cli_config_gen/#router-ospf-configuration","text":"router_ospf : process_ids : < process_id > : passive_interface_default : < true | false > router_id : < IPv4_address > no_passive_interfaces : - < interface_1 > - < interface_2 > max_lsa : < integer > default_information_originate : always : true redistribute : static : route_map : < route_map_name > connected : route_map : < route_map_name >","title":"Router OSPF Configuration"},{"location":"roles/eos_cli_config_gen/#routing-pim-sparse-mode","text":"router_pim_sparse_mode : ipv4 : rp_addresses : < rp_address_1 > : groups : < group_prefix_1/mask > : < group_prefix_2/mask > : < rp_address_2 > : anycast_rps : < anycast_rp_address_1 > : other_anycast_rp_addresses : < ip_address_other_anycast_rp_1 > : register_count : < register_count_nb >","title":"Routing PIM Sparse Mode"},{"location":"roles/eos_cli_config_gen/#router-isis-configuration","text":"router_isis : instance : <ISIS Instance Name> net : < CLNS Address to run ISIS | format 49.0001.0001.0000.0001.00 > router_id : < IPv4_address > no_passive_interfaces : < List no-passive-interface > is_type : < level-1 | level-1-2 | level-2 > address_family : < List of Address Families > isis_af_defaults : - maximum-paths < Integer 1-64 >","title":"Router ISIS Configuration"},{"location":"roles/eos_cli_config_gen/#queue-monitor-streaming","text":"queue_monitor_streaming : enable : < true | false >","title":"Queue Monitor Streaming"},{"location":"roles/eos_cli_config_gen/#ip-tacacs-source-interfaces","text":"ip_tacacs_source_interfaces : - name : <interface_name_1 > vrf : < vrf_name_1 > - name : <interface_name_2 >","title":"IP TACACS+ Source Interfaces"},{"location":"roles/eos_cli_config_gen/#vm-tracer-sessions","text":"vmtracer_sessions : < vmtracer_session_name_1 > : url : < url > username : < username > password : < encrypted_password > autovlan_disable : < true | false > source_interface : < interface_name > < vmtracer_session_name_2 > : url : < url > username : < username > password : < encrypted_password >","title":"VM Tracer Sessions"},{"location":"roles/eos_cli_config_gen/#banners","text":"banners : login : | < text ending with EOF > motd : | < text ending with EOF >","title":"Banners"},{"location":"roles/eos_cli_config_gen/#http-management-api","text":"management_api_http : enable_http : < true | false > enable_https : < true | false > enable_vrfs : < vrf_name_1 > : access_group : < Standard IPv4 ACL name > ipv6_access_group : < Standard IPv6 ACL name > < vrf_name_2 > :","title":"HTTP Management API"},{"location":"roles/eos_cli_config_gen/#management-console","text":"management_console : idle_timeout : < 0-86400 in minutes >","title":"Management Console"},{"location":"roles/eos_cli_config_gen/#management-security","text":"management_security : password : encryption_key_common : < true | false >","title":"Management Security"},{"location":"roles/eos_cli_config_gen/#management-ssh","text":"management_ssh : access_groups : - name : < standard_acl_name_1 > : - name : < standard_acl_name_2 > : vrf : < vrf name > ipv6_access_groups : - name : < standard_acl_name_1 > : - name : < standard_acl_name_2 > : vrf : < vrf name > idle_timeout : < 0-86400 in minutes > enable : < true | false > vrfs : < vrf_name_1 > : enable : < true | false > < vrf_name_2 > : enable : < true | false >","title":"Management SSH"},{"location":"roles/eos_cli_config_gen/#license","text":"Project is published under Apache 2.0 License","title":"License"},{"location":"roles/eos_config_deploy_cvp/","text":"Ansible Role: eos_config_deploy_cvp # Table of Contents: Ansible Role: eos_config_deploy_eapi Overview Role requirements Role Inputs and Outputs Inputs Module variables Getting Started Add additional configlets Run module with different tags Outputs Tasks Requirements License Overview # eos_config_deploy_cvp , is a role that deploys the configuration to Arista EOS devices via CloudVision Management platform. The eos_config_deploy_cvp role: Designed to configure CloudVision with fabric configlets & topology. Deploy intended configlets to devices and execute pending tasks. Role requirements # This role requires to install arista.cvp collection to support CloudVision interactions. $ ansible-galaxy collection install arista.cvp NOTE : When using ansible-cvp modules, the user that is executing the ansible-playbook has to have access to both CVP and the EOS CLI. Role Inputs and Outputs # Figure 1 below provides a visualization of the roles inputs, and outputs and tasks in order executed by the role. Read inventory file Build containers topology Role looks for configuration previously generated by arista.avd.eos_cli_config_gen List configuration and build configlets list, one per device. Role looks for additional configlets to attach to either devices or containers. Build CloudVision configuration using arista.cvp collection: Build configlets on CV. Create containers topology. Move devices to container. Bind Configlet to device. Deploy Fabric configuration by running all pending tasks (optional, if execute_tasks == true). Inputs # Inventory configuration: An entry must be part of the inventory to describe CloudVision server. arista.cvp modules use httpapi approach. Example below provides framework to use in your inventory. all : children : cloudvision : hosts : cv_server01 : ansible_httpapi_host : 10.83.28.164 ansible_host : 10.83.28.164 ansible_user : ansible ansible_password : ansible ansible_connection : httpapi ansible_httpapi_use_ssl : True ansible_httpapi_validate_certs : False ansible_network_os : eos ansible_httpapi_port : 443 # Configuration to get Virtual Env information ansible_python_interpreter : $(which python3) Module variables # container_root : Inventory group name where Fabric devices are located. Default: all . configlets_prefix : Prefix to use for configlet on CV side. Default: {{ fabric_name }} . device_filter : Filter to target a specific set of devices on CV side. Default: AVD-{{ fabric_name }}- . state : present / absent . Support creation or cleanup topology on CV server. Default: present . execute_tasks : true / false . Support automatically excuting pending tasks. Default: false . cvp_configlets : Structure to add additional configlets to those automatically generated by AVD roles. Getting Started # tasks : - name : run CVP provisioning import_role : name : eos_config_deploy_cvp vars : container_root : 'DC1_FABRIC' configlets_prefix : 'DC1-AVD' device_filter : 'DC1' state : present execute_tasks : false Add additional configlets # This structure MUST be part of group_vars targeting container_root . Below is an example applied to eos_l3_evpn : # group_vars/DC1_FABRIC.yml # List of additional CVP configlets to bind to devices and containers # Configlets MUST be configured on CVP before running AVD playbooks. cv_configlets : containers : <name of container> : - <First configlet to attach> - <Second configlet to attach> - <...> devices : <inventory_hostname> : - <First configlet to attach> - <Second configlet to attach> - <...> <inventory_hostname> : - <First configlet to attach> - <Second configlet to attach> - <...> Full example: # group_vars/DC1_FABRIC.yml # List of additional CVP configlets to bind to devices and containers # Configlets MUST be configured on CVP before running AVD playbooks. cv_configlets : containers : DC1_L3LEAFS : - GLOBAL-ALIASES devices : DC1-L2LEAF2A : - GLOBAL-ALIASES DC1-L2LEAF2B : - GLOBAL-ALIASES Notes: These configlets MUST be created previously on CloudVision server and won\u2019t be managed by AVD roles. Current version does not support configlets unbound from container for safety reason. In such case, configlets should be removed from variables and manually unbind from containers on Cloudvision. Run module with different tags # This module also supports tags to run a subset of ansible tasks: build : Generate Arista Validated Design configuration for EOS devices (structure_configs / configs / documentation) and CloudVision inputs. provision : Run build tags + configure Cloudvision with information generated in previous tasks $ ansible-playbook playbook.to.deploy.with.cvp.yml --tags \"provision\" Outputs # None. Tasks # Copy generated configuration to CloudVision static configlets. Create container topology and attach devices to correct container Bind configlet to devices. Apply generated tasks to deploy configuration to devices. Requirements # Requirements are located here: avd-requirements License # Project is published under Apache 2.0 License","title":"eos_config_deploy_cvp"},{"location":"roles/eos_config_deploy_cvp/#ansible-role-eos_config_deploy_cvp","text":"Table of Contents: Ansible Role: eos_config_deploy_eapi Overview Role requirements Role Inputs and Outputs Inputs Module variables Getting Started Add additional configlets Run module with different tags Outputs Tasks Requirements License","title":"Ansible Role: eos_config_deploy_cvp"},{"location":"roles/eos_config_deploy_cvp/#overview","text":"eos_config_deploy_cvp , is a role that deploys the configuration to Arista EOS devices via CloudVision Management platform. The eos_config_deploy_cvp role: Designed to configure CloudVision with fabric configlets & topology. Deploy intended configlets to devices and execute pending tasks.","title":"Overview"},{"location":"roles/eos_config_deploy_cvp/#role-requirements","text":"This role requires to install arista.cvp collection to support CloudVision interactions. $ ansible-galaxy collection install arista.cvp NOTE : When using ansible-cvp modules, the user that is executing the ansible-playbook has to have access to both CVP and the EOS CLI.","title":"Role requirements"},{"location":"roles/eos_config_deploy_cvp/#role-inputs-and-outputs","text":"Figure 1 below provides a visualization of the roles inputs, and outputs and tasks in order executed by the role. Read inventory file Build containers topology Role looks for configuration previously generated by arista.avd.eos_cli_config_gen List configuration and build configlets list, one per device. Role looks for additional configlets to attach to either devices or containers. Build CloudVision configuration using arista.cvp collection: Build configlets on CV. Create containers topology. Move devices to container. Bind Configlet to device. Deploy Fabric configuration by running all pending tasks (optional, if execute_tasks == true).","title":"Role Inputs and Outputs"},{"location":"roles/eos_config_deploy_cvp/#inputs","text":"Inventory configuration: An entry must be part of the inventory to describe CloudVision server. arista.cvp modules use httpapi approach. Example below provides framework to use in your inventory. all : children : cloudvision : hosts : cv_server01 : ansible_httpapi_host : 10.83.28.164 ansible_host : 10.83.28.164 ansible_user : ansible ansible_password : ansible ansible_connection : httpapi ansible_httpapi_use_ssl : True ansible_httpapi_validate_certs : False ansible_network_os : eos ansible_httpapi_port : 443 # Configuration to get Virtual Env information ansible_python_interpreter : $(which python3)","title":"Inputs"},{"location":"roles/eos_config_deploy_cvp/#module-variables","text":"container_root : Inventory group name where Fabric devices are located. Default: all . configlets_prefix : Prefix to use for configlet on CV side. Default: {{ fabric_name }} . device_filter : Filter to target a specific set of devices on CV side. Default: AVD-{{ fabric_name }}- . state : present / absent . Support creation or cleanup topology on CV server. Default: present . execute_tasks : true / false . Support automatically excuting pending tasks. Default: false . cvp_configlets : Structure to add additional configlets to those automatically generated by AVD roles.","title":"Module variables"},{"location":"roles/eos_config_deploy_cvp/#getting-started","text":"tasks : - name : run CVP provisioning import_role : name : eos_config_deploy_cvp vars : container_root : 'DC1_FABRIC' configlets_prefix : 'DC1-AVD' device_filter : 'DC1' state : present execute_tasks : false","title":"Getting Started"},{"location":"roles/eos_config_deploy_cvp/#add-additional-configlets","text":"This structure MUST be part of group_vars targeting container_root . Below is an example applied to eos_l3_evpn : # group_vars/DC1_FABRIC.yml # List of additional CVP configlets to bind to devices and containers # Configlets MUST be configured on CVP before running AVD playbooks. cv_configlets : containers : <name of container> : - <First configlet to attach> - <Second configlet to attach> - <...> devices : <inventory_hostname> : - <First configlet to attach> - <Second configlet to attach> - <...> <inventory_hostname> : - <First configlet to attach> - <Second configlet to attach> - <...> Full example: # group_vars/DC1_FABRIC.yml # List of additional CVP configlets to bind to devices and containers # Configlets MUST be configured on CVP before running AVD playbooks. cv_configlets : containers : DC1_L3LEAFS : - GLOBAL-ALIASES devices : DC1-L2LEAF2A : - GLOBAL-ALIASES DC1-L2LEAF2B : - GLOBAL-ALIASES Notes: These configlets MUST be created previously on CloudVision server and won\u2019t be managed by AVD roles. Current version does not support configlets unbound from container for safety reason. In such case, configlets should be removed from variables and manually unbind from containers on Cloudvision.","title":"Add additional configlets"},{"location":"roles/eos_config_deploy_cvp/#run-module-with-different-tags","text":"This module also supports tags to run a subset of ansible tasks: build : Generate Arista Validated Design configuration for EOS devices (structure_configs / configs / documentation) and CloudVision inputs. provision : Run build tags + configure Cloudvision with information generated in previous tasks $ ansible-playbook playbook.to.deploy.with.cvp.yml --tags \"provision\"","title":"Run module with different tags"},{"location":"roles/eos_config_deploy_cvp/#outputs","text":"None.","title":"Outputs"},{"location":"roles/eos_config_deploy_cvp/#tasks","text":"Copy generated configuration to CloudVision static configlets. Create container topology and attach devices to correct container Bind configlet to devices. Apply generated tasks to deploy configuration to devices.","title":"Tasks"},{"location":"roles/eos_config_deploy_cvp/#requirements","text":"Requirements are located here: avd-requirements","title":"Requirements"},{"location":"roles/eos_config_deploy_cvp/#license","text":"Project is published under Apache 2.0 License","title":"License"},{"location":"roles/eos_config_deploy_eapi/","text":"Ansible Role: eos_config_deploy_eapi # Table of Contents: Ansible Role: eos_config_deploy_eapi Overview Role Inputs and Outputs Requirements License Overview # eos_config_deploy_eapi , is a role that deploys the configuration to Arista EOS devices. The eos_config_deploy_eapi role: Designed to replace device running-configuration with intended configuration. Backup configuration after successfully change. Role Inputs and Outputs # Figure 1 below provides a visualization of the roles inputs, and outputs and tasks in order executed by the role. Inputs: Device configuration file in EOS CLI syntax. Outputs: Device running-configuration (backup). Tasks: Replace configuration on device with intended EOS configuration (Only when change is detected when configuration is generated). If changed, saves to startup-config, and notifies handler to backup configuration. Show running configuration of device (handler) Copy configuration to: ./config_backup/{{ inventory_hostname }}.cfg (handler) Requirements # Requirements are located here: avd-requirements License # Project is published under Apache 2.0 License","title":"eos_config_deploy_eapi"},{"location":"roles/eos_config_deploy_eapi/#ansible-role-eos_config_deploy_eapi","text":"Table of Contents: Ansible Role: eos_config_deploy_eapi Overview Role Inputs and Outputs Requirements License","title":"Ansible Role: eos_config_deploy_eapi"},{"location":"roles/eos_config_deploy_eapi/#overview","text":"eos_config_deploy_eapi , is a role that deploys the configuration to Arista EOS devices. The eos_config_deploy_eapi role: Designed to replace device running-configuration with intended configuration. Backup configuration after successfully change.","title":"Overview"},{"location":"roles/eos_config_deploy_eapi/#role-inputs-and-outputs","text":"Figure 1 below provides a visualization of the roles inputs, and outputs and tasks in order executed by the role. Inputs: Device configuration file in EOS CLI syntax. Outputs: Device running-configuration (backup). Tasks: Replace configuration on device with intended EOS configuration (Only when change is detected when configuration is generated). If changed, saves to startup-config, and notifies handler to backup configuration. Show running configuration of device (handler) Copy configuration to: ./config_backup/{{ inventory_hostname }}.cfg (handler)","title":"Role Inputs and Outputs"},{"location":"roles/eos_config_deploy_eapi/#requirements","text":"Requirements are located here: avd-requirements","title":"Requirements"},{"location":"roles/eos_config_deploy_eapi/#license","text":"Project is published under Apache 2.0 License","title":"License"},{"location":"roles/eos_l3ls_evpn/","text":"Ansible Role: eos_l3ls_evpn # Table of Contents: Ansible Role: eos_l3ls_evpn Overview Role Inputs and Outputs Requirements Role Variables Common Device Configuration Variables Fabric Underlay and Overlay Topology Variables Fabric Topology Variables Type Variable Spine Variables L3 Leaf Variables L2 Leafs Variables Network Services Variables - VRFs/VLANs Server Edge Port Connectivity Single attached server scenario MLAG dual-attached server scenario Variable to attach additional configlets Event Handlers Platform Specific settings vEOS-LAB Know Caveats and Recommendations License Overview # eos_l3ls_evpn , is a role that provides an abstracted data model to deploy a L3 Leaf and Spine fabric leveraging VXLAN data-plane with an EVPN control-plane. The eos_l3ls_evpn role: Enables network engineers to deploy Arista L3 Leaf & Spine fabric underlay and overlay network services effectively and with consistency. Designed to be extended easily, leveraging a \u201cstackable template architecture\u201d . Designed to be used with the eos_l3ls_config_gen role to generate a complete switch configuration and applied using a config replace strategy with either eos_config_deploy_eapi role. eos_config_deploy_cvp role. Designed to generate the intended configuration offline, without relying on switch current state information. Facilitates the evaluation of the configuration prior to deployment with tools like Batfish Role Inputs and Outputs # Figure 1 below provides a visualization of the roles inputs, and outputs and tasks in order executed by the role. Inputs: Desired variables are defined in: role defaults, group_vars, and host_vars variables. If desired, the role can be extended to leverage data from dynamic sources such as an IPAM or CMDB. Outputs: A structured EOS configuration file in yaml format. This provides the following benefits: First, this allows us to naturally detect duplicate entries from inputs, as yaml dictionaries don\u2019t process duplicate keys. Leverage the structured data to create eos cli configuration. Leverage the structured data to create end user documentation. Leverage the structured data for pre and post fabric tests. Fabric Documentation in Markdown format. Leaf and Spine Topology summary in csv format. Tasks: Generate device configuration in a structured format (yaml). Include device structured configuration that was previously generated. Generate VXLAN/EVPN fabric documentation in Markdown format. Generate Leaf and Spine point-to-point links summary in CSV format. Generate Leaf and Spine physical topology summary in CSV format. Requirements # Requirements are located here: avd-requirements Role Variables # The role variables are documented inline within yaml formated output with: \u201c< >\u201d Some variables are required while others are optional. Default values, are stored in the role defaults main.yml file. Role variable are grouped by configuration elements and are typically stored in different group_vars files. Common Device Configuration Variables # Common device configuration variables are for elements not related specifically to the fabric configuration. The variables should be applied to all devices within the fabric and can be shared with other infrastructure elements. Variables and Options: # Clock timezone | Optional timezone : < timezone > # Dictionary of local users | Required local_users : < username_1 > : privilege : < (1-15) Initial privilege level with local EXEC authorization > role : < Specify a role for the user > sha512_password : \"< SHA512 ENCRYPTED password >\" < username_2 > : privilege : < (1-15) Initial privilege level with local EXEC authorization > role : < Specify a role for the user > sha512_password : \"< SHA512 ENCRYPTED password >\" # Management eAPI | Required # Default is https management eAPI enabled management_eapi : enable_http : < boolean | default -> false > enable_https : < boolean | default -> true > # CloudVision - Telemetry Agent (TerminAttr) configuration | Optional cvp_instance_ip : < IPv4 address > or cvp_instance_ips : - < IPv4 address > - < IPv4 address > - < IPv4 address > cvp_ingestauth_key : < CloudVision Ingest Authentication key > terminattr_ingestgrpcurl_port : < port_number | default -> 9910 > terminattr_smashexcludes : \"< smash excludes | default -> ale,flexCounter,hardware,kni,pulse,strata >\" terminattr_ingestexclude : \"< ingest excludes | default -> /Sysdb/cell/1/agent,/Sysdb/cell/2/agent >\" # Management interface configuration | Required mgmt_vrf_routing : < boolean | default -> false > mgmt_interface : < mgmt_interface | default -> Management1 > mgmt_interface_vrf : < vrf_name | default -> MGMT > mgmt_gateway : < IPv4 address > # OOB mgmt interface destination networks - override default route mgmt_destination_networks : - < IPv4_network/Mask > - < IPv4_network/Mask > # list of DNS servers | Optional name_servers : - < IPv4_address_1 > - < IPv4_address_2 > # List of NTP Servers IP or DNS name | Optional # The first NTP server in the list will be preferred # NTP request will be sourced from < management_interface_vrf > ntp_servers : - < ntp_server_1 > - < ntp_server_1 > # Internal vlan allocation order and range | Required internal_vlan_order : allocation : < ascending or descending | default -> ascending > range : beginning : < vlan_id | default -> 1006 > ending : < vlan_id | default -> 1199 > # Redundancy for chassis platforms with dual supervisors | Optional redundancy : protocol : < sso | rpr > # MAC address-table aging time | Optional # Use to change the EOS default of 300 mac_address_table : aging_time : < time_in_seconds > Example: note: Default values are commented # Timezone timezone : \"US/Eastern\" # local users local_users : admin : privilege : 15 role : network-admin sha512_password : \"$6$Df86J4/SFMDE3/1K$Hef4KstdoxNDaami37cBquTWOTplC.miMPjXVgQxMe92.e5wxlnXOLlebgPj8Fz1KO0za/RCO7ZIs4Q6Eiq1g1\" cvpadmin : privilege : 15 role : network-admin sha512_password : \"$6$rZKcbIZ7iWGAWTUM$TCgDn1KcavS0s.OV8lacMTUkxTByfzcGlFlYUWroxYuU7M/9bIodhRO7nXGzMweUxvbk8mJmQl8Bh44cRktUj.\" # Management eAPI # management_eapi: # enable_https: true # Cloud Vision server information cvp_instance_ips : - 192.168.2.201 - 192.168.2.202 - 192.168.2.203 cvp_ingestauth_key : telarista # terminattr_ingestgrpcurl_port: 9910 # terminattr_smashexcludes: \"ale,flexCounter,hardware,kni,pulse,strata\" # terminattr_ingestexclude: \"/Sysdb/cell/1/agent,/Sysdb/cell/2/agent # Management interface configuration mgmt_gateway : 192.168.2.1 # mgmt_vrf_routing: false # mgmt_interface: Management1 # mgmt_interface_vrf: MGMT # OOB mgmt interface destination networks # mgmt_destination_networks: # - 0.0.0.0/0 # DNS servers. name_servers : - 192.168.2.1 - 8.8.8.8 # NTP Servers ntp_servers : - 0.north-america.pool.ntp.org - 1.north-america.pool.ntp.org # Internal vlan allocation order and range # internal_vlan_order: # allocation: ascending # range: # beginning: 1006 # ending: 1199 # Redundancy for chassis platforms with dual supervisors redundancy : protocol : sso # MAC address-table aging time mac_address_table : aging_time : 1500 Fabric Underlay and Overlay Topology Variables # The fabric underlay and overlay topology variables, define the elements related to build the L3 Leaf and Spine fabric. The following underlay routing protocols are supported: BGP (default) OSPF. ISIS. Only summary network addresses need to be defined. IP addresses are then assigned to each node, based on its unique device id. To view IP address allocation and consumption, a summary is provided in the auto-generated fabric documentation in Markdown format. The variables should be applied to all devices in the fabric. Variables and Options: # Fabric Name, required to match group_var file name | Required. fabric_name : < Fabric_Name > # Underlay routing protocol | Required. underlay_routing_protocol : < BGP or OSPF or ISIS | Default -> BGP > # Underlay OSFP | Required when < underlay_routing_protocol > == OSPF underlay_ospf_process_id : < process_id | Default -> 100 > underlay_ospf_area : < ospf_area | Default -> 0.0.0.0 > underlay_ospf_max_lsa : < lsa | Default -> 12000 > # Underlay OSFP | Required when < underlay_routing_protocol > == ISIS isis_area_id : < isis area | Default -> \"49.0001\" > isis_site_id : < isis site ID | Default -> \"0001\" > # Point to Point Links MTU | Required. p2p_uplinks_mtu : < 0-9216 | default -> 9000 > # IP Summary for Point to Point interfaces between L3 leafs and spines used for underlay peering | Required # Assigned as /31 for each uplink interfaces # Assign network summary larger then: # [ total spines * total potential L3 leafs * 2 * max_l3leaf_to_spine_links(default: 1) ] underlay_p2p_network_summary : < IPv4_network/Mask > # IP address summary for BGP evpn overlay peering loopback for L3 leafs and spines | Required # Assigned as /32 to Loopback0 # Assign range larger then: # [ total spines + total potential L3 leafs ] overlay_loopback_network_summary : < IPv4_network/Mask > # IP address summary VTEP VXLAN Tunnel source loopback1 IP for L3 leafs | Required # Assigned as /32 to Loopback1 # Assign range larger then total L3 leafs vtep_loopback_network_summary : < IPv4_network/Mask > # IP address summary used for MLAG Peer Link (control link) and underlay L3 peering | *Required # * When MLAG leafs present in topology. # Assign range larger then total: L3 Leafs + 2 ] mlag_ips : leaf_peer_l3 : < IPv4_network/Mask > mlag_peer : < IPv4_network/Mask > # BGP peer groups encrypted password # IPv4_UNDERLAY_PEERS and MLAG_IPv4_UNDERLAY_PEER | Required when < underlay_routing_protocol > == BGP # EVPN_OVERLAY_PEERS | Required # Leverage an Arista EOS switch to generate the encrypted password bgp_peer_groups : IPv4_UNDERLAY_PEERS : password : \"< encrypted password >\" MLAG_IPv4_UNDERLAY_PEER : password : \"< encrypted password >\" EVPN_OVERLAY_PEERS : password : \"< encrypted password >\" # Spine BGP Tuning | Optional. spine_bgp_defaults : - update wait-for-convergence - update wait-install - no bgp default ipv4-unicast - distance bgp 20 200 200 - graceful-restart restart-time 300 - graceful-restart # Leaf BGP Tuning | Optional. leaf_bgp_defaults : - update wait-install - no bgp default ipv4-unicast - distance bgp 20 200 200 - graceful-restart restart-time 300 - graceful-restart # Enable vlan aware bundles for EVPN MAC-VRF | Required. vxlan_vlan_aware_bundles : < boolean | default -> false > # BFD Multihop tunning | Required. bfd_multihop : interval : < | default -> 300 > min_rx : < | default -> 300 > multiplier : < | default -> 3 > Example: note: Default values are commented # Defined in FABRIC.yml fabric_name : DC1_FABRIC # underlay_routing_protocol: BGP # underlay_ospf_process_id: 100 # underlay_ospf_area: 0.0.0.0 # underlay_ospf_max_lsa: 12000 # p2p_uplinks_mtu: 9000 underlay_p2p_network_summary : 172.31.255.0/24 overlay_loopback_network_summary : 192.168.255.0/24 vtep_loopback_network_summary : 192.168.254.0/24 mlag_ips : leaf_peer_l3 : 10.255.251.0/24 mlag_peer : 10.255.252.0/24 bgp_peer_groups : IPv4_UNDERLAY_PEERS : password : \"AQQvKeimxJu+uGQ/yYvv9w==\" EVPN_OVERLAY_PEERS : password : \"q+VNViP5i4rVjW1cxFv2wA==\" MLAG_IPv4_UNDERLAY_PEER : password : \"vnEaG8gMeQf3d3cN6PktXQ==\" # spine_bgp_defaults: # - update wait-for-convergence # - update wait-install # - no bgp default ipv4-unicast # - distance bgp 20 200 200 # - graceful-restart restart-time 300 # - graceful-restart # leaf_bgp_defaults: # - update wait-install # - no bgp default ipv4-unicast # - distance bgp 20 200 200 # - graceful-restart restart-time 300 # - graceful-restart # vxlan_vlan_aware_bundles: false # bfd_multihop: # interval: 300 # min_rx: 300 # multiplier: 3 Fabric Topology Variables # The fabric topology variables define the connectivity between the spines, L3 leafs, and L2 leafs. The variables should be applied to all devices in the fabric. Connectivity is defined from the child\u2019s device perspective. Source uplink interfaces and parent interfaces are defined on the child. A static unique identifier (id) is assigned to each device. This is leveraged to derive the IP address assignment from each summary defined in the Fabric Underlay and Overlay Topology Variables. Within the l3_leaf and l2_leaf dictionary variables, defaults can be defined. This reduces user input requirements, limiting errors. The default variables can be overridden when defined under the node groups. The ability to define a super-spine layer is planned for a future release of ansible-avd. Type Variable # The type: variable needs to be defined for each device in the fabric. This is leveraged to load to appropriate template, to generate the configuration. Variables and Options: # define the layer type type : < spine | l3leaf | l2leaf > Example: # Defined in SPINE.yml file type : spine # Defined in L3LEAFS.yml type : l3leaf # Defined in L2LEAFS.yml type : l2leaf Spine Variables # Variables and Options: # Defined in FABRIC.yml spine : # Arista platform family | Required. platform : < Arista Platform Family > # Spine BGP AS | Required. bgp_as : < bgp_as > # Accepted L3 leaf bgp as range | Required. leaf_as_range : < bgp_as_start-bgp_as_end > # Specify dictionary of Spine nodes | Required. nodes : < inventory_hostname > : # Unique identifier | Required. id : < integer > # Node management IP address | Required. mgmt_ip : < IPv4_address/Mask > < inventory_hostname > : id : < integer > mgmt_ip : < IPv4_address/Mask > Example: # Defined in FABRIC.yml spine : platform : vEOS-LAB bgp_as : 65001 leaf_as_range : 65101-65132 nodes : DC1-SPINE1 : id : 1 mgmt_ip : 192.168.2.101/24 DC1-SPINE2 : id : 2 mgmt_ip : 192.168.2.102/24 L3 Leaf Variables # Variables and Options: l3leaf : # L3 Leaf default variables, can be overridden when defined under < node_group >. defaults : # Arista platform family. | Required platform : < Arista Platform Family > # Parent spine switches (list), corresponding to uplink_to_spine_interfaces and spine_interfaces | Required. spines : [ < spine_inventory_hostname > , < spine_inventory_hostname > ] # Uplink to spine interfaces (list), interface located on L3 Leaf, # corresponding to spines and spine_interfaces | Required. uplink_to_spine_interfaces : [ < ethernet_interface_1 > , < ethernet_interface_2 > ] # Point-to-Point interface speed - will apply to L3 Leaf and Spine switches | Optional. p2p_link_interface_speed : < interface_speed > # MLAG interfaces (list) | Required when MLAG leafs present in topology. mlag_interfaces : [ < ethernet_interface_3 > , < ethernet_interface_4 > ] # Spanning tree mode (note - only mstp has been validated at this time) | Required. spanning_tree_mode : < mstp > # Spanning tree priority | Required. spanning_tree_priority : < spanning-tree priority > # Virtual router mac address for anycast gateway | Required. virtual_router_mac_address : < mac address > # The node groups are group of one or two nodes where specific variables can be defined related to the topology # and allowed L3 and L2 network services. # All variables defined under `defaults` dictionary can be defined under each node group to override it. node_groups : # node_group_1, will result in stand-alone leaf. < node_group_1 > : # L3 Leaf BGP AS. | Required. bgp_as : < bgp_as > # Filter L3 and L2 network services based on tenant and tags ( and operation filter )| Optional # If filter is not defined will default to all filter : tenants : [ < tenant_1 > , < tenant_2 > | default all ] tags : [ < tag_1 > , < tag_2 > | default -> all ] ] # Define one or two nodes - same name as inventory_hostname | Required # When two nodes are defined, this will create an MLAG pair. nodes : # First node < l3_leaf_inventory_hostname_1 > : # Unique identifier | Required. id : < integer > # Node management IP address | Required. mgmt_ip : < IPv4_address/Mask > # Spine interfaces (list), interface located on Spine, # corresponding to spines and uplink_to_spine_interfaces | Required. spine_interfaces : [ < ethernet_interface_1 > , < ethernet_interface_1 > ] # node_group_2, will result in MLAG pair. < node_group_2 > : bgp_as : < bgp_as > filter : tenants : [ < tenant_1 > , < tenant_2 > | default all ] tags : [ < tag_1 > , < tag_2 > | default -> all ] nodes : # Second node < l3_leaf_inventory_hostname_2 > : id : < integer > mgmt_ip : < IPv4_address/Mask > spine_interfaces : [ < ethernet_interface_2 > , < ethernet_interface_2 > ] # Third node < l3_leaf_inventory_hostname_3 > : id : < integer > mgmt_ip : < IPv4_address/Mask > spine_interfaces : [ < ethernet_interface_3 > , < ethernet_interface_3 > ] Example: # Defined in FABRIC.yml l3leaf : defaults : platform : vEOS-LAB bgp_as : 65100 spines : [ DC1-SPINE1 , DC1-SPINE2 ] uplink_to_spine_interfaces : [ Ethernet1 , Ethernet2 ] mlag_interfaces : [ Ethernet3 , Ethernet4 ] spanning_tree_mode : mstp spanning_tree_priority : 4096 virtual_router_mac_address : 00:1c:73:00:dc:01 node_groups : DC1_LEAF1 : bgp_as : 65101 filter : tenants : [ Tenant_A , Tenant_B , Tenant_C ] tags : [ opzone ] nodes : DC1-LEAF1A : id : 1 mgmt_ip : 192.168.2.105/24 spine_interfaces : [ Ethernet1 , Ethernet1 ] DC1_LEAF2 : bgp_as : 65102 filter : tenants : [ Tenant_A ] tags : [ opzone , web , app , db , vmotion , nfs ] nodes : DC1-LEAF2A : id : 2 mgmt_ip : 192.168.2.106/24 spine_interfaces : [ Ethernet2 , Ethernet2 ] DC1-LEAF2B : id : 3 mgmt_ip : 192.168.2.107/24 spine_interfaces : [ Ethernet3 , Ethernet3 ] DC1_SVC3 : bgp_as : 65103 filter : tenants : [ Tenant_A ] tags : [ erp1 ] nodes : DC1-SVC3A : id : 4 mgmt_ip : 192.168.2.108/24 spine_interfaces : [ Ethernet4 , Ethernet4 ] DC1-SVC3B : id : 5 mgmt_ip : 192.168.2.109/24 spine_interfaces : [ Ethernet5 , Ethernet5 ] L2 Leafs Variables # Variables and Options: l2leaf : # L2 Leaf default variables, can be overridden when defined under < node_group >. defaults : # Arista platform family. | Required platform : < Arista Platform Family > # Parent L3 switches (list), corresponding to uplink_interfaces and l3leaf_interfaces | Required. parent_l3leafs : [ DC1-LEAF2A , DC1-LEAF2B ] # Uplink interfaces (list), interface located on L2 Leaf, # corresponding to parent_l3leafs and l3leaf_interfaces | Required. uplink_interfaces : [ < ethernet_interface_1 > , < ethernet_interface_2 > ] # Point-to-Point interface speed - will apply to L2 Leaf and L3 Leaf switches | Optional. p2p_link_interface_speed : < interface_speed > # MLAG interfaces (list) | Required when MLAG leafs present in topology. mlag_interfaces : [ < ethernet_interface_3 > , < ethernet_interface_4 > ] # Spanning tree mode (note - only mstp has been validated at this time) | Required. spanning_tree_mode : < mstp > # Spanning tree priority | Required. spanning_tree_priority : < spanning-tree priority > # The node groups are group of one or two nodes where specific variables can be defined related to the topology # and allowed L3 and L2 network services. # All variables defined under `defaults` dictionary can be defined under each node group to override it. node_groups : # node_group_1, will result in stand-alone leaf. < node_group_1 > : # Filter L3 and L2 network services based on tenant and tags - and filter | Optional # If filter is not defined will default to all filter : tenants : [ < tenant_1 > , < tenant_2 > | default all ] tags : [ < tag_1 > , < tag_2 > | default -> all ] ] # Define one or two nodes - same name as inventory_hostname. # When two nodes are defined, this will create an MLAG pair. nodes : # First node < l2_leaf_inventory_hostname_1 > : # Unique identifier | Required. id : < integer > # Node management IP address | Required. mgmt_ip : < IPv4_address/Mask > # l3leaf interfaces (list), interface located on l3leaf, # corresponding to parent_l3leafs and uplink_interfaces | Required. l3leaf_interfaces : [ < ethernet_interface_6 > , < ethernet_interface_6 > ] # node_group_2, will result in MLAG pair. < node_group_1 > : parent_l3leafs : [ DC1-SVC3A , DC1-SVC3B ] nodes : # Second node. < l2_leaf_inventory_hostname_2 > : id : < integer > mgmt_ip : < IPv4_address/Mask > l3leaf_interfaces : [ < ethernet_interface_7 > , < ethernet_interface_7 > ] # Third node. < l2_leaf_inventory_hostname_3 > : id : < integer > mgmt_ip : < IPv4_address/Mask > l3leaf_interfaces : [ < ethernet_interface_8 > , < ethernet_interface_8 > ] Example: # Defined in FABRIC.yml l2leaf : defaults : platform : vEOS-LAB parent_l3leafs : [ DC1-LEAF2A , DC1-LEAF2B ] uplink_interfaces : [ Ethernet1 , Ethernet2 ] mlag_interfaces : [ Ethernet3 , Ethernet4 ] spanning_tree_mode : mstp spanning_tree_priority : 16384 node_groups : DC1_L2LEAF4 : uplink_interfaces : [ Ethernet11 , Ethernet12 ] filter : tenants : [ Tenant_A ] tags : [ opzone , web , app ] nodes : DC1-L2LEAF4A : id : 8 mgmt_ip : 192.168.2.112/24 l3leaf_interfaces : [ Ethernet6 , Ethernet6 ] DC1_L2LEAF5 : parent_l3leafs : [ DC1-SVC3A , DC1-SVC3B ] nodes : DC1-L2LEAF5A : id : 10 mgmt_ip : 192.168.2.113/24 l3leaf_interfaces : [ Ethernet5 , Ethernet5 ] DC1-L2LEAF5B : id : 11 mgmt_ip : 192.168.2.114/24 l3leaf_interfaces : [ Ethernet6 , Ethernet6 ] Network Services Variables - VRFs/VLANs # The network services variables provide an abstracted model to create L2 and L3 network services across the fabric. The network services are grouped by tenants. The definition of a tenant may vary between organizations. e.g. Tenants can be organizations or departments. The tenant shares a common vni range for mac vrf assignment. The filtering model allows for granular deployment of network service to the fabric leveraging the tenant name and tags applied to the service definition. This allows for the re-use of SVIs and VLANs across the fabric. Variables and Options: # On mlag leafs, an SVI interface is defined per vrf, to establish iBGP peering. | Required (when mlag leafs in topology) # The SVI id will be derived from the base vlan defined: mlag_ibgp_peering_vrfs.base_vlan + vrf_vni mlag_ibgp_peering_vrfs : base_vlan : < 1-4000 | default -> 3000 > # Dictionary of tenants, to define network services: L3 VRFs and L2 VLNAS. tenants : # Specify a tenant name. | Required # Tenant provide a construct to group L3 VRFs and L2 VLANs. # Networks services can be filtered by tenant name. < tenant_a > : # VXLAN Network Identifier for MAC VRF | Required. # VXLAN VNI is derived from the base number with simple addition. # e.g. mac_vrf_vni_base = 10000, svi 100 = VNI 10100, svi 300 = VNI 10300. mac_vrf_vni_base : < 10000-16770000 > # Define L3 network services organized by vrf. vrfs : # VRF name | Required < tenant_a_vrf_1 > : # VRF VNI | Required. # The VRF VNI range is limited. vrf_vni : <1-1024> # Enable VTEP Network diagnostics | Optional. # This will create a loopback with virtual source-nat enable to perform diagnostics from the switch. vtep_diagnostic : # Loopback interface number | Required (when vtep_diagnotics defined) loopback : < 2-2100 > # Loopback ip range, a unique ip is derived from this ranged and assigned # to each l3 leaf based on it's unique id. | Required (when vtep_diagnotics defined) loopback_ip_range : < IPv4_address/Mask > # Dictionary of SVIs | Required. # This will create both the L3 SVI and L2 VLAN based on filters applied to l3leaf and l2leaf. svis : # SVI interface id and VLAN id. | Required < 1-4096 > : # By default the vni will be derived from \"mac_vrf_vni_base:\" # The vni_override allows us to override this value and statically define it. | Optional vni_override : < 1-16777215 > # vlan name + svi description. | Required name : < description > # Tags leveraged for networks services filtering. | Required tags : [ < tag_1 > , < tag_2 > ] # Enable or disable interface enabled : < true | false > # ip address virtual to configure VXLAN Anycast IP address # Conserves IP addresses in VXLAN deployments as it doesn't require unique IP addresses on each node. # Optional ip_address_virtual: : < IPv4_address/Mask > # ip virtual-router address # note, also requires an IP address to be configured on the SVI where it is applied. # Optional ip_virtual_router_address : < IPv4_address/Mask > # Define node specific configuration, such as unique IP addresses. nodes : < l3_leaf_inventory_hostname_1 > : # device unique IP address for node. ip_address : < IPv4_address/Mask > < l3_leaf_inventory_hostname_2 > : ip_address : < IPv4_address/Mask > < 1-4096 > : name : < description > tags : [ < tag_1 > , < tag_2 > ] enabled : < true | false > ip_address_virtual : < IPv4_address/Mask > < tenant_a_vrf_2 > : vrf_vni : <1-1024> svis : < 1-4096 > : name : < description > tags : [ < tag_1 > , < tag_2 > ] enabled : < true | false > ip_address_virtual : < IPv4_address/Mask > < 1-4096 > : name : < description > tags : [ < tag_1 > , < tag_2 > ] enabled : < true | false > ip_address_virtual : < IPv4_address/Mask > # Define L2 network services organized by vlan id. l2vlans : # VLAN id. < 1-4096 > : # By default the vni will be derived from \"mac_vrf_vni_base:\" # The vni_override, allows to override this value and statically define it. vni_override : < 1-16777215 > # VLAN name. name : < description > # Tags leveraged for networks services filtering. tags : [ < tag_1 > , < tag_2 > ] < 1-4096 > : name : < description > tags : [ < tag_1 > , < tag_2 > ] < tenant_a > : mac_vrf_vni_base : < 10000-16770000 > vrfs : < tenant_b_vrf_1 > : vrf_vni : <1-1024> vtep_diagnostic : loopback : < 2-2100 > loopback_ip_range : < IPv4_address/Mask > svis : < 1-4096 > : name : < description > tags : [ < tag_1 > , < tag_2 > ] enabled : < true | false > ip_address_virtual : < IPv4_address/Mask > < 1-4096 > : vni_override : < 1-16777215 > name : < description > tags : [ < tag_1 > , < tag_2 > ] enabled : < true | false > ip_address_virtual : < IPv4_address/Mask > l2vlans : < 1-4096 > : vni_override : < 1-16777215 > name : < description > tags : [ < tag_1 > , < tag_2 > ] < 1-4096 > : name : < description > tags : [ < tag_1 > , < tag_2 > ] Example: # mlag_ibgp_peering_vrfs: # base_vlan: 3000 tenants : Tenant_A : mac_vrf_vni_base : 10000 vrfs : Tenant_A_OP_Zone : vrf_vni : 10 vtep_diagnostic : loopback : 100 loopback_ip_range : 10.255.1.0/24 svis : 110 : name : Tenant_A_OP_Zone_1 tags : [ opzone ] enabled : true ip_address_virtual : 10.1.10.0/24 111 : vni_override : 50111 name : Tenant_A_OP_Zone_2 tags : [ opzone ] enabled : true ip_address_virtual : 10.1.11.0/24 112 : name : Tenant_A_OP_Zone_3 tags : [ DC1_LEAF2 ] enabled : true ip_virtual_router_address : 10.1.12.1/24 nodes : DC1-LEAF2A : ip_address : 10.1.12.2/24 DC1-LEAF2B : ip_address : 10.1.12.3/24 113 : name : Tenant_A_OP_Zone_WAN tags : [ DC1_BL1 ] enabled : true nodes : DC1-BL1A : ip_address : 10.1.13.1/24 DC1-BL1B : ip_address : 10.1.13.2/24 Tenant_A_WEB_Zone : vrf_vni : 11 svis : 120 : name : Tenant_A_WEB_Zone_1 tags : [ web , erp1 ] enabled : true ip_address_virtual : 10.1.20.0/24 121 : name : Tenant_A_WEBZone_2 tags : [ web ] enabled : true ip_address_virtual : 10.1.21.0/24 Tenant_A_APP_Zone : vrf_vni : 12 svis : 130 : name : Tenant_A_APP_Zone_1 tags : [ app , erp1 ] enabled : true ip_address_virtual : 10.1.30.0/24 131 : name : Tenant_A_APP_Zone_2 tags : [ app ] enabled : true ip_address_virtual : 10.1.31.0/24 Tenant_A_DB_Zone : vrf_vni : 13 svis : 140 : name : Tenant_A_DB_BZone_1 tags : [ db , erp1 ] enabled : true ip_address_virtual : 10.1.40.0/24 141 : name : Tenant_A_DB_Zone_2 tags : [ db ] enabled : true ip_address_virtual : 10.1.41.0/24 Tenant_A_WAN_Zone : vrf_vni : 14 svis : 150 : name : Tenant_A_WAN_Zone_1 tags : [ wan ] enabled : true ip_address_virtual : 10.1.40.0/24 l2vlans : 160 : vni_override : 55160 name : Tenant_A_VMOTION tags : [ vmotion ] 161 : name : Tenant_A_NFS tags : [ nfs ] Tenant_B : mac_vrf_vni_base : 20000 vrfs : Tenant_B_OP_Zone : vrf_vni : 20 svis : 210 : name : Tenant_B_OP_Zone_1 tags : [ opzone ] enabled : true ip_address_virtual : 10.2.10.0/24 211 : name : Tenant_B_OP_Zone_2 tags : [ opzone ] enabled : true ip_address_virtual : 10.2.11.0/24 Tenant_B_WAN_Zone : vrf_vni : 21 svis : 250 : name : Tenant_B_WAN_Zone_1 tags : [ wan ] enabled : true ip_address_virtual : 10.2.50.0/24 Server Edge Port Connectivity # The Server Edge Port Connectivity variables, define infrastructure elements that connect to the fabric on switched interface(s). The infrastructure elements are not limited to servers, but any device that connect to a L2 switch port, i.e.: firewalls, load balancers and storage. Variables and Options: # Dictionary of port_profiles to be applied to elements defined in the servers variables. port_profiles : # Port-profile name < port_profile_1 > : # Interface mode | required mode : < access | dot1q-tunnel | trunk > # Native VLAN for a trunk port | optional native_vlan : <native vlan number> # Interface vlans | required vlans : < vlans as string > # Flow control | Optional flowcontrol : received : < received | send | on > < port_profile_2 > : mode : < access | dot1q-tunnel | trunk > vlans : < vlans as string > # Dictionary of servers, a device attaching to a L2 switched port(s) servers : # Server name, this will be used in the switchport description < server_1 > : # rack is used for documentation purposes only rack : < rack_id > # A list of adapter(s), group by adapters leveraging the same port-profile. adapters : # Example of stand-alone adapter # Adapter speed - if not specified will be auto. - speed : < adapter speed > # Local server port(s) server_ports : [ < interface_name > ] # List of port(s) connected to switches switch_ports : [ < switchport_interface > ] # List of switche(s) switches : [ < device > ] # Port-profile name, to inherit configuration. profile : < port_profile_name > # Example of port-channel adpater - server_ports : [ < interface_name_1 > , < interface_name_2 > ] switch_ports : [ < switchport_interface_1 > , < switchport_interface_2 > ] switches : [ < device_1 > , < device_2 > ] profile : < port_profile_name > # Port- Channel port_channel : # State, create or remove port-channel. state : < present | absent > # Port-Channel Description. description : < port_channel_description > # Port-Channel Mode. mode : < active | passive | on > < server_2 > : rack : RackC adapters : - speed : < adapter speed > server_ports : [ < interface_name > ] switch_ports : [ < switchport_interface > ] switches : [ < device > ] profile : < port_profile_name > - server_ports : [ < interface_name_1 > , < interface_name_2 > ] switch_ports : [ < switchport_interface_1 > , < switchport_interface_2 > ] switches : [ < device_1 > , < device_2 > ] profile : < port_profile_name > port_channel : state : < present | absent > description : < port_channel_description > mode : < active | passive | on > Example: port_profiles : VM_Servers : mode : trunk vlans : \"110-111,120-121,130-131\" MGMT : mode : access vlans : \"110\" DB_Clusters : mode : trunk vlans : \"140-141\" servers : server01 : rack : RackB adapters : # Single homed interface from E0 toward DC1-LEAF1A_Eth5 - server_ports : [ E0 ] switch_ports : [ Ethernet5 ] switches : [ DC1-LEAF1A ] profile : MGMT # MLAG dual-homed connection from E1 to DC1-LEAF2A_Eth10 # from E2 to DC1-LEAF2B_Eth10 - server_ports : [ E1 , E2 ] switch_ports : [ Ethernet10 , Ethernet10 ] switches : [ DC1-LEAF2A , DC1-LEAF2B ] profile : DB_Clusters port_channel : state : present description : PortChanne1 mode : active server03 : rack : RackC adapters : # MLAG dual-homed connection from E0 to DC1-SVC3A_Eth10 # from E1 to DC1-SVC3B_Eth10 - server_ports : [ E0 , E1 ] switch_ports : [ Ethernet10 , Ethernet10 ] switches : [ DC1-SVC3A , DC1-SVC3B ] profile : VM_Servers port_channel : state : present description : PortChanne1 mode : active Single attached server scenario # Single attached interface from E0 toward DC1-LEAF1A interface Eth5 servers : server01 : rack : RackB adapters : - server_ports : [ E0 ] switch_ports : [ Ethernet5 ] switches : [ DC1-LEAF1A ] profile : MGMT MLAG dual-attached server scenario # MLAG dual-homed connection: From E0 to DC1-SVC3A interface Eth10 From E1 to DC1-SVC3B interface Eth10 servers : server01 : rack : RackB adapters : - server_ports : [ E0 , E1 ] switch_ports : [ Ethernet10 , Ethernet10 ] switches : [ DC1-SVC3A , DC1-SVC3B ] profile : VM_Servers port_channel : state : present description : PortChanne1 mode : active Variable to attach additional configlets # Role eos_config_deploy_cvp provides an option to attach additional configlets to both devices or containers. This function allows users to quickly deployed a new feature with no JINJA2 implementation. These configlets must be managed on Cloudvision as current role does not upload additional containers. To attach configlets to containers or devices, please refer to eos_config_deploy_cvp documentation Below is an example provided as-is: # group_vars/DC1_FABRIC.yml # List of additional CVP configlets to bind to devices and containers # Configlets MUST be configured on CVP before running AVD playbooks. cv_configlets : containers : DC1_L3LEAFS : - GLOBAL-ALIASES devices : DC1-L2LEAF2A : - GLOBAL-ALIASES DC1-L2LEAF2B : - GLOBAL-ALIASES Event Handlers # Gives ability to monitor and react to Syslog messages provides a powerful and flexible tool that can be used to apply self-healing actions, customize the system behavior, and implement workarounds to problems discovered in the field. Variables and Options: event_handlers : evpn-blacklist-recovery : # Name of the event-handler action_type : < bash, increment > action : < Command to run when handler is triggered > delay : < int / delay in sec between 2 triggers > trigger : < on-logging > regex : < string to trigger handler > asynchronous : < true, false > Example: event_handlers : evpn-blacklist-recovery : action_type : bash action : FastCli -p 15 -c \"clear bgp evpn host-flap\" delay : 300 trigger : on-logging regex : EVPN-3-BLACKLISTED_DUPLICATE_MAC asynchronous : true Platform Specific settings # Set platform specific settings, TCAM profile and reload delay. The reload delay values should be reviewed and tuned to the specific environment. If the platform is not defined, it will load parameters from the platform tagged default . Variables and Options: platform_settings : - platforms : [ default ] reload_delay : mlag : < seconds > non_mlag : < seconds > - platforms : [ < Arista Platform Family > , < Arista Platform Family > ] tcam_profile : < tcam_profile > reload_delay : mlag : < seconds > non_mlag : < seconds > note: Recommended default values for Jericho based platform, and all other platforms default tag. Example: # platform_settings: # - platforms: [ default ] # reload_delay: # mlag: 300 # non_mlag: 330 # - platforms: [ 7800R3, 7500R3, 7500R, 7280R3, 7280R2, 7280R ] # tcam_profile: vxlan-routing # reload_delay: # mlag: 780 # non_mlag: 1020 vEOS-LAB Know Caveats and Recommendations # vEOS-LAB is a great tool to learn and test ansible-avd automation framework. In fact, this is the primary tool leveraged by Arista Ansible Team, for development and testing efforts. vEOS-lab enables you to create and run replicas of physical networks within a risk free virtual environment. Virtual networks created with vEOS-lab can be used for network modeling, planning for new services, or validating new features and functionality for the installed network. vEOS-lab is not a network simulator but the exact EOS implementation that runs on the hardware platforms. Supported features are documented here: vEOS-LAB Datasheet However, because vEOS-LAB implements a virtual data plane there are known caveats and adjustments that are required to default arista.avd settings: Variables adjustments required for vEOS-LAB: # Disable update wait-for-convergence and update wait-for-install, which is not supported in vEOS-LAB. spine_bgp_defaults : # - update wait-for-convergence # - update wait-install - no bgp default ipv4-unicast - distance bgp 20 200 200 - graceful-restart restart-time 300 - graceful-restart leaf_bgp_defaults : # - update wait-install - no bgp default ipv4-unicast - distance bgp 20 200 200 - graceful-restart restart-time 300 - graceful-restart # Update p2p mtu 9000 -> 1500, MTU 9000 not supported in vEOS-LAB. p2p_uplinks_mtu : 1500 # Adjust default bfd values, to avoid high CPU. bfd_multihop : interval : 1200 min_rx : 1200 multiplier : 3 License # Project is published under Apache 2.0 License","title":"eos_l3ls_evpn"},{"location":"roles/eos_l3ls_evpn/#ansible-role-eos_l3ls_evpn","text":"Table of Contents: Ansible Role: eos_l3ls_evpn Overview Role Inputs and Outputs Requirements Role Variables Common Device Configuration Variables Fabric Underlay and Overlay Topology Variables Fabric Topology Variables Type Variable Spine Variables L3 Leaf Variables L2 Leafs Variables Network Services Variables - VRFs/VLANs Server Edge Port Connectivity Single attached server scenario MLAG dual-attached server scenario Variable to attach additional configlets Event Handlers Platform Specific settings vEOS-LAB Know Caveats and Recommendations License","title":"Ansible Role: eos_l3ls_evpn"},{"location":"roles/eos_l3ls_evpn/#overview","text":"eos_l3ls_evpn , is a role that provides an abstracted data model to deploy a L3 Leaf and Spine fabric leveraging VXLAN data-plane with an EVPN control-plane. The eos_l3ls_evpn role: Enables network engineers to deploy Arista L3 Leaf & Spine fabric underlay and overlay network services effectively and with consistency. Designed to be extended easily, leveraging a \u201cstackable template architecture\u201d . Designed to be used with the eos_l3ls_config_gen role to generate a complete switch configuration and applied using a config replace strategy with either eos_config_deploy_eapi role. eos_config_deploy_cvp role. Designed to generate the intended configuration offline, without relying on switch current state information. Facilitates the evaluation of the configuration prior to deployment with tools like Batfish","title":"Overview"},{"location":"roles/eos_l3ls_evpn/#role-inputs-and-outputs","text":"Figure 1 below provides a visualization of the roles inputs, and outputs and tasks in order executed by the role. Inputs: Desired variables are defined in: role defaults, group_vars, and host_vars variables. If desired, the role can be extended to leverage data from dynamic sources such as an IPAM or CMDB. Outputs: A structured EOS configuration file in yaml format. This provides the following benefits: First, this allows us to naturally detect duplicate entries from inputs, as yaml dictionaries don\u2019t process duplicate keys. Leverage the structured data to create eos cli configuration. Leverage the structured data to create end user documentation. Leverage the structured data for pre and post fabric tests. Fabric Documentation in Markdown format. Leaf and Spine Topology summary in csv format. Tasks: Generate device configuration in a structured format (yaml). Include device structured configuration that was previously generated. Generate VXLAN/EVPN fabric documentation in Markdown format. Generate Leaf and Spine point-to-point links summary in CSV format. Generate Leaf and Spine physical topology summary in CSV format.","title":"Role Inputs and Outputs"},{"location":"roles/eos_l3ls_evpn/#requirements","text":"Requirements are located here: avd-requirements","title":"Requirements"},{"location":"roles/eos_l3ls_evpn/#role-variables","text":"The role variables are documented inline within yaml formated output with: \u201c< >\u201d Some variables are required while others are optional. Default values, are stored in the role defaults main.yml file. Role variable are grouped by configuration elements and are typically stored in different group_vars files.","title":"Role Variables"},{"location":"roles/eos_l3ls_evpn/#common-device-configuration-variables","text":"Common device configuration variables are for elements not related specifically to the fabric configuration. The variables should be applied to all devices within the fabric and can be shared with other infrastructure elements. Variables and Options: # Clock timezone | Optional timezone : < timezone > # Dictionary of local users | Required local_users : < username_1 > : privilege : < (1-15) Initial privilege level with local EXEC authorization > role : < Specify a role for the user > sha512_password : \"< SHA512 ENCRYPTED password >\" < username_2 > : privilege : < (1-15) Initial privilege level with local EXEC authorization > role : < Specify a role for the user > sha512_password : \"< SHA512 ENCRYPTED password >\" # Management eAPI | Required # Default is https management eAPI enabled management_eapi : enable_http : < boolean | default -> false > enable_https : < boolean | default -> true > # CloudVision - Telemetry Agent (TerminAttr) configuration | Optional cvp_instance_ip : < IPv4 address > or cvp_instance_ips : - < IPv4 address > - < IPv4 address > - < IPv4 address > cvp_ingestauth_key : < CloudVision Ingest Authentication key > terminattr_ingestgrpcurl_port : < port_number | default -> 9910 > terminattr_smashexcludes : \"< smash excludes | default -> ale,flexCounter,hardware,kni,pulse,strata >\" terminattr_ingestexclude : \"< ingest excludes | default -> /Sysdb/cell/1/agent,/Sysdb/cell/2/agent >\" # Management interface configuration | Required mgmt_vrf_routing : < boolean | default -> false > mgmt_interface : < mgmt_interface | default -> Management1 > mgmt_interface_vrf : < vrf_name | default -> MGMT > mgmt_gateway : < IPv4 address > # OOB mgmt interface destination networks - override default route mgmt_destination_networks : - < IPv4_network/Mask > - < IPv4_network/Mask > # list of DNS servers | Optional name_servers : - < IPv4_address_1 > - < IPv4_address_2 > # List of NTP Servers IP or DNS name | Optional # The first NTP server in the list will be preferred # NTP request will be sourced from < management_interface_vrf > ntp_servers : - < ntp_server_1 > - < ntp_server_1 > # Internal vlan allocation order and range | Required internal_vlan_order : allocation : < ascending or descending | default -> ascending > range : beginning : < vlan_id | default -> 1006 > ending : < vlan_id | default -> 1199 > # Redundancy for chassis platforms with dual supervisors | Optional redundancy : protocol : < sso | rpr > # MAC address-table aging time | Optional # Use to change the EOS default of 300 mac_address_table : aging_time : < time_in_seconds > Example: note: Default values are commented # Timezone timezone : \"US/Eastern\" # local users local_users : admin : privilege : 15 role : network-admin sha512_password : \"$6$Df86J4/SFMDE3/1K$Hef4KstdoxNDaami37cBquTWOTplC.miMPjXVgQxMe92.e5wxlnXOLlebgPj8Fz1KO0za/RCO7ZIs4Q6Eiq1g1\" cvpadmin : privilege : 15 role : network-admin sha512_password : \"$6$rZKcbIZ7iWGAWTUM$TCgDn1KcavS0s.OV8lacMTUkxTByfzcGlFlYUWroxYuU7M/9bIodhRO7nXGzMweUxvbk8mJmQl8Bh44cRktUj.\" # Management eAPI # management_eapi: # enable_https: true # Cloud Vision server information cvp_instance_ips : - 192.168.2.201 - 192.168.2.202 - 192.168.2.203 cvp_ingestauth_key : telarista # terminattr_ingestgrpcurl_port: 9910 # terminattr_smashexcludes: \"ale,flexCounter,hardware,kni,pulse,strata\" # terminattr_ingestexclude: \"/Sysdb/cell/1/agent,/Sysdb/cell/2/agent # Management interface configuration mgmt_gateway : 192.168.2.1 # mgmt_vrf_routing: false # mgmt_interface: Management1 # mgmt_interface_vrf: MGMT # OOB mgmt interface destination networks # mgmt_destination_networks: # - 0.0.0.0/0 # DNS servers. name_servers : - 192.168.2.1 - 8.8.8.8 # NTP Servers ntp_servers : - 0.north-america.pool.ntp.org - 1.north-america.pool.ntp.org # Internal vlan allocation order and range # internal_vlan_order: # allocation: ascending # range: # beginning: 1006 # ending: 1199 # Redundancy for chassis platforms with dual supervisors redundancy : protocol : sso # MAC address-table aging time mac_address_table : aging_time : 1500","title":"Common Device Configuration Variables"},{"location":"roles/eos_l3ls_evpn/#fabric-underlay-and-overlay-topology-variables","text":"The fabric underlay and overlay topology variables, define the elements related to build the L3 Leaf and Spine fabric. The following underlay routing protocols are supported: BGP (default) OSPF. ISIS. Only summary network addresses need to be defined. IP addresses are then assigned to each node, based on its unique device id. To view IP address allocation and consumption, a summary is provided in the auto-generated fabric documentation in Markdown format. The variables should be applied to all devices in the fabric. Variables and Options: # Fabric Name, required to match group_var file name | Required. fabric_name : < Fabric_Name > # Underlay routing protocol | Required. underlay_routing_protocol : < BGP or OSPF or ISIS | Default -> BGP > # Underlay OSFP | Required when < underlay_routing_protocol > == OSPF underlay_ospf_process_id : < process_id | Default -> 100 > underlay_ospf_area : < ospf_area | Default -> 0.0.0.0 > underlay_ospf_max_lsa : < lsa | Default -> 12000 > # Underlay OSFP | Required when < underlay_routing_protocol > == ISIS isis_area_id : < isis area | Default -> \"49.0001\" > isis_site_id : < isis site ID | Default -> \"0001\" > # Point to Point Links MTU | Required. p2p_uplinks_mtu : < 0-9216 | default -> 9000 > # IP Summary for Point to Point interfaces between L3 leafs and spines used for underlay peering | Required # Assigned as /31 for each uplink interfaces # Assign network summary larger then: # [ total spines * total potential L3 leafs * 2 * max_l3leaf_to_spine_links(default: 1) ] underlay_p2p_network_summary : < IPv4_network/Mask > # IP address summary for BGP evpn overlay peering loopback for L3 leafs and spines | Required # Assigned as /32 to Loopback0 # Assign range larger then: # [ total spines + total potential L3 leafs ] overlay_loopback_network_summary : < IPv4_network/Mask > # IP address summary VTEP VXLAN Tunnel source loopback1 IP for L3 leafs | Required # Assigned as /32 to Loopback1 # Assign range larger then total L3 leafs vtep_loopback_network_summary : < IPv4_network/Mask > # IP address summary used for MLAG Peer Link (control link) and underlay L3 peering | *Required # * When MLAG leafs present in topology. # Assign range larger then total: L3 Leafs + 2 ] mlag_ips : leaf_peer_l3 : < IPv4_network/Mask > mlag_peer : < IPv4_network/Mask > # BGP peer groups encrypted password # IPv4_UNDERLAY_PEERS and MLAG_IPv4_UNDERLAY_PEER | Required when < underlay_routing_protocol > == BGP # EVPN_OVERLAY_PEERS | Required # Leverage an Arista EOS switch to generate the encrypted password bgp_peer_groups : IPv4_UNDERLAY_PEERS : password : \"< encrypted password >\" MLAG_IPv4_UNDERLAY_PEER : password : \"< encrypted password >\" EVPN_OVERLAY_PEERS : password : \"< encrypted password >\" # Spine BGP Tuning | Optional. spine_bgp_defaults : - update wait-for-convergence - update wait-install - no bgp default ipv4-unicast - distance bgp 20 200 200 - graceful-restart restart-time 300 - graceful-restart # Leaf BGP Tuning | Optional. leaf_bgp_defaults : - update wait-install - no bgp default ipv4-unicast - distance bgp 20 200 200 - graceful-restart restart-time 300 - graceful-restart # Enable vlan aware bundles for EVPN MAC-VRF | Required. vxlan_vlan_aware_bundles : < boolean | default -> false > # BFD Multihop tunning | Required. bfd_multihop : interval : < | default -> 300 > min_rx : < | default -> 300 > multiplier : < | default -> 3 > Example: note: Default values are commented # Defined in FABRIC.yml fabric_name : DC1_FABRIC # underlay_routing_protocol: BGP # underlay_ospf_process_id: 100 # underlay_ospf_area: 0.0.0.0 # underlay_ospf_max_lsa: 12000 # p2p_uplinks_mtu: 9000 underlay_p2p_network_summary : 172.31.255.0/24 overlay_loopback_network_summary : 192.168.255.0/24 vtep_loopback_network_summary : 192.168.254.0/24 mlag_ips : leaf_peer_l3 : 10.255.251.0/24 mlag_peer : 10.255.252.0/24 bgp_peer_groups : IPv4_UNDERLAY_PEERS : password : \"AQQvKeimxJu+uGQ/yYvv9w==\" EVPN_OVERLAY_PEERS : password : \"q+VNViP5i4rVjW1cxFv2wA==\" MLAG_IPv4_UNDERLAY_PEER : password : \"vnEaG8gMeQf3d3cN6PktXQ==\" # spine_bgp_defaults: # - update wait-for-convergence # - update wait-install # - no bgp default ipv4-unicast # - distance bgp 20 200 200 # - graceful-restart restart-time 300 # - graceful-restart # leaf_bgp_defaults: # - update wait-install # - no bgp default ipv4-unicast # - distance bgp 20 200 200 # - graceful-restart restart-time 300 # - graceful-restart # vxlan_vlan_aware_bundles: false # bfd_multihop: # interval: 300 # min_rx: 300 # multiplier: 3","title":"Fabric Underlay and Overlay Topology Variables"},{"location":"roles/eos_l3ls_evpn/#fabric-topology-variables","text":"The fabric topology variables define the connectivity between the spines, L3 leafs, and L2 leafs. The variables should be applied to all devices in the fabric. Connectivity is defined from the child\u2019s device perspective. Source uplink interfaces and parent interfaces are defined on the child. A static unique identifier (id) is assigned to each device. This is leveraged to derive the IP address assignment from each summary defined in the Fabric Underlay and Overlay Topology Variables. Within the l3_leaf and l2_leaf dictionary variables, defaults can be defined. This reduces user input requirements, limiting errors. The default variables can be overridden when defined under the node groups. The ability to define a super-spine layer is planned for a future release of ansible-avd.","title":"Fabric Topology Variables"},{"location":"roles/eos_l3ls_evpn/#type-variable","text":"The type: variable needs to be defined for each device in the fabric. This is leveraged to load to appropriate template, to generate the configuration. Variables and Options: # define the layer type type : < spine | l3leaf | l2leaf > Example: # Defined in SPINE.yml file type : spine # Defined in L3LEAFS.yml type : l3leaf # Defined in L2LEAFS.yml type : l2leaf","title":"Type Variable"},{"location":"roles/eos_l3ls_evpn/#spine-variables","text":"Variables and Options: # Defined in FABRIC.yml spine : # Arista platform family | Required. platform : < Arista Platform Family > # Spine BGP AS | Required. bgp_as : < bgp_as > # Accepted L3 leaf bgp as range | Required. leaf_as_range : < bgp_as_start-bgp_as_end > # Specify dictionary of Spine nodes | Required. nodes : < inventory_hostname > : # Unique identifier | Required. id : < integer > # Node management IP address | Required. mgmt_ip : < IPv4_address/Mask > < inventory_hostname > : id : < integer > mgmt_ip : < IPv4_address/Mask > Example: # Defined in FABRIC.yml spine : platform : vEOS-LAB bgp_as : 65001 leaf_as_range : 65101-65132 nodes : DC1-SPINE1 : id : 1 mgmt_ip : 192.168.2.101/24 DC1-SPINE2 : id : 2 mgmt_ip : 192.168.2.102/24","title":"Spine Variables"},{"location":"roles/eos_l3ls_evpn/#l3-leaf-variables","text":"Variables and Options: l3leaf : # L3 Leaf default variables, can be overridden when defined under < node_group >. defaults : # Arista platform family. | Required platform : < Arista Platform Family > # Parent spine switches (list), corresponding to uplink_to_spine_interfaces and spine_interfaces | Required. spines : [ < spine_inventory_hostname > , < spine_inventory_hostname > ] # Uplink to spine interfaces (list), interface located on L3 Leaf, # corresponding to spines and spine_interfaces | Required. uplink_to_spine_interfaces : [ < ethernet_interface_1 > , < ethernet_interface_2 > ] # Point-to-Point interface speed - will apply to L3 Leaf and Spine switches | Optional. p2p_link_interface_speed : < interface_speed > # MLAG interfaces (list) | Required when MLAG leafs present in topology. mlag_interfaces : [ < ethernet_interface_3 > , < ethernet_interface_4 > ] # Spanning tree mode (note - only mstp has been validated at this time) | Required. spanning_tree_mode : < mstp > # Spanning tree priority | Required. spanning_tree_priority : < spanning-tree priority > # Virtual router mac address for anycast gateway | Required. virtual_router_mac_address : < mac address > # The node groups are group of one or two nodes where specific variables can be defined related to the topology # and allowed L3 and L2 network services. # All variables defined under `defaults` dictionary can be defined under each node group to override it. node_groups : # node_group_1, will result in stand-alone leaf. < node_group_1 > : # L3 Leaf BGP AS. | Required. bgp_as : < bgp_as > # Filter L3 and L2 network services based on tenant and tags ( and operation filter )| Optional # If filter is not defined will default to all filter : tenants : [ < tenant_1 > , < tenant_2 > | default all ] tags : [ < tag_1 > , < tag_2 > | default -> all ] ] # Define one or two nodes - same name as inventory_hostname | Required # When two nodes are defined, this will create an MLAG pair. nodes : # First node < l3_leaf_inventory_hostname_1 > : # Unique identifier | Required. id : < integer > # Node management IP address | Required. mgmt_ip : < IPv4_address/Mask > # Spine interfaces (list), interface located on Spine, # corresponding to spines and uplink_to_spine_interfaces | Required. spine_interfaces : [ < ethernet_interface_1 > , < ethernet_interface_1 > ] # node_group_2, will result in MLAG pair. < node_group_2 > : bgp_as : < bgp_as > filter : tenants : [ < tenant_1 > , < tenant_2 > | default all ] tags : [ < tag_1 > , < tag_2 > | default -> all ] nodes : # Second node < l3_leaf_inventory_hostname_2 > : id : < integer > mgmt_ip : < IPv4_address/Mask > spine_interfaces : [ < ethernet_interface_2 > , < ethernet_interface_2 > ] # Third node < l3_leaf_inventory_hostname_3 > : id : < integer > mgmt_ip : < IPv4_address/Mask > spine_interfaces : [ < ethernet_interface_3 > , < ethernet_interface_3 > ] Example: # Defined in FABRIC.yml l3leaf : defaults : platform : vEOS-LAB bgp_as : 65100 spines : [ DC1-SPINE1 , DC1-SPINE2 ] uplink_to_spine_interfaces : [ Ethernet1 , Ethernet2 ] mlag_interfaces : [ Ethernet3 , Ethernet4 ] spanning_tree_mode : mstp spanning_tree_priority : 4096 virtual_router_mac_address : 00:1c:73:00:dc:01 node_groups : DC1_LEAF1 : bgp_as : 65101 filter : tenants : [ Tenant_A , Tenant_B , Tenant_C ] tags : [ opzone ] nodes : DC1-LEAF1A : id : 1 mgmt_ip : 192.168.2.105/24 spine_interfaces : [ Ethernet1 , Ethernet1 ] DC1_LEAF2 : bgp_as : 65102 filter : tenants : [ Tenant_A ] tags : [ opzone , web , app , db , vmotion , nfs ] nodes : DC1-LEAF2A : id : 2 mgmt_ip : 192.168.2.106/24 spine_interfaces : [ Ethernet2 , Ethernet2 ] DC1-LEAF2B : id : 3 mgmt_ip : 192.168.2.107/24 spine_interfaces : [ Ethernet3 , Ethernet3 ] DC1_SVC3 : bgp_as : 65103 filter : tenants : [ Tenant_A ] tags : [ erp1 ] nodes : DC1-SVC3A : id : 4 mgmt_ip : 192.168.2.108/24 spine_interfaces : [ Ethernet4 , Ethernet4 ] DC1-SVC3B : id : 5 mgmt_ip : 192.168.2.109/24 spine_interfaces : [ Ethernet5 , Ethernet5 ]","title":"L3 Leaf Variables"},{"location":"roles/eos_l3ls_evpn/#l2-leafs-variables","text":"Variables and Options: l2leaf : # L2 Leaf default variables, can be overridden when defined under < node_group >. defaults : # Arista platform family. | Required platform : < Arista Platform Family > # Parent L3 switches (list), corresponding to uplink_interfaces and l3leaf_interfaces | Required. parent_l3leafs : [ DC1-LEAF2A , DC1-LEAF2B ] # Uplink interfaces (list), interface located on L2 Leaf, # corresponding to parent_l3leafs and l3leaf_interfaces | Required. uplink_interfaces : [ < ethernet_interface_1 > , < ethernet_interface_2 > ] # Point-to-Point interface speed - will apply to L2 Leaf and L3 Leaf switches | Optional. p2p_link_interface_speed : < interface_speed > # MLAG interfaces (list) | Required when MLAG leafs present in topology. mlag_interfaces : [ < ethernet_interface_3 > , < ethernet_interface_4 > ] # Spanning tree mode (note - only mstp has been validated at this time) | Required. spanning_tree_mode : < mstp > # Spanning tree priority | Required. spanning_tree_priority : < spanning-tree priority > # The node groups are group of one or two nodes where specific variables can be defined related to the topology # and allowed L3 and L2 network services. # All variables defined under `defaults` dictionary can be defined under each node group to override it. node_groups : # node_group_1, will result in stand-alone leaf. < node_group_1 > : # Filter L3 and L2 network services based on tenant and tags - and filter | Optional # If filter is not defined will default to all filter : tenants : [ < tenant_1 > , < tenant_2 > | default all ] tags : [ < tag_1 > , < tag_2 > | default -> all ] ] # Define one or two nodes - same name as inventory_hostname. # When two nodes are defined, this will create an MLAG pair. nodes : # First node < l2_leaf_inventory_hostname_1 > : # Unique identifier | Required. id : < integer > # Node management IP address | Required. mgmt_ip : < IPv4_address/Mask > # l3leaf interfaces (list), interface located on l3leaf, # corresponding to parent_l3leafs and uplink_interfaces | Required. l3leaf_interfaces : [ < ethernet_interface_6 > , < ethernet_interface_6 > ] # node_group_2, will result in MLAG pair. < node_group_1 > : parent_l3leafs : [ DC1-SVC3A , DC1-SVC3B ] nodes : # Second node. < l2_leaf_inventory_hostname_2 > : id : < integer > mgmt_ip : < IPv4_address/Mask > l3leaf_interfaces : [ < ethernet_interface_7 > , < ethernet_interface_7 > ] # Third node. < l2_leaf_inventory_hostname_3 > : id : < integer > mgmt_ip : < IPv4_address/Mask > l3leaf_interfaces : [ < ethernet_interface_8 > , < ethernet_interface_8 > ] Example: # Defined in FABRIC.yml l2leaf : defaults : platform : vEOS-LAB parent_l3leafs : [ DC1-LEAF2A , DC1-LEAF2B ] uplink_interfaces : [ Ethernet1 , Ethernet2 ] mlag_interfaces : [ Ethernet3 , Ethernet4 ] spanning_tree_mode : mstp spanning_tree_priority : 16384 node_groups : DC1_L2LEAF4 : uplink_interfaces : [ Ethernet11 , Ethernet12 ] filter : tenants : [ Tenant_A ] tags : [ opzone , web , app ] nodes : DC1-L2LEAF4A : id : 8 mgmt_ip : 192.168.2.112/24 l3leaf_interfaces : [ Ethernet6 , Ethernet6 ] DC1_L2LEAF5 : parent_l3leafs : [ DC1-SVC3A , DC1-SVC3B ] nodes : DC1-L2LEAF5A : id : 10 mgmt_ip : 192.168.2.113/24 l3leaf_interfaces : [ Ethernet5 , Ethernet5 ] DC1-L2LEAF5B : id : 11 mgmt_ip : 192.168.2.114/24 l3leaf_interfaces : [ Ethernet6 , Ethernet6 ]","title":"L2 Leafs Variables"},{"location":"roles/eos_l3ls_evpn/#network-services-variables-vrfsvlans","text":"The network services variables provide an abstracted model to create L2 and L3 network services across the fabric. The network services are grouped by tenants. The definition of a tenant may vary between organizations. e.g. Tenants can be organizations or departments. The tenant shares a common vni range for mac vrf assignment. The filtering model allows for granular deployment of network service to the fabric leveraging the tenant name and tags applied to the service definition. This allows for the re-use of SVIs and VLANs across the fabric. Variables and Options: # On mlag leafs, an SVI interface is defined per vrf, to establish iBGP peering. | Required (when mlag leafs in topology) # The SVI id will be derived from the base vlan defined: mlag_ibgp_peering_vrfs.base_vlan + vrf_vni mlag_ibgp_peering_vrfs : base_vlan : < 1-4000 | default -> 3000 > # Dictionary of tenants, to define network services: L3 VRFs and L2 VLNAS. tenants : # Specify a tenant name. | Required # Tenant provide a construct to group L3 VRFs and L2 VLANs. # Networks services can be filtered by tenant name. < tenant_a > : # VXLAN Network Identifier for MAC VRF | Required. # VXLAN VNI is derived from the base number with simple addition. # e.g. mac_vrf_vni_base = 10000, svi 100 = VNI 10100, svi 300 = VNI 10300. mac_vrf_vni_base : < 10000-16770000 > # Define L3 network services organized by vrf. vrfs : # VRF name | Required < tenant_a_vrf_1 > : # VRF VNI | Required. # The VRF VNI range is limited. vrf_vni : <1-1024> # Enable VTEP Network diagnostics | Optional. # This will create a loopback with virtual source-nat enable to perform diagnostics from the switch. vtep_diagnostic : # Loopback interface number | Required (when vtep_diagnotics defined) loopback : < 2-2100 > # Loopback ip range, a unique ip is derived from this ranged and assigned # to each l3 leaf based on it's unique id. | Required (when vtep_diagnotics defined) loopback_ip_range : < IPv4_address/Mask > # Dictionary of SVIs | Required. # This will create both the L3 SVI and L2 VLAN based on filters applied to l3leaf and l2leaf. svis : # SVI interface id and VLAN id. | Required < 1-4096 > : # By default the vni will be derived from \"mac_vrf_vni_base:\" # The vni_override allows us to override this value and statically define it. | Optional vni_override : < 1-16777215 > # vlan name + svi description. | Required name : < description > # Tags leveraged for networks services filtering. | Required tags : [ < tag_1 > , < tag_2 > ] # Enable or disable interface enabled : < true | false > # ip address virtual to configure VXLAN Anycast IP address # Conserves IP addresses in VXLAN deployments as it doesn't require unique IP addresses on each node. # Optional ip_address_virtual: : < IPv4_address/Mask > # ip virtual-router address # note, also requires an IP address to be configured on the SVI where it is applied. # Optional ip_virtual_router_address : < IPv4_address/Mask > # Define node specific configuration, such as unique IP addresses. nodes : < l3_leaf_inventory_hostname_1 > : # device unique IP address for node. ip_address : < IPv4_address/Mask > < l3_leaf_inventory_hostname_2 > : ip_address : < IPv4_address/Mask > < 1-4096 > : name : < description > tags : [ < tag_1 > , < tag_2 > ] enabled : < true | false > ip_address_virtual : < IPv4_address/Mask > < tenant_a_vrf_2 > : vrf_vni : <1-1024> svis : < 1-4096 > : name : < description > tags : [ < tag_1 > , < tag_2 > ] enabled : < true | false > ip_address_virtual : < IPv4_address/Mask > < 1-4096 > : name : < description > tags : [ < tag_1 > , < tag_2 > ] enabled : < true | false > ip_address_virtual : < IPv4_address/Mask > # Define L2 network services organized by vlan id. l2vlans : # VLAN id. < 1-4096 > : # By default the vni will be derived from \"mac_vrf_vni_base:\" # The vni_override, allows to override this value and statically define it. vni_override : < 1-16777215 > # VLAN name. name : < description > # Tags leveraged for networks services filtering. tags : [ < tag_1 > , < tag_2 > ] < 1-4096 > : name : < description > tags : [ < tag_1 > , < tag_2 > ] < tenant_a > : mac_vrf_vni_base : < 10000-16770000 > vrfs : < tenant_b_vrf_1 > : vrf_vni : <1-1024> vtep_diagnostic : loopback : < 2-2100 > loopback_ip_range : < IPv4_address/Mask > svis : < 1-4096 > : name : < description > tags : [ < tag_1 > , < tag_2 > ] enabled : < true | false > ip_address_virtual : < IPv4_address/Mask > < 1-4096 > : vni_override : < 1-16777215 > name : < description > tags : [ < tag_1 > , < tag_2 > ] enabled : < true | false > ip_address_virtual : < IPv4_address/Mask > l2vlans : < 1-4096 > : vni_override : < 1-16777215 > name : < description > tags : [ < tag_1 > , < tag_2 > ] < 1-4096 > : name : < description > tags : [ < tag_1 > , < tag_2 > ] Example: # mlag_ibgp_peering_vrfs: # base_vlan: 3000 tenants : Tenant_A : mac_vrf_vni_base : 10000 vrfs : Tenant_A_OP_Zone : vrf_vni : 10 vtep_diagnostic : loopback : 100 loopback_ip_range : 10.255.1.0/24 svis : 110 : name : Tenant_A_OP_Zone_1 tags : [ opzone ] enabled : true ip_address_virtual : 10.1.10.0/24 111 : vni_override : 50111 name : Tenant_A_OP_Zone_2 tags : [ opzone ] enabled : true ip_address_virtual : 10.1.11.0/24 112 : name : Tenant_A_OP_Zone_3 tags : [ DC1_LEAF2 ] enabled : true ip_virtual_router_address : 10.1.12.1/24 nodes : DC1-LEAF2A : ip_address : 10.1.12.2/24 DC1-LEAF2B : ip_address : 10.1.12.3/24 113 : name : Tenant_A_OP_Zone_WAN tags : [ DC1_BL1 ] enabled : true nodes : DC1-BL1A : ip_address : 10.1.13.1/24 DC1-BL1B : ip_address : 10.1.13.2/24 Tenant_A_WEB_Zone : vrf_vni : 11 svis : 120 : name : Tenant_A_WEB_Zone_1 tags : [ web , erp1 ] enabled : true ip_address_virtual : 10.1.20.0/24 121 : name : Tenant_A_WEBZone_2 tags : [ web ] enabled : true ip_address_virtual : 10.1.21.0/24 Tenant_A_APP_Zone : vrf_vni : 12 svis : 130 : name : Tenant_A_APP_Zone_1 tags : [ app , erp1 ] enabled : true ip_address_virtual : 10.1.30.0/24 131 : name : Tenant_A_APP_Zone_2 tags : [ app ] enabled : true ip_address_virtual : 10.1.31.0/24 Tenant_A_DB_Zone : vrf_vni : 13 svis : 140 : name : Tenant_A_DB_BZone_1 tags : [ db , erp1 ] enabled : true ip_address_virtual : 10.1.40.0/24 141 : name : Tenant_A_DB_Zone_2 tags : [ db ] enabled : true ip_address_virtual : 10.1.41.0/24 Tenant_A_WAN_Zone : vrf_vni : 14 svis : 150 : name : Tenant_A_WAN_Zone_1 tags : [ wan ] enabled : true ip_address_virtual : 10.1.40.0/24 l2vlans : 160 : vni_override : 55160 name : Tenant_A_VMOTION tags : [ vmotion ] 161 : name : Tenant_A_NFS tags : [ nfs ] Tenant_B : mac_vrf_vni_base : 20000 vrfs : Tenant_B_OP_Zone : vrf_vni : 20 svis : 210 : name : Tenant_B_OP_Zone_1 tags : [ opzone ] enabled : true ip_address_virtual : 10.2.10.0/24 211 : name : Tenant_B_OP_Zone_2 tags : [ opzone ] enabled : true ip_address_virtual : 10.2.11.0/24 Tenant_B_WAN_Zone : vrf_vni : 21 svis : 250 : name : Tenant_B_WAN_Zone_1 tags : [ wan ] enabled : true ip_address_virtual : 10.2.50.0/24","title":"Network Services Variables - VRFs/VLANs"},{"location":"roles/eos_l3ls_evpn/#server-edge-port-connectivity","text":"The Server Edge Port Connectivity variables, define infrastructure elements that connect to the fabric on switched interface(s). The infrastructure elements are not limited to servers, but any device that connect to a L2 switch port, i.e.: firewalls, load balancers and storage. Variables and Options: # Dictionary of port_profiles to be applied to elements defined in the servers variables. port_profiles : # Port-profile name < port_profile_1 > : # Interface mode | required mode : < access | dot1q-tunnel | trunk > # Native VLAN for a trunk port | optional native_vlan : <native vlan number> # Interface vlans | required vlans : < vlans as string > # Flow control | Optional flowcontrol : received : < received | send | on > < port_profile_2 > : mode : < access | dot1q-tunnel | trunk > vlans : < vlans as string > # Dictionary of servers, a device attaching to a L2 switched port(s) servers : # Server name, this will be used in the switchport description < server_1 > : # rack is used for documentation purposes only rack : < rack_id > # A list of adapter(s), group by adapters leveraging the same port-profile. adapters : # Example of stand-alone adapter # Adapter speed - if not specified will be auto. - speed : < adapter speed > # Local server port(s) server_ports : [ < interface_name > ] # List of port(s) connected to switches switch_ports : [ < switchport_interface > ] # List of switche(s) switches : [ < device > ] # Port-profile name, to inherit configuration. profile : < port_profile_name > # Example of port-channel adpater - server_ports : [ < interface_name_1 > , < interface_name_2 > ] switch_ports : [ < switchport_interface_1 > , < switchport_interface_2 > ] switches : [ < device_1 > , < device_2 > ] profile : < port_profile_name > # Port- Channel port_channel : # State, create or remove port-channel. state : < present | absent > # Port-Channel Description. description : < port_channel_description > # Port-Channel Mode. mode : < active | passive | on > < server_2 > : rack : RackC adapters : - speed : < adapter speed > server_ports : [ < interface_name > ] switch_ports : [ < switchport_interface > ] switches : [ < device > ] profile : < port_profile_name > - server_ports : [ < interface_name_1 > , < interface_name_2 > ] switch_ports : [ < switchport_interface_1 > , < switchport_interface_2 > ] switches : [ < device_1 > , < device_2 > ] profile : < port_profile_name > port_channel : state : < present | absent > description : < port_channel_description > mode : < active | passive | on > Example: port_profiles : VM_Servers : mode : trunk vlans : \"110-111,120-121,130-131\" MGMT : mode : access vlans : \"110\" DB_Clusters : mode : trunk vlans : \"140-141\" servers : server01 : rack : RackB adapters : # Single homed interface from E0 toward DC1-LEAF1A_Eth5 - server_ports : [ E0 ] switch_ports : [ Ethernet5 ] switches : [ DC1-LEAF1A ] profile : MGMT # MLAG dual-homed connection from E1 to DC1-LEAF2A_Eth10 # from E2 to DC1-LEAF2B_Eth10 - server_ports : [ E1 , E2 ] switch_ports : [ Ethernet10 , Ethernet10 ] switches : [ DC1-LEAF2A , DC1-LEAF2B ] profile : DB_Clusters port_channel : state : present description : PortChanne1 mode : active server03 : rack : RackC adapters : # MLAG dual-homed connection from E0 to DC1-SVC3A_Eth10 # from E1 to DC1-SVC3B_Eth10 - server_ports : [ E0 , E1 ] switch_ports : [ Ethernet10 , Ethernet10 ] switches : [ DC1-SVC3A , DC1-SVC3B ] profile : VM_Servers port_channel : state : present description : PortChanne1 mode : active","title":"Server Edge Port Connectivity"},{"location":"roles/eos_l3ls_evpn/#single-attached-server-scenario","text":"Single attached interface from E0 toward DC1-LEAF1A interface Eth5 servers : server01 : rack : RackB adapters : - server_ports : [ E0 ] switch_ports : [ Ethernet5 ] switches : [ DC1-LEAF1A ] profile : MGMT","title":"Single attached server scenario"},{"location":"roles/eos_l3ls_evpn/#mlag-dual-attached-server-scenario","text":"MLAG dual-homed connection: From E0 to DC1-SVC3A interface Eth10 From E1 to DC1-SVC3B interface Eth10 servers : server01 : rack : RackB adapters : - server_ports : [ E0 , E1 ] switch_ports : [ Ethernet10 , Ethernet10 ] switches : [ DC1-SVC3A , DC1-SVC3B ] profile : VM_Servers port_channel : state : present description : PortChanne1 mode : active","title":"MLAG dual-attached server scenario"},{"location":"roles/eos_l3ls_evpn/#variable-to-attach-additional-configlets","text":"Role eos_config_deploy_cvp provides an option to attach additional configlets to both devices or containers. This function allows users to quickly deployed a new feature with no JINJA2 implementation. These configlets must be managed on Cloudvision as current role does not upload additional containers. To attach configlets to containers or devices, please refer to eos_config_deploy_cvp documentation Below is an example provided as-is: # group_vars/DC1_FABRIC.yml # List of additional CVP configlets to bind to devices and containers # Configlets MUST be configured on CVP before running AVD playbooks. cv_configlets : containers : DC1_L3LEAFS : - GLOBAL-ALIASES devices : DC1-L2LEAF2A : - GLOBAL-ALIASES DC1-L2LEAF2B : - GLOBAL-ALIASES","title":"Variable to attach additional configlets"},{"location":"roles/eos_l3ls_evpn/#event-handlers","text":"Gives ability to monitor and react to Syslog messages provides a powerful and flexible tool that can be used to apply self-healing actions, customize the system behavior, and implement workarounds to problems discovered in the field. Variables and Options: event_handlers : evpn-blacklist-recovery : # Name of the event-handler action_type : < bash, increment > action : < Command to run when handler is triggered > delay : < int / delay in sec between 2 triggers > trigger : < on-logging > regex : < string to trigger handler > asynchronous : < true, false > Example: event_handlers : evpn-blacklist-recovery : action_type : bash action : FastCli -p 15 -c \"clear bgp evpn host-flap\" delay : 300 trigger : on-logging regex : EVPN-3-BLACKLISTED_DUPLICATE_MAC asynchronous : true","title":"Event Handlers"},{"location":"roles/eos_l3ls_evpn/#platform-specific-settings","text":"Set platform specific settings, TCAM profile and reload delay. The reload delay values should be reviewed and tuned to the specific environment. If the platform is not defined, it will load parameters from the platform tagged default . Variables and Options: platform_settings : - platforms : [ default ] reload_delay : mlag : < seconds > non_mlag : < seconds > - platforms : [ < Arista Platform Family > , < Arista Platform Family > ] tcam_profile : < tcam_profile > reload_delay : mlag : < seconds > non_mlag : < seconds > note: Recommended default values for Jericho based platform, and all other platforms default tag. Example: # platform_settings: # - platforms: [ default ] # reload_delay: # mlag: 300 # non_mlag: 330 # - platforms: [ 7800R3, 7500R3, 7500R, 7280R3, 7280R2, 7280R ] # tcam_profile: vxlan-routing # reload_delay: # mlag: 780 # non_mlag: 1020","title":"Platform Specific settings"},{"location":"roles/eos_l3ls_evpn/#veos-lab-know-caveats-and-recommendations","text":"vEOS-LAB is a great tool to learn and test ansible-avd automation framework. In fact, this is the primary tool leveraged by Arista Ansible Team, for development and testing efforts. vEOS-lab enables you to create and run replicas of physical networks within a risk free virtual environment. Virtual networks created with vEOS-lab can be used for network modeling, planning for new services, or validating new features and functionality for the installed network. vEOS-lab is not a network simulator but the exact EOS implementation that runs on the hardware platforms. Supported features are documented here: vEOS-LAB Datasheet However, because vEOS-LAB implements a virtual data plane there are known caveats and adjustments that are required to default arista.avd settings: Variables adjustments required for vEOS-LAB: # Disable update wait-for-convergence and update wait-for-install, which is not supported in vEOS-LAB. spine_bgp_defaults : # - update wait-for-convergence # - update wait-install - no bgp default ipv4-unicast - distance bgp 20 200 200 - graceful-restart restart-time 300 - graceful-restart leaf_bgp_defaults : # - update wait-install - no bgp default ipv4-unicast - distance bgp 20 200 200 - graceful-restart restart-time 300 - graceful-restart # Update p2p mtu 9000 -> 1500, MTU 9000 not supported in vEOS-LAB. p2p_uplinks_mtu : 1500 # Adjust default bfd values, to avoid high CPU. bfd_multihop : interval : 1200 min_rx : 1200 multiplier : 3","title":"vEOS-LAB Know Caveats and Recommendations"},{"location":"roles/eos_l3ls_evpn/#license","text":"Project is published under Apache 2.0 License","title":"License"}]}